{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S4_Assignment_Solution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C6Q1qmEfZGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29bb5653-62bf-44b8-87bd-43f9784f47bf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFvX_zvMhIew",
        "outputId": "a6e02324-84c9-4c14-aed9-ad2e362bc6f4"
      },
      "source": [
        "%cd /content/drive/MyDrive/END/Week4"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/END/Week4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjanDrtyd8I2"
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy', include_lengths = True)\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gdj9vbG-eYzX",
        "outputId": "dee0968e-2d7c-4034-e13b-15854c54bddd"
      },
      "source": [
        "from torchtext import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL, root = 'data')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:03<00:00, 22.5MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pEE_0Xiebtd"
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTWy7M8AjdF0",
        "outputId": "2696fcc6-5bca-483a-ce93-f1869b3fa530"
      },
      "source": [
        "len(train_data), len(valid_data), len(test_data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17500, 7500, 25000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCjemXjIegFi",
        "outputId": "a14449e0-d657-469d-9595-765049876d52"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:29, 2.22MB/s]                           \n",
            "100%|█████████▉| 399241/400000 [00:17<00:00, 22043.11it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFF8FPrMnQb_"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eygvQUi4DFFP"
      },
      "source": [
        "## Reversing the text\n",
        "We can use torch.flip or list reversal to reverse the text. Lets try it out on one batch of the text. torch.flip is more efficient than the second method shown later\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qUTkFTc_g28",
        "outputId": "2ea27f40-22ef-4125-8065-a793128758b8"
      },
      "source": [
        "one_batch = list(train_iterator)[0].text[0]\n",
        "one_batch"
      ],
      "execution_count": 405,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  11,  314,   11,  ...,    0,   25,  403],\n",
              "        [ 290,   12,   19,  ...,  251,  333,    2],\n",
              "        [  13,  282, 2352,  ...,    3, 7151, 1684],\n",
              "        ...,\n",
              "        [2606,   40,   16,  ...,    1,    1,    1],\n",
              "        [ 880,  235,   24,  ...,    1,    1,    1],\n",
              "        [   4,   88,    4,  ...,    1,    1,    1]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 405
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooDZVFRfD4p0"
      },
      "source": [
        "### Method 1: Using torch.flip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhCxMHnVCTUB",
        "outputId": "277d1b37-3a1a-4e23-85e7-f15fb1da3cd7"
      },
      "source": [
        "torch.flip(one_batch, (0, ))"
      ],
      "execution_count": 406,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   4,   88,    4,  ...,    1,    1,    1],\n",
              "        [ 880,  235,   24,  ...,    1,    1,    1],\n",
              "        [2606,   40,   16,  ...,    1,    1,    1],\n",
              "        ...,\n",
              "        [  13,  282, 2352,  ...,    3, 7151, 1684],\n",
              "        [ 290,   12,   19,  ...,  251,  333,    2],\n",
              "        [  11,  314,   11,  ...,    0,   25,  403]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 406
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFZtPt5KEB6O"
      },
      "source": [
        "### Method 2: Using list reversal using reversed function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHFG3zkBEmqG"
      },
      "source": [
        "**Original text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "JnasqALuEE1f",
        "outputId": "390f518e-a549-44a9-e2b4-9c3ad775820f"
      },
      "source": [
        "\" \".join([TEXT.vocab.itos[x] for x in one_batch[:, 0].detach().cpu()])"
      ],
      "execution_count": 407,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I believe that war films should try to convey the terror of war , avoid idealism and respect some rudimentary military principles . <unk> barely does the first . <unk> being a Russian war film , I was expecting patriotism , sentimentality , beautiful poetic pictures , a lush score , Slavic <unk> and cruel Germans . What I did n\\'t need was the naive love non - affair , the unrealistically silly war scenes and the abuse of the syrupy soundtrack in a film which avoided carefully all historical or political references ( <unk> , Nazism , Holocaust ) only to end on a passing but nonetheless insulting to our sense of history <unk> about \" liberating Poland \" . A missed opportunity as a film but not as propaganda apparently .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 407
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THvkITSQEpSK"
      },
      "source": [
        "**Reversed text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "rRf1sNRSEvB8",
        "outputId": "cf1440a8-a231-4cee-fba2-c53159111212"
      },
      "source": [
        "\" \".join(list(reversed([TEXT.vocab.itos[x] for x in one_batch[:, 0].detach().cpu()])))"
      ],
      "execution_count": 408,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'. apparently propaganda as not but film a as opportunity missed A . \" Poland liberating \" about <unk> history of sense our to insulting nonetheless but passing a on end to only ) Holocaust , Nazism , <unk> ( references political or historical all carefully avoided which film a in soundtrack syrupy the of abuse the and scenes war silly unrealistically the , affair - non love naive the was need n\\'t did I What . Germans cruel and <unk> Slavic , score lush a , pictures poetic beautiful , sentimentality , patriotism expecting was I , film war Russian a being <unk> . first the does barely <unk> . principles military rudimentary some respect and idealism avoid , war of terror the convey to try should films war that believe I'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 408
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uHD1dOOFASk"
      },
      "source": [
        "**This we have to do individually for each text using a for loop if we are using Method 2. Hence Method 1 is more efficient**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0AWZHs9FpmG"
      },
      "source": [
        "## Model Definition\n",
        "\n",
        "Here we have to use 3 LSTM layers in a loop instead of using the layer parameter = 3 in the nn.LSTM layer.\n",
        "This we can do using torch.Modulelist and passing the cell states and hidden states of one LSTM layer to other using a for loop "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNaQzau4HVg1"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 409,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0Q88D1lnbyq"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.multi_layered_rnn = nn.ModuleList([nn.LSTM(embedding_dim, hidden_dim)])\n",
        "        self.multi_layered_rnn.extend([nn.Dropout(dropout), nn.LSTM(hidden_dim, hidden_dim)]*(n_layers-1))\n",
        "        \n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 1, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        #pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, enforce_sorted=False)\n",
        "        for rnn in self.multi_layered_rnn:\n",
        "          # print(packed_embedded)\n",
        "          if not isinstance(rnn, torch.nn.modules.dropout.Dropout): \n",
        "            packed_embedded, (hidden, cell) = rnn(packed_embedded)\n",
        "          else:\n",
        "            packed_embedded, packed_lengths = nn.utils.rnn.pad_packed_sequence(packed_embedded)\n",
        "            packed_embedded = nn.utils.rnn.pack_padded_sequence(rnn(packed_embedded), packed_lengths, enforce_sorted=False)\n",
        "        \n",
        "        #unpack sequence\n",
        "        # output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * num directions]\n",
        "        #output over padding tokens are zero tensors\n",
        "        \n",
        "        #hidden = [num layers * num directions, batch size, hid dim]\n",
        "        #cell = [num layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        #and apply dropout\n",
        "        \n",
        "        hidden = self.dropout(hidden[-1,:,:])\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "            \n",
        "        return self.fc(hidden)"
      ],
      "execution_count": 458,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drXl6D7awiz5"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 3\n",
        "# BIDIRECTIONAL = True\n",
        "DROPOUT = 0.2\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = RNN(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)"
      ],
      "execution_count": 459,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAPh1RBcN8-9",
        "outputId": "94414117-d434-4619-a317-b149e01a322d"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 460,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (multi_layered_rnn): ModuleList(\n",
            "    (0): LSTM(100, 256)\n",
            "    (1): Dropout(p=0.2, inplace=False)\n",
            "    (2): LSTM(256, 256)\n",
            "    (3): Dropout(p=0.2, inplace=False)\n",
            "    (4): LSTM(256, 256)\n",
            "  )\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eIlu6H1wsqJ",
        "outputId": "50522ecc-b86f-4e03-a07a-92e1af9ce9f0"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 461,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 3,393,385 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqCPf95Qw02K",
        "outputId": "822b41d3-1aeb-4e77-92a1-473328f5f100"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 462,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25002, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgIPwqrTxKQX",
        "outputId": "7ad803bc-3148-46f9-a158-c90f04b27b8c"
      },
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 463,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
              "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [-0.0218, -0.0350,  0.1495,  ..., -0.5508,  0.4874, -0.1341],\n",
              "        [-0.6345,  0.5735, -0.3945,  ..., -0.4865,  0.1097,  0.5122],\n",
              "        [ 0.6406,  0.3674,  0.8373,  ..., -0.1512, -0.0284, -0.1952]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 463
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw-L6PtLxMje",
        "outputId": "18dcc756-30ca-4ce2-f53e-97058cea1554"
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": 464,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [-0.0218, -0.0350,  0.1495,  ..., -0.5508,  0.4874, -0.1341],\n",
            "        [-0.6345,  0.5735, -0.3945,  ..., -0.4865,  0.1097,  0.5122],\n",
            "        [ 0.6406,  0.3674,  0.8373,  ..., -0.1512, -0.0284, -0.1952]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IooCd1N6xeka"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 465,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8qZQ1JHxz9i"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 466,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSCdjCrxx4qd"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 467,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2T-bpWsO6T1"
      },
      "source": [
        "**In the train function we are reversing the text online as we get the data from the batch. This was it will be less memory intensive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DXXcEuwx8f4"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        text, text_lengths = batch.text\n",
        "        text_lengths = text_lengths.cpu()\n",
        "        #Reversing the text\n",
        "        text = torch.flip(text, (0, ))\n",
        "\n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 468,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKX78wFryObF"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text, text_lengths = batch.text\n",
        "            text_lengths = text_lengths.cpu()\n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 469,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMJrW0y6yR52"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 470,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCaZtDACyU3y",
        "outputId": "28eb7c96-582f-4b0c-d844-91e7dbec96bb"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 471,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.679 | Train Acc: 57.02%\n",
            "\t Val. Loss: 0.662 |  Val. Acc: 62.69%\n",
            "Epoch: 02 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.659 | Train Acc: 60.13%\n",
            "\t Val. Loss: 0.672 |  Val. Acc: 65.51%\n",
            "Epoch: 03 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.506 | Train Acc: 75.81%\n",
            "\t Val. Loss: 0.362 |  Val. Acc: 84.97%\n",
            "Epoch: 04 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.331 | Train Acc: 86.30%\n",
            "\t Val. Loss: 0.346 |  Val. Acc: 85.90%\n",
            "Epoch: 05 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.293 | Train Acc: 88.18%\n",
            "\t Val. Loss: 0.314 |  Val. Acc: 87.20%\n",
            "Epoch: 06 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.233 | Train Acc: 91.00%\n",
            "\t Val. Loss: 0.319 |  Val. Acc: 87.50%\n",
            "Epoch: 07 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.198 | Train Acc: 92.61%\n",
            "\t Val. Loss: 0.373 |  Val. Acc: 85.64%\n",
            "Epoch: 08 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.180 | Train Acc: 93.31%\n",
            "\t Val. Loss: 0.409 |  Val. Acc: 85.76%\n",
            "Epoch: 09 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.150 | Train Acc: 94.61%\n",
            "\t Val. Loss: 0.306 |  Val. Acc: 88.05%\n",
            "Epoch: 10 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.131 | Train Acc: 95.30%\n",
            "\t Val. Loss: 0.399 |  Val. Acc: 85.84%\n",
            "Epoch: 11 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.104 | Train Acc: 96.33%\n",
            "\t Val. Loss: 0.379 |  Val. Acc: 87.98%\n",
            "Epoch: 12 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.101 | Train Acc: 96.59%\n",
            "\t Val. Loss: 0.404 |  Val. Acc: 87.49%\n",
            "Epoch: 13 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.076 | Train Acc: 97.51%\n",
            "\t Val. Loss: 0.408 |  Val. Acc: 87.64%\n",
            "Epoch: 14 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.062 | Train Acc: 97.96%\n",
            "\t Val. Loss: 0.472 |  Val. Acc: 87.37%\n",
            "Epoch: 15 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.056 | Train Acc: 98.28%\n",
            "\t Val. Loss: 0.448 |  Val. Acc: 87.56%\n",
            "Epoch: 16 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.048 | Train Acc: 98.53%\n",
            "\t Val. Loss: 0.477 |  Val. Acc: 87.70%\n",
            "Epoch: 17 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.046 | Train Acc: 98.49%\n",
            "\t Val. Loss: 0.506 |  Val. Acc: 87.46%\n",
            "Epoch: 18 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.034 | Train Acc: 99.07%\n",
            "\t Val. Loss: 0.519 |  Val. Acc: 87.09%\n",
            "Epoch: 19 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.037 | Train Acc: 98.87%\n",
            "\t Val. Loss: 0.475 |  Val. Acc: 87.64%\n",
            "Epoch: 20 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.035 | Train Acc: 98.96%\n",
            "\t Val. Loss: 0.477 |  Val. Acc: 87.80%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWScDwsVyZqC",
        "outputId": "010ae91d-34a6-4611-ef74-4cf04f448a59"
      },
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 472,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.338 | Test Acc: 85.84%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pVcyNqGaW8Q"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def predict_sentiment(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    rev_tokenized = list(reversed(tokenized))\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in rev_tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
        "    return prediction.item()"
      ],
      "execution_count": 473,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urbjp1_2abz_",
        "outputId": "90c826a7-6fe9-4e84-f313-20d1312773dd"
      },
      "source": [
        "sentence = \"This film is terrible\"\n",
        "predict_sentiment(model, sentence)"
      ],
      "execution_count": 474,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0022441146429628134"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 474
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UXJmeQzeT5c",
        "outputId": "61a49491-07d6-474d-bd1b-2c77bdc1db12"
      },
      "source": [
        "sentence = \"This film is awesome\"\n",
        "predict_sentiment(model, sentence)"
      ],
      "execution_count": 475,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9864891767501831"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 475
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPRbvCmhvzSI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}