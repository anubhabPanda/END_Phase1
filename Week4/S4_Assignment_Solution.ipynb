{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S4_Assignment_Solution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C6Q1qmEfZGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa5756e7-7254-40d5-fddb-aeb5c9421553"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 498,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFvX_zvMhIew",
        "outputId": "3b63a7df-7b88-4b47-8d8c-3f64f0b8d842"
      },
      "source": [
        "%cd /content/drive/MyDrive/END/Week4"
      ],
      "execution_count": 499,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/END/Week4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjanDrtyd8I2"
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy', include_lengths = True)\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 500,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gdj9vbG-eYzX"
      },
      "source": [
        "from torchtext import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL, root = 'data')"
      ],
      "execution_count": 501,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pEE_0Xiebtd"
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 502,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTWy7M8AjdF0",
        "outputId": "251c46c1-2fef-41e0-b559-1b41de3f6972"
      },
      "source": [
        "len(train_data), len(valid_data), len(test_data)"
      ],
      "execution_count": 503,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17500, 7500, 25000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 503
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCjemXjIegFi",
        "outputId": "d14703a7-d50c-448e-bc55-73a4af3c83cb"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.200d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 504,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/400000 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 1663/400000 [00:00<00:23, 16624.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 3162/400000 [00:00<00:24, 16097.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 4719/400000 [00:00<00:24, 15935.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 6157/400000 [00:00<00:25, 15431.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 7666/400000 [00:00<00:25, 15327.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 9252/400000 [00:00<00:25, 15480.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 10831/400000 [00:00<00:24, 15571.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 12405/400000 [00:00<00:24, 15620.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 13873/400000 [00:00<00:25, 15218.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 15332/400000 [00:01<00:25, 14987.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 16809/400000 [00:01<00:25, 14915.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▍         | 18415/400000 [00:01<00:25, 15239.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▍         | 19975/400000 [00:01<00:24, 15343.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▌         | 21499/400000 [00:01<00:24, 15309.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 23021/400000 [00:01<00:25, 14935.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 24510/400000 [00:01<00:25, 14799.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 26099/400000 [00:01<00:24, 15108.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 27684/400000 [00:01<00:24, 15319.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 29217/400000 [00:01<00:26, 14143.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 30739/400000 [00:02<00:25, 14448.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 32300/400000 [00:02<00:24, 14777.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 33850/400000 [00:02<00:24, 14984.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 35449/400000 [00:02<00:23, 15269.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 37040/400000 [00:02<00:23, 15455.54it/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|▉         | 38620/400000 [00:02<00:23, 15556.59it/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 40204/400000 [00:02<00:23, 15638.59it/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 41771/400000 [00:02<00:23, 15445.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 43319/400000 [00:02<00:23, 14994.17it/s]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 44824/400000 [00:02<00:23, 14958.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 46418/400000 [00:03<00:23, 15238.42it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 47946/400000 [00:03<00:23, 15029.67it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 49514/400000 [00:03<00:23, 15217.65it/s]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 51091/400000 [00:03<00:22, 15376.74it/s]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 52632/400000 [00:03<00:23, 14942.99it/s]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▎        | 54131/400000 [00:03<00:23, 14766.40it/s]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 55696/400000 [00:03<00:22, 15018.64it/s]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 57282/400000 [00:03<00:22, 15259.03it/s]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▍        | 58863/400000 [00:03<00:22, 15418.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 60408/400000 [00:03<00:22, 15185.01it/s]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 61938/400000 [00:04<00:22, 15218.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 63522/400000 [00:04<00:21, 15398.67it/s]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▋        | 65122/400000 [00:04<00:21, 15573.53it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 66712/400000 [00:04<00:21, 15670.04it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 68286/400000 [00:04<00:21, 15689.89it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 69856/400000 [00:04<00:21, 15210.67it/s]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 71381/400000 [00:04<00:21, 15221.39it/s]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 72928/400000 [00:04<00:21, 15293.87it/s]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▊        | 74520/400000 [00:04<00:21, 15474.42it/s]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 76070/400000 [00:04<00:21, 15261.36it/s]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 77640/400000 [00:05<00:20, 15388.37it/s]\u001b[A\u001b[A\n",
            "\n",
            " 20%|█▉        | 79181/400000 [00:05<00:21, 15149.99it/s]\u001b[A\u001b[A\n",
            "\n",
            " 20%|██        | 80758/400000 [00:05<00:20, 15329.79it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 82328/400000 [00:05<00:20, 15437.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 83874/400000 [00:05<00:21, 14494.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██▏       | 85337/400000 [00:05<00:23, 13600.74it/s]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 86718/400000 [00:05<00:23, 13386.32it/s]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 88128/400000 [00:05<00:22, 13592.69it/s]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 89499/400000 [00:05<00:23, 13454.18it/s]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 90860/400000 [00:06<00:22, 13497.96it/s]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 92289/400000 [00:06<00:22, 13724.86it/s]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 93684/400000 [00:06<00:22, 13789.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 95067/400000 [00:06<00:23, 13134.66it/s]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 96416/400000 [00:06<00:22, 13239.04it/s]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 97747/400000 [00:06<00:23, 12691.39it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▍       | 99155/400000 [00:06<00:23, 13077.33it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 100667/400000 [00:06<00:21, 13628.03it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 102265/400000 [00:06<00:20, 14257.32it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 103718/400000 [00:06<00:20, 14335.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▋       | 105276/400000 [00:07<00:20, 14687.07it/s]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 106879/400000 [00:07<00:19, 15064.11it/s]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 108396/400000 [00:07<00:19, 14693.53it/s]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 109962/400000 [00:07<00:19, 14969.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 111467/400000 [00:07<00:19, 14596.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 112943/400000 [00:07<00:19, 14642.88it/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▊       | 114413/400000 [00:07<00:19, 14638.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 115972/400000 [00:07<00:19, 14907.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 117531/400000 [00:07<00:18, 15104.14it/s]\u001b[A\u001b[A\n",
            "\n",
            " 30%|██▉       | 119045/400000 [00:08<00:18, 14906.95it/s]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 120539/400000 [00:08<00:19, 14588.34it/s]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 122002/400000 [00:08<00:19, 14001.46it/s]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 123448/400000 [00:08<00:19, 14134.31it/s]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███▏      | 125032/400000 [00:08<00:18, 14605.76it/s]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 126501/400000 [00:08<00:19, 14387.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 128028/400000 [00:08<00:18, 14640.90it/s]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 129607/400000 [00:08<00:18, 14967.08it/s]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 131139/400000 [00:08<00:17, 15069.54it/s]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 132685/400000 [00:08<00:17, 15183.11it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▎      | 134207/400000 [00:09<00:17, 15024.19it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 135729/400000 [00:09<00:17, 15081.87it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 137319/400000 [00:09<00:17, 15316.01it/s]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▍      | 138906/400000 [00:09<00:16, 15477.34it/s]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▌      | 140501/400000 [00:09<00:16, 15615.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 142076/400000 [00:09<00:16, 15653.33it/s]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 143655/400000 [00:09<00:16, 15693.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▋      | 145236/400000 [00:09<00:16, 15726.71it/s]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 146810/400000 [00:09<00:16, 15375.11it/s]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 148352/400000 [00:09<00:16, 15387.87it/s]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 149893/400000 [00:10<00:16, 14871.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 151385/400000 [00:10<00:16, 14727.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 152862/400000 [00:10<00:17, 14334.60it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▊      | 154400/400000 [00:10<00:16, 14631.54it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 155869/400000 [00:10<00:16, 14612.68it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 157334/400000 [00:10<00:16, 14419.72it/s]\u001b[A\u001b[A\n",
            "\n",
            " 40%|███▉      | 158779/400000 [00:10<00:16, 14318.64it/s]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 160214/400000 [00:10<00:17, 14058.32it/s]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 161623/400000 [00:10<00:17, 14010.64it/s]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 163026/400000 [00:10<00:16, 13940.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 164422/400000 [00:11<00:18, 13015.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████▏     | 165737/400000 [00:11<00:18, 12400.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 166993/400000 [00:11<00:19, 12218.26it/s]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 168227/400000 [00:11<00:19, 12051.40it/s]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 169466/400000 [00:11<00:18, 12148.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 170793/400000 [00:11<00:18, 12463.67it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 172046/400000 [00:11<00:18, 12408.71it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 173557/400000 [00:11<00:17, 13111.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 175102/400000 [00:11<00:16, 13734.13it/s]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 176535/400000 [00:12<00:16, 13906.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 177945/400000 [00:12<00:15, 13963.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▍     | 179351/400000 [00:12<00:15, 13963.47it/s]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▌     | 180754/400000 [00:12<00:15, 13940.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 182153/400000 [00:12<00:16, 13525.61it/s]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 183636/400000 [00:12<00:15, 13890.18it/s]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▋     | 185032/400000 [00:12<00:15, 13735.96it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 186411/400000 [00:12<00:16, 13291.32it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 187926/400000 [00:12<00:15, 13797.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 189479/400000 [00:12<00:14, 14274.92it/s]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 190918/400000 [00:13<00:14, 14141.54it/s]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 192438/400000 [00:13<00:14, 14441.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 193990/400000 [00:13<00:13, 14747.71it/s]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 195557/400000 [00:13<00:13, 15012.39it/s]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 197075/400000 [00:13<00:13, 15061.65it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|████▉     | 198586/400000 [00:13<00:13, 14666.78it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 200126/400000 [00:13<00:13, 14878.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 201670/400000 [00:13<00:13, 15041.18it/s]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 203242/400000 [00:13<00:12, 15237.13it/s]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 204769/400000 [00:13<00:12, 15187.85it/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 206290/400000 [00:14<00:13, 14842.91it/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 207825/400000 [00:14<00:12, 14989.78it/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 209402/400000 [00:14<00:12, 15215.05it/s]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 210927/400000 [00:14<00:12, 15037.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 212434/400000 [00:14<00:13, 14202.43it/s]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 213866/400000 [00:14<00:13, 13909.21it/s]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 215354/400000 [00:14<00:13, 14186.32it/s]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 216914/400000 [00:14<00:12, 14581.39it/s]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▍    | 218408/400000 [00:14<00:12, 14684.76it/s]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▍    | 219934/400000 [00:15<00:12, 14852.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▌    | 221424/400000 [00:15<00:12, 14232.40it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 222905/400000 [00:15<00:12, 14398.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 224352/400000 [00:15<00:12, 13927.04it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▋    | 225753/400000 [00:15<00:13, 13265.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 227092/400000 [00:15<00:13, 13225.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 228462/400000 [00:15<00:12, 13362.73it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 229814/400000 [00:15<00:12, 13409.35it/s]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 231352/400000 [00:15<00:12, 13944.21it/s]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 232923/400000 [00:15<00:11, 14428.62it/s]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▊    | 234481/400000 [00:16<00:11, 14755.46it/s]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 235966/400000 [00:16<00:11, 14602.03it/s]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 237480/400000 [00:16<00:11, 14759.33it/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|█████▉    | 238962/400000 [00:16<00:11, 14190.73it/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 240390/400000 [00:16<00:11, 14016.37it/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 241798/400000 [00:16<00:11, 13255.07it/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 243244/400000 [00:16<00:11, 13593.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 244749/400000 [00:16<00:11, 13998.87it/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 246288/400000 [00:16<00:10, 14387.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 247839/400000 [00:17<00:10, 14705.97it/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 249319/400000 [00:17<00:10, 14247.06it/s]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 250847/400000 [00:17<00:10, 14540.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 252310/400000 [00:17<00:10, 14105.49it/s]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 253850/400000 [00:17<00:10, 14469.26it/s]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 255306/400000 [00:17<00:10, 14144.60it/s]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 256781/400000 [00:17<00:10, 14319.33it/s]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▍   | 258303/400000 [00:17<00:09, 14578.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▍   | 259786/400000 [00:17<00:09, 14650.42it/s]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▌   | 261331/400000 [00:17<00:09, 14880.87it/s]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 262866/400000 [00:18<00:09, 15017.05it/s]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 264371/400000 [00:18<00:09, 14199.45it/s]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▋   | 265894/400000 [00:18<00:09, 14492.36it/s]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 267353/400000 [00:18<00:09, 14213.81it/s]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 268798/400000 [00:18<00:09, 14282.21it/s]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 270232/400000 [00:18<00:09, 13880.47it/s]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 271763/400000 [00:18<00:08, 14278.46it/s]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 273293/400000 [00:18<00:08, 14570.19it/s]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▊   | 274769/400000 [00:18<00:08, 14626.11it/s]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 276330/400000 [00:18<00:08, 14906.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 277891/400000 [00:19<00:08, 15108.47it/s]\u001b[A\u001b[A\n",
            "\n",
            " 70%|██████▉   | 279406/400000 [00:19<00:08, 14706.63it/s]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 280882/400000 [00:19<00:08, 14446.29it/s]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 282415/400000 [00:19<00:07, 14698.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 283949/400000 [00:19<00:07, 14882.67it/s]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████▏  | 285441/400000 [00:19<00:07, 14574.75it/s]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 286903/400000 [00:19<00:07, 14470.76it/s]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 288417/400000 [00:19<00:07, 14661.01it/s]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 289886/400000 [00:19<00:07, 14300.71it/s]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 291402/400000 [00:20<00:07, 14546.50it/s]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 292970/400000 [00:20<00:07, 14868.29it/s]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▎  | 294462/400000 [00:20<00:07, 14530.29it/s]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 295999/400000 [00:20<00:07, 14770.61it/s]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 297481/400000 [00:20<00:07, 14400.74it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▍  | 298927/400000 [00:20<00:07, 13608.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 300340/400000 [00:20<00:07, 13760.36it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 301844/400000 [00:20<00:06, 14118.20it/s]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 303380/400000 [00:20<00:06, 14467.65it/s]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 304899/400000 [00:20<00:06, 14674.83it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 306373/400000 [00:21<00:06, 14366.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 307875/400000 [00:21<00:06, 14556.53it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 309336/400000 [00:21<00:06, 14290.16it/s]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 310821/400000 [00:21<00:06, 14453.57it/s]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 312270/400000 [00:21<00:06, 14256.88it/s]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 313699/400000 [00:21<00:06, 13549.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 315064/400000 [00:21<00:06, 13331.60it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 316460/400000 [00:21<00:06, 13513.61it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 317818/400000 [00:21<00:06, 13362.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 80%|███████▉  | 319369/400000 [00:22<00:05, 13939.73it/s]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 320886/400000 [00:22<00:05, 14285.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 322333/400000 [00:22<00:05, 14338.34it/s]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 323910/400000 [00:22<00:05, 14737.89it/s]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████▏ | 325391/400000 [00:22<00:05, 14608.01it/s]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 326858/400000 [00:22<00:05, 14421.16it/s]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 328393/400000 [00:22<00:04, 14680.88it/s]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 329884/400000 [00:22<00:04, 14748.36it/s]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 331384/400000 [00:22<00:04, 14820.50it/s]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 332881/400000 [00:22<00:04, 14864.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▎ | 334437/400000 [00:23<00:04, 15065.97it/s]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 335946/400000 [00:23<00:04, 14648.81it/s]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 337415/400000 [00:23<00:04, 13785.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▍ | 338879/400000 [00:23<00:04, 14028.80it/s]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▌ | 340410/400000 [00:23<00:04, 14388.02it/s]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▌ | 341937/400000 [00:23<00:03, 14641.07it/s]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 343409/400000 [00:23<00:03, 14297.91it/s]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 344953/400000 [00:23<00:03, 14620.96it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 346516/400000 [00:23<00:03, 14908.89it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 348077/400000 [00:23<00:03, 15111.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 349594/400000 [00:24<00:03, 15099.38it/s]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 351155/400000 [00:24<00:03, 15246.54it/s]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 352683/400000 [00:24<00:03, 14619.42it/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▊ | 354153/400000 [00:24<00:03, 14619.37it/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 355699/400000 [00:24<00:02, 14861.29it/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 357198/400000 [00:24<00:02, 14899.49it/s]\u001b[A\u001b[A\n",
            "\n",
            " 90%|████████▉ | 358692/400000 [00:24<00:02, 14600.99it/s]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 360156/400000 [00:24<00:02, 14277.73it/s]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 361704/400000 [00:24<00:02, 14616.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 363273/400000 [00:24<00:02, 14921.15it/s]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 364850/400000 [00:25<00:02, 15165.16it/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 366405/400000 [00:25<00:02, 15276.69it/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 367936/400000 [00:25<00:02, 14674.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 369411/400000 [00:25<00:02, 14611.95it/s]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 370938/400000 [00:25<00:01, 14801.55it/s]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 372499/400000 [00:25<00:01, 15034.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▎| 374070/400000 [00:25<00:01, 15229.90it/s]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 375608/400000 [00:25<00:01, 15272.08it/s]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 377138/400000 [00:25<00:01, 15036.14it/s]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▍| 378645/400000 [00:26<00:01, 14796.48it/s]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▌| 380179/400000 [00:26<00:01, 14954.95it/s]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▌| 381698/400000 [00:26<00:01, 15022.35it/s]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 383202/400000 [00:26<00:01, 14913.96it/s]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 384695/400000 [00:26<00:01, 14691.43it/s]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 386166/400000 [00:26<00:00, 14575.20it/s]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 387675/400000 [00:26<00:00, 14724.47it/s]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 389236/400000 [00:26<00:00, 14978.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 390736/400000 [00:26<00:00, 14888.13it/s]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 392298/400000 [00:26<00:00, 15100.26it/s]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 393857/400000 [00:27<00:00, 15241.61it/s]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 395390/400000 [00:27<00:00, 15266.43it/s]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 396918/400000 [00:27<00:00, 14925.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|█████████▉| 398414/400000 [00:27<00:00, 14726.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|█████████▉| 399982/400000 [00:27<00:00, 14998.43it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFF8FPrMnQb_"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": 526,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eygvQUi4DFFP"
      },
      "source": [
        "## Reversing the text\n",
        "We can use torch.flip or list reversal to reverse the text. Lets try it out on one batch of the text. torch.flip is more efficient than the second method shown later\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qUTkFTc_g28",
        "outputId": "7fc3c85f-cb10-4027-d81d-a67b6ed1caad"
      },
      "source": [
        "one_batch = list(train_iterator)[0].text[0]\n",
        "one_batch"
      ],
      "execution_count": 527,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  11, 8503,   11,  ...,   66,   66,   66],\n",
              "        [  19, 1180,  216,  ...,   24,   23,   19],\n",
              "        [ 818,  256,   12,  ...,    9,    9,    5],\n",
              "        ...,\n",
              "        [ 220,   64,   22,  ...,    4,    0, 5140],\n",
              "        [  53,   21,  308,  ...,    1,    1,    1],\n",
              "        [ 163,    4,    4,  ...,    1,    1,    1]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 527
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooDZVFRfD4p0"
      },
      "source": [
        "### Method 1: Using torch.flip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhCxMHnVCTUB",
        "outputId": "4311ca68-f260-49a4-c79c-03a22d9310f5"
      },
      "source": [
        "torch.flip(one_batch, (0, ))"
      ],
      "execution_count": 528,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 163,    4,    4,  ...,    1,    1,    1],\n",
              "        [  53,   21,  308,  ...,    1,    1,    1],\n",
              "        [ 220,   64,   22,  ...,    4,    0, 5140],\n",
              "        ...,\n",
              "        [ 818,  256,   12,  ...,    9,    9,    5],\n",
              "        [  19, 1180,  216,  ...,   24,   23,   19],\n",
              "        [  11, 8503,   11,  ...,   66,   66,   66]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 528
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFZtPt5KEB6O"
      },
      "source": [
        "### Method 2: Using list reversal using reversed function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHFG3zkBEmqG"
      },
      "source": [
        "**Original text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "JnasqALuEE1f",
        "outputId": "2d201842-9c19-47d1-af75-80d70cdec257"
      },
      "source": [
        "\" \".join([TEXT.vocab.itos[x] for x in one_batch[:, 0].detach().cpu()])"
      ],
      "execution_count": 529,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I was surprised at how a movie could be both cheesy and excellent at the same time . The <unk> flying saucer was naff beyond comprehension , especially when landing , yet the specially effects when the Krell attacked were awesome for a film that was made over half a century ago ! Living in the middle east I saw shades of Islam creep in when JJ Adams suggested <unk> should dress more modestly , and as an engineer , was amazed by the imagination used for the ' futuristic ' gadgets , and <unk> dreamed up by the props department . All in all , an entertaining hour and a half , my first time seeing Walter Pidgeon and a chance to see Leslie <unk> as a ' young ' man\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 529
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THvkITSQEpSK"
      },
      "source": [
        "**Reversed text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "rRf1sNRSEvB8",
        "outputId": "d95f806c-9e91-43ba-f2e7-27a4e024ad2d"
      },
      "source": [
        "\" \".join(list(reversed([TEXT.vocab.itos[x] for x in one_batch[:, 0].detach().cpu()])))"
      ],
      "execution_count": 530,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"man ' young ' a as <unk> Leslie see to chance a and Pidgeon Walter seeing time first my , half a and hour entertaining an , all in All . department props the by up dreamed <unk> and , gadgets ' futuristic ' the for used imagination the by amazed was , engineer an as and , modestly more dress should <unk> suggested Adams JJ when in creep Islam of shades saw I east middle the in Living ! ago century a half over made was that film a for awesome were attacked Krell the when effects specially the yet , landing when especially , comprehension beyond naff was saucer flying <unk> The . time same the at excellent and cheesy both be could movie a how at surprised was I\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 530
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uHD1dOOFASk"
      },
      "source": [
        "**This we have to do individually for each text using a for loop if we are using Method 2. Hence Method 1 is more efficient**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0AWZHs9FpmG"
      },
      "source": [
        "## Model Definition\n",
        "\n",
        "Here we have to use 3 LSTM layers in a loop instead of using the layer parameter = 3 in the nn.LSTM layer.\n",
        "This we can do using torch.Modulelist and passing the cell states and hidden states of one LSTM layer to other using a for loop "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNaQzau4HVg1"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 531,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0Q88D1lnbyq"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.multi_layered_rnn = nn.ModuleList([nn.LSTM(embedding_dim, hidden_dim)])\n",
        "        self.multi_layered_rnn.extend([nn.Dropout(dropout), nn.LSTM(hidden_dim, hidden_dim)]*(n_layers-1))\n",
        "        \n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 1, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        #pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, enforce_sorted=False)\n",
        "        for rnn in self.multi_layered_rnn:\n",
        "          # print(packed_embedded)\n",
        "          if not isinstance(rnn, torch.nn.modules.dropout.Dropout): \n",
        "            packed_embedded, (hidden, cell) = rnn(packed_embedded)\n",
        "          else:\n",
        "            packed_embedded, packed_lengths = nn.utils.rnn.pad_packed_sequence(packed_embedded)\n",
        "            packed_embedded = nn.utils.rnn.pack_padded_sequence(rnn(packed_embedded), packed_lengths, enforce_sorted=False)\n",
        "        \n",
        "        #unpack sequence\n",
        "        # output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * num directions]\n",
        "        #output over padding tokens are zero tensors\n",
        "        \n",
        "        #hidden = [num layers * num directions, batch size, hid dim]\n",
        "        #cell = [num layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        #and apply dropout\n",
        "        \n",
        "        hidden = self.dropout(hidden[-1,:,:])\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "            \n",
        "        return self.fc(hidden)"
      ],
      "execution_count": 566,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drXl6D7awiz5"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 200\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 3\n",
        "# BIDIRECTIONAL = True\n",
        "DROPOUT = 0.2\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = RNN(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)"
      ],
      "execution_count": 567,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAPh1RBcN8-9",
        "outputId": "3ab1ede9-8c7d-44c7-f78e-6868a82d85dc"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 568,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (embedding): Embedding(25002, 200, padding_idx=1)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (multi_layered_rnn): ModuleList(\n",
            "    (0): LSTM(200, 256)\n",
            "    (1): Dropout(p=0.2, inplace=False)\n",
            "    (2): LSTM(256, 256)\n",
            "    (3): Dropout(p=0.2, inplace=False)\n",
            "    (4): LSTM(256, 256)\n",
            "  )\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eIlu6H1wsqJ",
        "outputId": "a9d8d765-5b29-43d7-c871-6f6b0194d63b"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 569,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 5,995,985 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqCPf95Qw02K",
        "outputId": "9f52eef8-f7f5-47e3-8492-c3bb2e7ee403"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 570,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25002, 200])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgIPwqrTxKQX",
        "outputId": "f4ed714b-ba82-4f5b-849c-8eecb0673461"
      },
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 571,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1117, -0.4966,  0.1631,  ..., -1.8542,  0.4022,  0.4238],\n",
              "        [ 0.2078,  1.1879, -0.7320,  ...,  1.3663, -0.4598,  0.6668],\n",
              "        [-0.0715,  0.0935,  0.0237,  ...,  0.3362,  0.0306,  0.2558],\n",
              "        ...,\n",
              "        [ 0.4815, -0.3176,  0.5229,  ...,  0.4595, -0.7940,  0.1645],\n",
              "        [-0.1764,  0.6005, -0.2219,  ...,  0.3903,  0.3519,  0.6316],\n",
              "        [ 0.2811, -0.2467,  0.0691,  ..., -0.2630,  0.0290,  0.5149]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 571
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw-L6PtLxMje",
        "outputId": "c9c6a2ac-491d-4e9b-c170-5bae6a8f37d6"
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": 572,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0715,  0.0935,  0.0237,  ...,  0.3362,  0.0306,  0.2558],\n",
            "        ...,\n",
            "        [ 0.4815, -0.3176,  0.5229,  ...,  0.4595, -0.7940,  0.1645],\n",
            "        [-0.1764,  0.6005, -0.2219,  ...,  0.3903,  0.3519,  0.6316],\n",
            "        [ 0.2811, -0.2467,  0.0691,  ..., -0.2630,  0.0290,  0.5149]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IooCd1N6xeka"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 573,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8qZQ1JHxz9i"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 574,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSCdjCrxx4qd"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 575,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2T-bpWsO6T1"
      },
      "source": [
        "**In the train function we are reversing the text online as we get the data from the batch. This was it will be less memory intensive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DXXcEuwx8f4"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        text, text_lengths = batch.text\n",
        "        text_lengths = text_lengths.cpu()\n",
        "        #Reversing the text\n",
        "        rev_text = torch.flip(text, (0, ))\n",
        "        predictions = model(rev_text, text_lengths).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 580,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKX78wFryObF"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text, text_lengths = batch.text\n",
        "            text_lengths = text_lengths.cpu()\n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 581,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMJrW0y6yR52"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 582,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCaZtDACyU3y",
        "outputId": "6d204afe-fb80-46c7-a881-88b440c4da13"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 583,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 30s\n",
            "\tTrain Loss: 0.681 | Train Acc: 54.69%\n",
            "\t Val. Loss: 0.684 |  Val. Acc: 53.19%\n",
            "Epoch: 02 | Epoch Time: 0m 30s\n",
            "\tTrain Loss: 0.656 | Train Acc: 59.36%\n",
            "\t Val. Loss: 0.689 |  Val. Acc: 55.20%\n",
            "Epoch: 03 | Epoch Time: 0m 30s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.31%\n",
            "\t Val. Loss: 0.695 |  Val. Acc: 49.22%\n",
            "Epoch: 04 | Epoch Time: 0m 30s\n",
            "\tTrain Loss: 0.661 | Train Acc: 61.32%\n",
            "\t Val. Loss: 0.546 |  Val. Acc: 78.62%\n",
            "Epoch: 05 | Epoch Time: 0m 30s\n",
            "\tTrain Loss: 0.551 | Train Acc: 73.38%\n",
            "\t Val. Loss: 0.375 |  Val. Acc: 85.48%\n",
            "Epoch: 06 | Epoch Time: 0m 30s\n",
            "\tTrain Loss: 0.315 | Train Acc: 87.99%\n",
            "\t Val. Loss: 0.361 |  Val. Acc: 86.26%\n",
            "Epoch: 07 | Epoch Time: 0m 30s\n",
            "\tTrain Loss: 0.226 | Train Acc: 91.91%\n",
            "\t Val. Loss: 0.331 |  Val. Acc: 87.30%\n",
            "Epoch: 08 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.171 | Train Acc: 93.81%\n",
            "\t Val. Loss: 0.370 |  Val. Acc: 87.37%\n",
            "Epoch: 09 | Epoch Time: 0m 30s\n",
            "\tTrain Loss: 0.129 | Train Acc: 95.81%\n",
            "\t Val. Loss: 0.355 |  Val. Acc: 87.49%\n",
            "Epoch: 10 | Epoch Time: 0m 30s\n",
            "\tTrain Loss: 0.098 | Train Acc: 96.94%\n",
            "\t Val. Loss: 0.381 |  Val. Acc: 87.42%\n",
            "Epoch: 11 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.084 | Train Acc: 97.38%\n",
            "\t Val. Loss: 0.429 |  Val. Acc: 87.48%\n",
            "Epoch: 12 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.063 | Train Acc: 98.15%\n",
            "\t Val. Loss: 0.463 |  Val. Acc: 87.36%\n",
            "Epoch: 13 | Epoch Time: 0m 30s\n",
            "\tTrain Loss: 0.057 | Train Acc: 98.32%\n",
            "\t Val. Loss: 0.512 |  Val. Acc: 86.71%\n",
            "Epoch: 14 | Epoch Time: 0m 30s\n",
            "\tTrain Loss: 0.050 | Train Acc: 98.61%\n",
            "\t Val. Loss: 0.459 |  Val. Acc: 87.36%\n",
            "Epoch: 15 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.037 | Train Acc: 98.95%\n",
            "\t Val. Loss: 0.461 |  Val. Acc: 86.85%\n",
            "Epoch: 16 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.032 | Train Acc: 99.10%\n",
            "\t Val. Loss: 0.536 |  Val. Acc: 86.64%\n",
            "Epoch: 17 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.027 | Train Acc: 99.28%\n",
            "\t Val. Loss: 0.566 |  Val. Acc: 86.85%\n",
            "Epoch: 18 | Epoch Time: 0m 30s\n",
            "\tTrain Loss: 0.024 | Train Acc: 99.38%\n",
            "\t Val. Loss: 0.595 |  Val. Acc: 86.92%\n",
            "Epoch: 19 | Epoch Time: 0m 30s\n",
            "\tTrain Loss: 0.022 | Train Acc: 99.44%\n",
            "\t Val. Loss: 0.560 |  Val. Acc: 86.80%\n",
            "Epoch: 20 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.025 | Train Acc: 99.31%\n",
            "\t Val. Loss: 0.546 |  Val. Acc: 86.66%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWScDwsVyZqC",
        "outputId": "0c52f16d-915d-4de2-f63a-71702ed7c462"
      },
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 588,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.339 | Test Acc: 86.57%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pVcyNqGaW8Q"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def predict_sentiment(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    rev_tokenized = list(reversed(tokenized))\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in rev_tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
        "    return prediction.item()"
      ],
      "execution_count": 589,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urbjp1_2abz_",
        "outputId": "6cb46932-4af8-488a-cb38-09c0bf02053b"
      },
      "source": [
        "sentence = \"This film is terrible\"\n",
        "predict_sentiment(model, sentence)"
      ],
      "execution_count": 590,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.027619820088148117"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 590
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UXJmeQzeT5c",
        "outputId": "25efe279-f7ca-4bc6-c0c9-e99ada171af1"
      },
      "source": [
        "sentence = \"This film is awesome\"\n",
        "predict_sentiment(model, sentence)"
      ],
      "execution_count": 591,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9871930480003357"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 591
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPRbvCmhvzSI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}