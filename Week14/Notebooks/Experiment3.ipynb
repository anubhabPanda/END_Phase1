{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiment3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p9am1aey1ym"
      },
      "source": [
        "### Features of this notebook\n",
        "1. Custom Tokenizer\n",
        "2. One Cyle LR\n",
        "3. Label Smoothing Cross Entropy\n",
        "4. More Data (CoNaLa Corpus)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cWl5cbOxnvV",
        "outputId": "7a398a60-0d2a-4bd5-9866-255ae71886af"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKkIH7bnyBAR",
        "outputId": "9dc41b60-57e3-48c9-e91e-4f2a03d15ba7"
      },
      "source": [
        "%cd /content/drive/MyDrive/END/Transformer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/END/Transformer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-dzij1s3ByF"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJVyVrloxtU0"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.legacy.data import Field, BucketIterator, Example, Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from custom_losses import LabelSmoothingCrossEntropy\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from spacy.tokenizer import Tokenizer\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pygments\n",
        "from pygments.lexers import PythonLexer"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD6T3VORx-Ak"
      },
      "source": [
        "# Setting Random Seeds\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZf2qzPKyFc2",
        "outputId": "0a11ee75-91b8-49de-a64f-639a28cae3f4"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.1.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzO_Rw8w3Zli"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM7r4aI4yHrU"
      },
      "source": [
        "lines = []\n",
        "with open('english_python_data_corrected.txt', encoding='utf-8') as f:\n",
        "    for counter, line in enumerate(f):\n",
        "            lines.append(line)\n",
        "#Removing comments  \n",
        "comment_re = re.compile(r'#\\s*\\dx\\d\\s*matrix|#\\s*result|#\\s*iterate|#\\s*initialize|#\\s*Driver|#\\s*This function|#\\s*Iterate', \n",
        "                        re.IGNORECASE)\n",
        "lines = [x for x in lines if re.search(comment_re, x) is None]\n",
        "\n",
        "example_start_id = [counter for counter,_ in enumerate(lines) if (_.startswith(\"#\") or _.startswith(\" #\")) and (lines[counter-1].strip() == '')]\n",
        "training_examples = []\n",
        "for num, idx in enumerate(example_start_id):\n",
        "    if idx != example_start_id[-1]:\n",
        "        example_dict = {}\n",
        "        example = lines[example_start_id[num]:example_start_id[num+1]]\n",
        "        if (re.search(r\"#\\s*\\d\", example[0], re.IGNORECASE)) and (re.search(r\"#\", example[1], re.IGNORECASE)) is not None:\n",
        "                    example_dict['ques_prompt'] = example[1].strip()\n",
        "                    example_dict['source_code'] = \"\".join(example[2:]).strip()\n",
        "        elif re.search(r'#\\s*In\\[\\d*\\]', \"\".join(example), re.IGNORECASE) is not None:\n",
        "            continue\n",
        "        else:\n",
        "            example_dict['ques_prompt'] = example[0].strip()\n",
        "            example_dict['source_code'] = \"\".join(example[1:]).strip()\n",
        "        training_examples.append(example_dict)\n",
        "    else:\n",
        "        example_dict = {}\n",
        "        example = lines[example_start_id[num]:]\n",
        "        example_dict['ques_prompt'] = example[0].strip()\n",
        "        example_dict['source_code'] = \"\".join(example[1:]).strip()\n",
        "        training_examples.append(example_dict)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWDP2kEEyQCN"
      },
      "source": [
        "full_data = pd.DataFrame(training_examples)\n",
        "# Dropping examples where length of code was greater than 250 characters\n",
        "len_filter = full_data['source_code'].apply(lambda x:len(x) > 250)\n",
        "full_data.drop(len_filter[len_filter == True].index.tolist(), inplace = True, axis = 0)\n",
        "full_data.reset_index(drop = True, inplace = True)\n",
        "full_data['ques_prompt'] = full_data['ques_prompt'].apply(lambda x:re.sub(r'\\d*', '', x))\n",
        "full_data['ques_prompt'] = full_data['ques_prompt'].apply(lambda x:re.sub(r'(#\\s)+', '', x))\n",
        "full_data.columns = ['src', 'trg']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "UifQzF1uIx2N",
        "outputId": "29474ce6-e8fe-4086-c3ed-32d56410ae3c"
      },
      "source": [
        "full_data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>trg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>write a python program to add two numbers</td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python function to add two user provid...</td>\n",
              "      <td>def add_two_numbers(num1, num2):\\n    sum = nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a program to find and print the largest ...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &gt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a program to find and print the smallest...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Write a python function to merge two given lis...</td>\n",
              "      <td>def merge_lists(l1, l2):\\n    return l1 + l2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 src                                                trg\n",
              "0          write a python program to add two numbers  num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...\n",
              "1  write a python function to add two user provid...  def add_two_numbers(num1, num2):\\n    sum = nu...\n",
              "2  write a program to find and print the largest ...  num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 >= n...\n",
              "3  write a program to find and print the smallest...  num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <= n...\n",
              "4  Write a python function to merge two given lis...       def merge_lists(l1, l2):\\n    return l1 + l2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFDKE_6MSULD"
      },
      "source": [
        "# Incorporating CoNaLa Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4NAz4VZSSv1"
      },
      "source": [
        "conala_train = pd.read_json('/content/drive/MyDrive/END/Transformer/conala-corpus/conala-train.json')\n",
        "conala_test = pd.read_json('/content/drive/MyDrive/END/Transformer/conala-corpus/conala-test.json')\n",
        "conala_data = pd.concat([conala_train, conala_test], axis = 0)\n",
        "conala_data = conala_data[['rewritten_intent', 'snippet']].rename(columns = {'rewritten_intent': 'src', 'snippet':'trg'})\n",
        "conala_data.dropna(inplace = True)\n",
        "conala_data.reset_index(drop = True, inplace = True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3Y4jaWOSeOf"
      },
      "source": [
        "full_data = pd.concat([full_data, conala_data], axis = 0)\n",
        "full_data.reset_index(drop = True, inplace = True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdrOdQr80B3J"
      },
      "source": [
        "# Loading spacy language models for tokenization\n",
        "en_tokenizer = spacy.load('en')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqfrzvJE3wJm"
      },
      "source": [
        "# Custom Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtzXgqS6pfeQ"
      },
      "source": [
        "lexer = PythonLexer()\n",
        "def tokenize_py(text):\n",
        "    \"\"\"\n",
        "    Tokenizes Python text from a string into a list of tokens\n",
        "    \"\"\"\n",
        "    tokens_texts = lexer.get_tokens(text)\n",
        "    tokens_texts = [i[1] for i in tokens_texts if i[0] != pygments.token.Comment.Single]\n",
        "    return tokens_texts\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of tokens\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in en_tokenizer.tokenizer(text)]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQcuYk3C4XgX",
        "outputId": "585fc4e6-c741-400c-8be4-6144c1d93ad4"
      },
      "source": [
        "# Let's test our custom tokenizer\n",
        "idx = 1\n",
        "print(f'Target Sentence :\\n{full_data.iloc[idx, 1]}\\n')\n",
        "print(f'Tokens : {tokenize_py(full_data.iloc[idx, 1])}\\n',)\n",
        "print(f'Reconstructed sentence from Tokens : \\n{\"\".join(tokenize_py(full_data.iloc[idx, 1]))}\\n')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target Sentence :\n",
            "def add_two_numbers(num1, num2):\n",
            "    sum = num1 + num2\n",
            "    return sum\n",
            "\n",
            "Tokens : ['def', ' ', 'add_two_numbers', '(', 'num1', ',', ' ', 'num2', ')', ':', '\\n', '    ', 'sum', ' ', '=', ' ', 'num1', ' ', '+', ' ', 'num2', '\\n', '    ', 'return', ' ', 'sum', '\\n']\n",
            "\n",
            "Reconstructed sentence from Tokens : \n",
            "def add_two_numbers(num1, num2):\n",
            "    sum = num1 + num2\n",
            "    return sum\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4To5gq4E5oUR",
        "outputId": "3261deda-f05a-405d-d48d-7830230d24fe"
      },
      "source": [
        "idx = 1454\n",
        "print(f'Target Sentence :\\n{full_data.iloc[idx, 1]}\\n')\n",
        "print(f'Tokens : {tokenize_py(full_data.iloc[idx, 1])}\\n',)\n",
        "print(f'Reconstructed sentence from Tokens : \\n{\"\".join(tokenize_py(full_data.iloc[idx, 1]))}\\n')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target Sentence :\n",
            "test_list = [(1, 3), (1, 4), (2, 3), (3, 2), (5, 3), (6, 4)] \n",
            "res = {} \n",
            "for i, j in test_list: \n",
            "     res.setdefault(j, []).append(i) \n",
            "print(\"The dictionary converted from tuple list : \" + str(res))\n",
            "\n",
            "Tokens : ['test_list', ' ', '=', ' ', '[', '(', '1', ',', ' ', '3', ')', ',', ' ', '(', '1', ',', ' ', '4', ')', ',', ' ', '(', '2', ',', ' ', '3', ')', ',', ' ', '(', '3', ',', ' ', '2', ')', ',', ' ', '(', '5', ',', ' ', '3', ')', ',', ' ', '(', '6', ',', ' ', '4', ')', ']', ' ', '\\n', 'res', ' ', '=', ' ', '{', '}', ' ', '\\n', 'for', ' ', 'i', ',', ' ', 'j', ' ', 'in', ' ', 'test_list', ':', ' ', '\\n', '     ', 'res', '.', 'setdefault', '(', 'j', ',', ' ', '[', ']', ')', '.', 'append', '(', 'i', ')', ' ', '\\n', 'print', '(', '\"', 'The dictionary converted from tuple list : ', '\"', ' ', '+', ' ', 'str', '(', 'res', ')', ')', '\\n']\n",
            "\n",
            "Reconstructed sentence from Tokens : \n",
            "test_list = [(1, 3), (1, 4), (2, 3), (3, 2), (5, 3), (6, 4)] \n",
            "res = {} \n",
            "for i, j in test_list: \n",
            "     res.setdefault(j, []).append(i) \n",
            "print(\"The dictionary converted from tuple list : \" + str(res))\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mUtDWea5uOV"
      },
      "source": [
        "As we can see that the python code structure is maintained and proper tokenization is there for f-strings, spaces, newline, python operators and brackets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iSMa5iYJG-i"
      },
      "source": [
        "# Defining the fields\n",
        "SRC = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            batch_first = True)\n",
        "\n",
        "# lower=False since python is case sensitive language\n",
        "TRG = Field(tokenize = tokenize_py, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = False, \n",
        "            batch_first = True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX4CJzLKJXqE"
      },
      "source": [
        "# Creating torchtext dataset \n",
        "fields = [('src', SRC), ('trg', TRG)]\n",
        "examples = [Example.fromlist([full_data.src[i], full_data.trg[i]], fields) for i in range(full_data.shape[0])]\n",
        "complete_dataset = Dataset(examples, fields)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sxQcLlGMv0-"
      },
      "source": [
        "# Splitting into train, test and validation\n",
        "train_data, valid_data, test_data = complete_dataset.split(split_ratio=[0.80, 0.05, 0.15], \n",
        "                                    random_state=random.seed(SEED))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6pfjzztO-HE",
        "outputId": "3093382c-e328-4024-c114-e45881a87134"
      },
      "source": [
        "len(train_data), len(valid_data), len(test_data)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5050, 946, 316)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YhWJpg8PD8B",
        "outputId": "f23b3517-91d2-4fb2-b09e-7ad669451eda"
      },
      "source": [
        "# Let's look at a few examples from the dataset\n",
        "idx = 9\n",
        "print(''.join(vars(train_data.examples[idx])['trg']))\n",
        "print(vars(train_data.examples[idx])['trg'])\n",
        "print(len(vars(train_data.examples[idx])['trg']))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "import re\n",
            "regex = '\\.[0]*'\n",
            "def remove_leading_zeros(ip):\n",
            "    modified_ip = re.sub(regex, '.', ip)\n",
            "    return modified_ip\n",
            "\n",
            "['import', ' ', 're', '\\n', 'regex', ' ', '=', ' ', \"'\", '\\\\', '.[0]*', \"'\", '\\n', 'def', ' ', 'remove_leading_zeros', '(', 'ip', ')', ':', '\\n', '    ', 'modified_ip', ' ', '=', ' ', 're', '.', 'sub', '(', 'regex', ',', ' ', \"'\", '.', \"'\", ',', ' ', 'ip', ')', '\\n', '    ', 'return', ' ', 'modified_ip', '\\n']\n",
            "46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orcMjw5KohfG",
        "outputId": "0a82159a-7070-49a3-d8e5-b1212c841a21"
      },
      "source": [
        "idx = 0\n",
        "print(''.join(vars(train_data.examples[idx])['trg']))\n",
        "print(vars(train_data.examples[idx])['trg'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[sum([x[1] for x in i]) for i in data]\n",
            "\n",
            "['[', 'sum', '(', '[', 'x', '[', '1', ']', ' ', 'for', ' ', 'x', ' ', 'in', ' ', 'i', ']', ')', ' ', 'for', ' ', 'i', ' ', 'in', ' ', 'data', ']', '\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWATKYiJPKHY"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STmUMUnjSeFG",
        "outputId": "5cb0389f-6df6-4270-a435-a091008d720f"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = 'cpu'\n",
        "device"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eYIBgWrSkln"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), sort_key = lambda x:len(x.src), sort_within_batch = False,\n",
        "     batch_size = BATCH_SIZE,\n",
        "     device = device)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCkVjzBuTXFC"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 200):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "        \n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        "            \n",
        "        return src"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKnjbUpXTaZZ"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len] \n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ycLDCPuTf63"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmIaAPSlTl-K"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEbFPA6XTp_g"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 250):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "            \n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBHcoWU0TvW6"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "            \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "            \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        # query, key, value\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06x-eTpHTxmJ"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        \n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return output, attention"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzgmVhkoTz1D"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HID_DIM = 512\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 1024\n",
        "DEC_PF_DIM = 1024\n",
        "ENC_DROPOUT = 0.2\n",
        "DEC_DROPOUT = 0.2\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pHkV-bLT3lO"
      },
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5ku2QdmT7G6",
        "outputId": "44f93cd7-027c-4bd9-e09e-382f7e30826b"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 22,984,982 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KALu_7hxUJmP"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlaoFi4PUMpb"
      },
      "source": [
        "model.apply(initialize_weights);"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aGeLVbfUOhw"
      },
      "source": [
        "LEARNING_RATE = 0.00001\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iFH6VuIUQsN"
      },
      "source": [
        "criterion = LabelSmoothingCrossEntropy(ignore_index = TRG_PAD_IDX)\n",
        "# criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67vxplARCKWU"
      },
      "source": [
        "# One Cycle LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at_ZxwaaCIph"
      },
      "source": [
        "max_lr = 0.0001\n",
        "N_EPOCHS = 100\n",
        "max_epoch = 30\n",
        "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr,\n",
        "                                     epochs = N_EPOCHS, steps_per_epoch=1, pct_start=max_epoch/N_EPOCHS, \n",
        "                                     anneal_strategy='linear', div_factor=10.0, final_div_factor=1.0)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSeRKtvzUSRd"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "                \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "            \n",
        "        output_dim = output.shape[-1]\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "                \n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "            \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RtYKHfPUUF3"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1bzVnDHUWIR"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QpGdTj_UYtL",
        "outputId": "310aa939-8db9-408b-8bd4-d90fb95a16a7"
      },
      "source": [
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'Experiment_3.pt')\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    scheduler.step()\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 21s\n",
            "\tTrain Loss: 7.617 | Train PPL: 2031.704\n",
            "\t Val. Loss: 6.783 |  Val. PPL: 882.359\n",
            "Epoch: 02 | Time: 0m 21s\n",
            "\tTrain Loss: 6.644 | Train PPL: 768.312\n",
            "\t Val. Loss: 6.109 |  Val. PPL: 450.054\n",
            "Epoch: 03 | Time: 0m 21s\n",
            "\tTrain Loss: 5.938 | Train PPL: 379.222\n",
            "\t Val. Loss: 5.412 |  Val. PPL: 224.046\n",
            "Epoch: 04 | Time: 0m 21s\n",
            "\tTrain Loss: 5.178 | Train PPL: 177.350\n",
            "\t Val. Loss: 4.594 |  Val. PPL:  98.930\n",
            "Epoch: 05 | Time: 0m 21s\n",
            "\tTrain Loss: 4.470 | Train PPL:  87.378\n",
            "\t Val. Loss: 4.084 |  Val. PPL:  59.397\n",
            "Epoch: 06 | Time: 0m 21s\n",
            "\tTrain Loss: 4.068 | Train PPL:  58.447\n",
            "\t Val. Loss: 3.855 |  Val. PPL:  47.212\n",
            "Epoch: 07 | Time: 0m 21s\n",
            "\tTrain Loss: 3.842 | Train PPL:  46.639\n",
            "\t Val. Loss: 3.669 |  Val. PPL:  39.224\n",
            "Epoch: 08 | Time: 0m 21s\n",
            "\tTrain Loss: 3.681 | Train PPL:  39.681\n",
            "\t Val. Loss: 3.542 |  Val. PPL:  34.529\n",
            "Epoch: 09 | Time: 0m 21s\n",
            "\tTrain Loss: 3.556 | Train PPL:  35.014\n",
            "\t Val. Loss: 3.435 |  Val. PPL:  31.043\n",
            "Epoch: 10 | Time: 0m 21s\n",
            "\tTrain Loss: 3.450 | Train PPL:  31.486\n",
            "\t Val. Loss: 3.342 |  Val. PPL:  28.287\n",
            "Epoch: 11 | Time: 0m 21s\n",
            "\tTrain Loss: 3.361 | Train PPL:  28.806\n",
            "\t Val. Loss: 3.264 |  Val. PPL:  26.145\n",
            "Epoch: 12 | Time: 0m 22s\n",
            "\tTrain Loss: 3.282 | Train PPL:  26.621\n",
            "\t Val. Loss: 3.200 |  Val. PPL:  24.525\n",
            "Epoch: 13 | Time: 0m 22s\n",
            "\tTrain Loss: 3.207 | Train PPL:  24.701\n",
            "\t Val. Loss: 3.136 |  Val. PPL:  23.006\n",
            "Epoch: 14 | Time: 0m 21s\n",
            "\tTrain Loss: 3.138 | Train PPL:  23.051\n",
            "\t Val. Loss: 3.073 |  Val. PPL:  21.603\n",
            "Epoch: 15 | Time: 0m 21s\n",
            "\tTrain Loss: 3.073 | Train PPL:  21.611\n",
            "\t Val. Loss: 3.014 |  Val. PPL:  20.368\n",
            "Epoch: 16 | Time: 0m 21s\n",
            "\tTrain Loss: 3.007 | Train PPL:  20.232\n",
            "\t Val. Loss: 2.968 |  Val. PPL:  19.446\n",
            "Epoch: 17 | Time: 0m 21s\n",
            "\tTrain Loss: 2.946 | Train PPL:  19.033\n",
            "\t Val. Loss: 2.906 |  Val. PPL:  18.288\n",
            "Epoch: 18 | Time: 0m 21s\n",
            "\tTrain Loss: 2.888 | Train PPL:  17.966\n",
            "\t Val. Loss: 2.861 |  Val. PPL:  17.485\n",
            "Epoch: 19 | Time: 0m 21s\n",
            "\tTrain Loss: 2.828 | Train PPL:  16.914\n",
            "\t Val. Loss: 2.824 |  Val. PPL:  16.845\n",
            "Epoch: 20 | Time: 0m 21s\n",
            "\tTrain Loss: 2.773 | Train PPL:  16.011\n",
            "\t Val. Loss: 2.780 |  Val. PPL:  16.118\n",
            "Epoch: 21 | Time: 0m 21s\n",
            "\tTrain Loss: 2.726 | Train PPL:  15.271\n",
            "\t Val. Loss: 2.734 |  Val. PPL:  15.393\n",
            "Epoch: 22 | Time: 0m 21s\n",
            "\tTrain Loss: 2.673 | Train PPL:  14.485\n",
            "\t Val. Loss: 2.708 |  Val. PPL:  14.994\n",
            "Epoch: 23 | Time: 0m 21s\n",
            "\tTrain Loss: 2.623 | Train PPL:  13.779\n",
            "\t Val. Loss: 2.678 |  Val. PPL:  14.555\n",
            "Epoch: 24 | Time: 0m 21s\n",
            "\tTrain Loss: 2.579 | Train PPL:  13.188\n",
            "\t Val. Loss: 2.644 |  Val. PPL:  14.070\n",
            "Epoch: 25 | Time: 0m 21s\n",
            "\tTrain Loss: 2.528 | Train PPL:  12.531\n",
            "\t Val. Loss: 2.607 |  Val. PPL:  13.558\n",
            "Epoch: 26 | Time: 0m 21s\n",
            "\tTrain Loss: 2.483 | Train PPL:  11.980\n",
            "\t Val. Loss: 2.576 |  Val. PPL:  13.144\n",
            "Epoch: 27 | Time: 0m 21s\n",
            "\tTrain Loss: 2.436 | Train PPL:  11.425\n",
            "\t Val. Loss: 2.552 |  Val. PPL:  12.834\n",
            "Epoch: 28 | Time: 0m 21s\n",
            "\tTrain Loss: 2.395 | Train PPL:  10.965\n",
            "\t Val. Loss: 2.530 |  Val. PPL:  12.558\n",
            "Epoch: 29 | Time: 0m 21s\n",
            "\tTrain Loss: 2.355 | Train PPL:  10.535\n",
            "\t Val. Loss: 2.501 |  Val. PPL:  12.198\n",
            "Epoch: 30 | Time: 0m 21s\n",
            "\tTrain Loss: 2.311 | Train PPL:  10.080\n",
            "\t Val. Loss: 2.474 |  Val. PPL:  11.871\n",
            "Epoch: 31 | Time: 0m 21s\n",
            "\tTrain Loss: 2.271 | Train PPL:   9.689\n",
            "\t Val. Loss: 2.445 |  Val. PPL:  11.536\n",
            "Epoch: 32 | Time: 0m 21s\n",
            "\tTrain Loss: 2.232 | Train PPL:   9.322\n",
            "\t Val. Loss: 2.439 |  Val. PPL:  11.458\n",
            "Epoch: 33 | Time: 0m 22s\n",
            "\tTrain Loss: 2.194 | Train PPL:   8.969\n",
            "\t Val. Loss: 2.415 |  Val. PPL:  11.194\n",
            "Epoch: 34 | Time: 0m 21s\n",
            "\tTrain Loss: 2.158 | Train PPL:   8.654\n",
            "\t Val. Loss: 2.401 |  Val. PPL:  11.030\n",
            "Epoch: 35 | Time: 0m 21s\n",
            "\tTrain Loss: 2.123 | Train PPL:   8.359\n",
            "\t Val. Loss: 2.387 |  Val. PPL:  10.878\n",
            "Epoch: 36 | Time: 0m 21s\n",
            "\tTrain Loss: 2.090 | Train PPL:   8.086\n",
            "\t Val. Loss: 2.362 |  Val. PPL:  10.608\n",
            "Epoch: 37 | Time: 0m 21s\n",
            "\tTrain Loss: 2.061 | Train PPL:   7.854\n",
            "\t Val. Loss: 2.347 |  Val. PPL:  10.450\n",
            "Epoch: 38 | Time: 0m 21s\n",
            "\tTrain Loss: 2.031 | Train PPL:   7.619\n",
            "\t Val. Loss: 2.339 |  Val. PPL:  10.367\n",
            "Epoch: 39 | Time: 0m 21s\n",
            "\tTrain Loss: 2.000 | Train PPL:   7.386\n",
            "\t Val. Loss: 2.328 |  Val. PPL:  10.255\n",
            "Epoch: 40 | Time: 0m 21s\n",
            "\tTrain Loss: 1.976 | Train PPL:   7.211\n",
            "\t Val. Loss: 2.317 |  Val. PPL:  10.141\n",
            "Epoch: 41 | Time: 0m 21s\n",
            "\tTrain Loss: 1.949 | Train PPL:   7.025\n",
            "\t Val. Loss: 2.309 |  Val. PPL:  10.061\n",
            "Epoch: 42 | Time: 0m 21s\n",
            "\tTrain Loss: 1.925 | Train PPL:   6.856\n",
            "\t Val. Loss: 2.302 |  Val. PPL:   9.994\n",
            "Epoch: 43 | Time: 0m 21s\n",
            "\tTrain Loss: 1.903 | Train PPL:   6.704\n",
            "\t Val. Loss: 2.297 |  Val. PPL:   9.949\n",
            "Epoch: 44 | Time: 0m 21s\n",
            "\tTrain Loss: 1.880 | Train PPL:   6.554\n",
            "\t Val. Loss: 2.288 |  Val. PPL:   9.858\n",
            "Epoch: 45 | Time: 0m 21s\n",
            "\tTrain Loss: 1.857 | Train PPL:   6.402\n",
            "\t Val. Loss: 2.279 |  Val. PPL:   9.767\n",
            "Epoch: 46 | Time: 0m 21s\n",
            "\tTrain Loss: 1.837 | Train PPL:   6.279\n",
            "\t Val. Loss: 2.276 |  Val. PPL:   9.738\n",
            "Epoch: 47 | Time: 0m 21s\n",
            "\tTrain Loss: 1.821 | Train PPL:   6.177\n",
            "\t Val. Loss: 2.269 |  Val. PPL:   9.669\n",
            "Epoch: 48 | Time: 0m 21s\n",
            "\tTrain Loss: 1.800 | Train PPL:   6.051\n",
            "\t Val. Loss: 2.269 |  Val. PPL:   9.668\n",
            "Epoch: 49 | Time: 0m 21s\n",
            "\tTrain Loss: 1.782 | Train PPL:   5.942\n",
            "\t Val. Loss: 2.261 |  Val. PPL:   9.588\n",
            "Epoch: 50 | Time: 0m 21s\n",
            "\tTrain Loss: 1.766 | Train PPL:   5.849\n",
            "\t Val. Loss: 2.255 |  Val. PPL:   9.532\n",
            "Epoch: 51 | Time: 0m 21s\n",
            "\tTrain Loss: 1.747 | Train PPL:   5.737\n",
            "\t Val. Loss: 2.252 |  Val. PPL:   9.504\n",
            "Epoch: 52 | Time: 0m 21s\n",
            "\tTrain Loss: 1.731 | Train PPL:   5.646\n",
            "\t Val. Loss: 2.254 |  Val. PPL:   9.525\n",
            "Epoch: 53 | Time: 0m 21s\n",
            "\tTrain Loss: 1.716 | Train PPL:   5.565\n",
            "\t Val. Loss: 2.240 |  Val. PPL:   9.389\n",
            "Epoch: 54 | Time: 0m 21s\n",
            "\tTrain Loss: 1.701 | Train PPL:   5.480\n",
            "\t Val. Loss: 2.239 |  Val. PPL:   9.385\n",
            "Epoch: 55 | Time: 0m 21s\n",
            "\tTrain Loss: 1.691 | Train PPL:   5.424\n",
            "\t Val. Loss: 2.242 |  Val. PPL:   9.410\n",
            "Epoch: 56 | Time: 0m 21s\n",
            "\tTrain Loss: 1.677 | Train PPL:   5.352\n",
            "\t Val. Loss: 2.235 |  Val. PPL:   9.344\n",
            "Epoch: 57 | Time: 0m 21s\n",
            "\tTrain Loss: 1.663 | Train PPL:   5.275\n",
            "\t Val. Loss: 2.236 |  Val. PPL:   9.360\n",
            "Epoch: 58 | Time: 0m 21s\n",
            "\tTrain Loss: 1.652 | Train PPL:   5.216\n",
            "\t Val. Loss: 2.243 |  Val. PPL:   9.425\n",
            "Epoch: 59 | Time: 0m 21s\n",
            "\tTrain Loss: 1.641 | Train PPL:   5.161\n",
            "\t Val. Loss: 2.234 |  Val. PPL:   9.338\n",
            "Epoch: 60 | Time: 0m 21s\n",
            "\tTrain Loss: 1.628 | Train PPL:   5.095\n",
            "\t Val. Loss: 2.230 |  Val. PPL:   9.304\n",
            "Epoch: 61 | Time: 0m 21s\n",
            "\tTrain Loss: 1.618 | Train PPL:   5.041\n",
            "\t Val. Loss: 2.228 |  Val. PPL:   9.277\n",
            "Epoch: 62 | Time: 0m 21s\n",
            "\tTrain Loss: 1.607 | Train PPL:   4.987\n",
            "\t Val. Loss: 2.221 |  Val. PPL:   9.213\n",
            "Epoch: 63 | Time: 0m 21s\n",
            "\tTrain Loss: 1.597 | Train PPL:   4.940\n",
            "\t Val. Loss: 2.223 |  Val. PPL:   9.236\n",
            "Epoch: 64 | Time: 0m 21s\n",
            "\tTrain Loss: 1.587 | Train PPL:   4.889\n",
            "\t Val. Loss: 2.224 |  Val. PPL:   9.242\n",
            "Epoch: 65 | Time: 0m 21s\n",
            "\tTrain Loss: 1.578 | Train PPL:   4.847\n",
            "\t Val. Loss: 2.219 |  Val. PPL:   9.202\n",
            "Epoch: 66 | Time: 0m 21s\n",
            "\tTrain Loss: 1.570 | Train PPL:   4.805\n",
            "\t Val. Loss: 2.227 |  Val. PPL:   9.270\n",
            "Epoch: 67 | Time: 0m 21s\n",
            "\tTrain Loss: 1.563 | Train PPL:   4.773\n",
            "\t Val. Loss: 2.221 |  Val. PPL:   9.217\n",
            "Epoch: 68 | Time: 0m 21s\n",
            "\tTrain Loss: 1.554 | Train PPL:   4.729\n",
            "\t Val. Loss: 2.222 |  Val. PPL:   9.221\n",
            "Epoch: 69 | Time: 0m 21s\n",
            "\tTrain Loss: 1.546 | Train PPL:   4.694\n",
            "\t Val. Loss: 2.217 |  Val. PPL:   9.177\n",
            "Epoch: 70 | Time: 0m 21s\n",
            "\tTrain Loss: 1.538 | Train PPL:   4.653\n",
            "\t Val. Loss: 2.216 |  Val. PPL:   9.168\n",
            "Epoch: 71 | Time: 0m 21s\n",
            "\tTrain Loss: 1.531 | Train PPL:   4.622\n",
            "\t Val. Loss: 2.219 |  Val. PPL:   9.196\n",
            "Epoch: 72 | Time: 0m 21s\n",
            "\tTrain Loss: 1.523 | Train PPL:   4.586\n",
            "\t Val. Loss: 2.216 |  Val. PPL:   9.168\n",
            "Epoch: 73 | Time: 0m 21s\n",
            "\tTrain Loss: 1.516 | Train PPL:   4.554\n",
            "\t Val. Loss: 2.216 |  Val. PPL:   9.172\n",
            "Epoch: 74 | Time: 0m 21s\n",
            "\tTrain Loss: 1.508 | Train PPL:   4.519\n",
            "\t Val. Loss: 2.217 |  Val. PPL:   9.175\n",
            "Epoch: 75 | Time: 0m 21s\n",
            "\tTrain Loss: 1.503 | Train PPL:   4.495\n",
            "\t Val. Loss: 2.218 |  Val. PPL:   9.188\n",
            "Epoch: 76 | Time: 0m 21s\n",
            "\tTrain Loss: 1.498 | Train PPL:   4.471\n",
            "\t Val. Loss: 2.219 |  Val. PPL:   9.195\n",
            "Epoch: 77 | Time: 0m 21s\n",
            "\tTrain Loss: 1.493 | Train PPL:   4.448\n",
            "\t Val. Loss: 2.221 |  Val. PPL:   9.221\n",
            "Epoch: 78 | Time: 0m 21s\n",
            "\tTrain Loss: 1.488 | Train PPL:   4.430\n",
            "\t Val. Loss: 2.222 |  Val. PPL:   9.225\n",
            "Epoch: 79 | Time: 0m 21s\n",
            "\tTrain Loss: 1.478 | Train PPL:   4.384\n",
            "\t Val. Loss: 2.221 |  Val. PPL:   9.212\n",
            "Epoch: 80 | Time: 0m 21s\n",
            "\tTrain Loss: 1.473 | Train PPL:   4.360\n",
            "\t Val. Loss: 2.218 |  Val. PPL:   9.191\n",
            "Epoch: 81 | Time: 0m 21s\n",
            "\tTrain Loss: 1.469 | Train PPL:   4.346\n",
            "\t Val. Loss: 2.226 |  Val. PPL:   9.266\n",
            "Epoch: 82 | Time: 0m 21s\n",
            "\tTrain Loss: 1.465 | Train PPL:   4.327\n",
            "\t Val. Loss: 2.231 |  Val. PPL:   9.306\n",
            "Epoch: 83 | Time: 0m 21s\n",
            "\tTrain Loss: 1.462 | Train PPL:   4.315\n",
            "\t Val. Loss: 2.225 |  Val. PPL:   9.258\n",
            "Epoch: 84 | Time: 0m 21s\n",
            "\tTrain Loss: 1.455 | Train PPL:   4.283\n",
            "\t Val. Loss: 2.228 |  Val. PPL:   9.277\n",
            "Epoch: 85 | Time: 0m 21s\n",
            "\tTrain Loss: 1.453 | Train PPL:   4.275\n",
            "\t Val. Loss: 2.227 |  Val. PPL:   9.271\n",
            "Epoch: 86 | Time: 0m 21s\n",
            "\tTrain Loss: 1.449 | Train PPL:   4.259\n",
            "\t Val. Loss: 2.227 |  Val. PPL:   9.273\n",
            "Epoch: 87 | Time: 0m 21s\n",
            "\tTrain Loss: 1.443 | Train PPL:   4.235\n",
            "\t Val. Loss: 2.226 |  Val. PPL:   9.259\n",
            "Epoch: 88 | Time: 0m 21s\n",
            "\tTrain Loss: 1.442 | Train PPL:   4.227\n",
            "\t Val. Loss: 2.223 |  Val. PPL:   9.231\n",
            "Epoch: 89 | Time: 0m 21s\n",
            "\tTrain Loss: 1.441 | Train PPL:   4.224\n",
            "\t Val. Loss: 2.223 |  Val. PPL:   9.238\n",
            "Epoch: 90 | Time: 0m 21s\n",
            "\tTrain Loss: 1.437 | Train PPL:   4.206\n",
            "\t Val. Loss: 2.226 |  Val. PPL:   9.266\n",
            "Epoch: 91 | Time: 0m 21s\n",
            "\tTrain Loss: 1.432 | Train PPL:   4.188\n",
            "\t Val. Loss: 2.224 |  Val. PPL:   9.243\n",
            "Epoch: 92 | Time: 0m 21s\n",
            "\tTrain Loss: 1.429 | Train PPL:   4.176\n",
            "\t Val. Loss: 2.228 |  Val. PPL:   9.279\n",
            "Epoch: 93 | Time: 0m 21s\n",
            "\tTrain Loss: 1.425 | Train PPL:   4.160\n",
            "\t Val. Loss: 2.225 |  Val. PPL:   9.256\n",
            "Epoch: 94 | Time: 0m 21s\n",
            "\tTrain Loss: 1.425 | Train PPL:   4.157\n",
            "\t Val. Loss: 2.226 |  Val. PPL:   9.264\n",
            "Epoch: 95 | Time: 0m 21s\n",
            "\tTrain Loss: 1.423 | Train PPL:   4.150\n",
            "\t Val. Loss: 2.221 |  Val. PPL:   9.221\n",
            "Epoch: 96 | Time: 0m 21s\n",
            "\tTrain Loss: 1.420 | Train PPL:   4.135\n",
            "\t Val. Loss: 2.226 |  Val. PPL:   9.266\n",
            "Epoch: 97 | Time: 0m 21s\n",
            "\tTrain Loss: 1.415 | Train PPL:   4.115\n",
            "\t Val. Loss: 2.226 |  Val. PPL:   9.262\n",
            "Epoch: 98 | Time: 0m 21s\n",
            "\tTrain Loss: 1.416 | Train PPL:   4.120\n",
            "\t Val. Loss: 2.225 |  Val. PPL:   9.251\n",
            "Epoch: 99 | Time: 0m 21s\n",
            "\tTrain Loss: 1.414 | Train PPL:   4.112\n",
            "\t Val. Loss: 2.226 |  Val. PPL:   9.259\n",
            "Epoch: 100 | Time: 0m 21s\n",
            "\tTrain Loss: 1.414 | Train PPL:   4.112\n",
            "\t Val. Loss: 2.225 |  Val. PPL:   9.249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7Dty35Sf9bL",
        "outputId": "e83a2f17-946f-43e8-ab9d-b1de33a9458d"
      },
      "source": [
        "model.load_state_dict(torch.load('Experiment_3.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 2.238 | Test PPL:   9.374 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "_pmW1KVL9fIA",
        "outputId": "e26c58d0-7026-445c-b18e-8861765623ef"
      },
      "source": [
        "def plot_losses(train_losses, valid_losses):\n",
        "  fig, ax = plt.subplots(figsize = (12, 6))\n",
        "  epochs = list(range(len(train_losses)))\n",
        "  ax.plot(epochs, train_losses, label = 'train_loss', color = 'green')\n",
        "  ax.plot(epochs, valid_losses, label = 'valid_loss', color = 'red')\n",
        "  ax.legend()\n",
        "  ax.set(xlabel = 'Epochs', ylabel = 'Cross_Entropy_Loss', title = 'Variation of loss with epochs')\n",
        "\n",
        "plot_losses(train_losses, valid_losses)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_WBWxvDzPoB"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7e5Ny4dzToy"
      },
      "source": [
        "def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 8, n_cols = 1):\n",
        "    \n",
        "    assert n_rows * n_cols == n_heads\n",
        "    \n",
        "    fig = plt.figure(figsize=(200,100))\n",
        "    \n",
        "    for i in range(n_heads):\n",
        "        \n",
        "        ax = fig.add_subplot(n_rows, n_cols, i+1)\n",
        "        \n",
        "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
        "\n",
        "        cax = ax.matshow(_attention, cmap='bone')\n",
        "\n",
        "        ax.tick_params(labelsize=12)\n",
        "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
        "                           rotation=45)\n",
        "        ax.set_yticklabels(['']+translation)\n",
        "\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN50LEW3zX3F"
      },
      "source": [
        "def show_results(infer_data, example_idx):\n",
        "  src = vars(infer_data.examples[example_idx])['src']\n",
        "  trg = vars(infer_data.examples[example_idx])['trg']\n",
        "  # print(f'src = {\" \".join(src)}')\n",
        "  # print(f'trg :\\n {\" \".join(trg)}')\n",
        "\n",
        "  translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "  # print(f'predicted trg :\\n {\" \".join(translation)}')\n",
        "\n",
        "  # display_attention(src, translation, attention)\n",
        "  return \" \".join(src), \"\".join(trg), \"\".join(translation)"
      ],
      "execution_count": 63,
      "outputs": []
    }
  ]
}