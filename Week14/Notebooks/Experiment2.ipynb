{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bdc93cf837144928a3009655639e34d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_96498cf317654005b5aebd34ef3e7305",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d8f8134d01b47fcac5321f28bf29daf",
              "IPY_MODEL_3aac2d978a004f8f9cc11ecea52b51bb"
            ]
          }
        },
        "96498cf317654005b5aebd34ef3e7305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d8f8134d01b47fcac5321f28bf29daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_69300322050f4a4bab300069b7a4e06b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 177,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 177,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d456c50b8834d89bcff02ba59f9952e"
          }
        },
        "3aac2d978a004f8f9cc11ecea52b51bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4c573b7c31104d9fb6e7f4d3a801bdc5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 177/177 [00:35&lt;00:00,  4.95it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_197d5d6b7c5546cd95d289b9feb5e295"
          }
        },
        "69300322050f4a4bab300069b7a4e06b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d456c50b8834d89bcff02ba59f9952e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c573b7c31104d9fb6e7f4d3a801bdc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "197d5d6b7c5546cd95d289b9feb5e295": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p9am1aey1ym"
      },
      "source": [
        "### Features of this notebook\n",
        "1. Custom Tokenizer\n",
        "2. One Cyle LR\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cWl5cbOxnvV",
        "outputId": "fa1f05e2-184e-4654-9c2f-1d75e1a9b96c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKkIH7bnyBAR",
        "outputId": "3f608109-28d1-4669-ab42-9bc24ef67c9e"
      },
      "source": [
        "%cd /content/drive/MyDrive/END/Transformer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/END/Transformer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc2IFI5Rqxqd"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Picasso')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-dzij1s3ByF"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJVyVrloxtU0"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.legacy.data import Field, BucketIterator, Example, Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from main_engine import lr_finder, schedulers\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from spacy.tokenizer import Tokenizer\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pygments\n",
        "from pygments.lexers import PythonLexer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD6T3VORx-Ak"
      },
      "source": [
        "# Setting Random Seeds\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZf2qzPKyFc2",
        "outputId": "aba4504c-c9d0-411e-a70a-56aa84b23a01"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2mâœ” Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzO_Rw8w3Zli"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM7r4aI4yHrU"
      },
      "source": [
        "lines = []\n",
        "with open('english_python_data_corrected.txt', encoding='utf-8') as f:\n",
        "    for counter, line in enumerate(f):\n",
        "            lines.append(line)\n",
        "#Removing comments  \n",
        "comment_re = re.compile(r'#\\s*\\dx\\d\\s*matrix|#\\s*result|#\\s*iterate|#\\s*initialize|#\\s*Driver|#\\s*This function|#\\s*Iterate', \n",
        "                        re.IGNORECASE)\n",
        "lines = [x for x in lines if re.search(comment_re, x) is None]\n",
        "\n",
        "example_start_id = [counter for counter,_ in enumerate(lines) if (_.startswith(\"#\") or _.startswith(\" #\")) and (lines[counter-1].strip() == '')]\n",
        "training_examples = []\n",
        "for num, idx in enumerate(example_start_id):\n",
        "    if idx != example_start_id[-1]:\n",
        "        example_dict = {}\n",
        "        example = lines[example_start_id[num]:example_start_id[num+1]]\n",
        "        if (re.search(r\"#\\s*\\d\", example[0], re.IGNORECASE)) and (re.search(r\"#\", example[1], re.IGNORECASE)) is not None:\n",
        "                    example_dict['ques_prompt'] = example[1].strip()\n",
        "                    example_dict['source_code'] = \"\".join(example[2:]).strip()\n",
        "        elif re.search(r'#\\s*In\\[\\d*\\]', \"\".join(example), re.IGNORECASE) is not None:\n",
        "            continue\n",
        "        else:\n",
        "            example_dict['ques_prompt'] = example[0].strip()\n",
        "            example_dict['source_code'] = \"\".join(example[1:]).strip()\n",
        "        training_examples.append(example_dict)\n",
        "    else:\n",
        "        example_dict = {}\n",
        "        example = lines[example_start_id[num]:]\n",
        "        example_dict['ques_prompt'] = example[0].strip()\n",
        "        example_dict['source_code'] = \"\".join(example[1:]).strip()\n",
        "        training_examples.append(example_dict)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWDP2kEEyQCN"
      },
      "source": [
        "full_data = pd.DataFrame(training_examples)\n",
        "# Dropping examples where length of code was greater than 250 characters\n",
        "len_filter = full_data['source_code'].apply(lambda x:len(x) > 250)\n",
        "full_data.drop(len_filter[len_filter == True].index.tolist(), inplace = True, axis = 0)\n",
        "full_data.reset_index(drop = True, inplace = True)\n",
        "full_data['ques_prompt'] = full_data['ques_prompt'].apply(lambda x:re.sub(r'\\d*', '', x))\n",
        "full_data['ques_prompt'] = full_data['ques_prompt'].apply(lambda x:re.sub(r'(#\\s)+', '', x))\n",
        "full_data.columns = ['src', 'trg']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "UifQzF1uIx2N",
        "outputId": "f4a4cb48-e04f-4785-abe7-3207cf1f9df5"
      },
      "source": [
        "full_data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>trg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>write a python program to add two numbers</td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python function to add two user provid...</td>\n",
              "      <td>def add_two_numbers(num1, num2):\\n    sum = nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a program to find and print the largest ...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &gt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a program to find and print the smallest...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Write a python function to merge two given lis...</td>\n",
              "      <td>def merge_lists(l1, l2):\\n    return l1 + l2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 src                                                trg\n",
              "0          write a python program to add two numbers  num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...\n",
              "1  write a python function to add two user provid...  def add_two_numbers(num1, num2):\\n    sum = nu...\n",
              "2  write a program to find and print the largest ...  num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 >= n...\n",
              "3  write a program to find and print the smallest...  num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <= n...\n",
              "4  Write a python function to merge two given lis...       def merge_lists(l1, l2):\\n    return l1 + l2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdrOdQr80B3J"
      },
      "source": [
        "# Loading spacy language models for tokenization\n",
        "en_tokenizer = spacy.load('en')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqfrzvJE3wJm"
      },
      "source": [
        "# Custom Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtzXgqS6pfeQ"
      },
      "source": [
        "lexer = PythonLexer()\n",
        "def tokenize_py(text):\n",
        "    \"\"\"\n",
        "    Tokenizes Python text from a string into a list of tokens\n",
        "    \"\"\"\n",
        "    tokens_texts = lexer.get_tokens(text)\n",
        "    tokens_texts = [i[1] for i in tokens_texts if i[0] != pygments.token.Comment.Single]\n",
        "    return tokens_texts\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of tokens\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in en_tokenizer.tokenizer(text)]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQcuYk3C4XgX",
        "outputId": "c796d5b5-f691-4e1e-98d4-e8bc4cd5140f"
      },
      "source": [
        "# Let's test our custom tokenizer\n",
        "idx = 1\n",
        "print(f'Target Sentence :\\n{full_data.iloc[idx, 1]}\\n')\n",
        "print(f'Tokens : {tokenize_py(full_data.iloc[idx, 1])}\\n',)\n",
        "print(f'Reconstructed sentence from Tokens : \\n{\"\".join(tokenize_py(full_data.iloc[idx, 1]))}\\n')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target Sentence :\n",
            "def add_two_numbers(num1, num2):\n",
            "    sum = num1 + num2\n",
            "    return sum\n",
            "\n",
            "Tokens : ['def', ' ', 'add_two_numbers', '(', 'num1', ',', ' ', 'num2', ')', ':', '\\n', '    ', 'sum', ' ', '=', ' ', 'num1', ' ', '+', ' ', 'num2', '\\n', '    ', 'return', ' ', 'sum', '\\n']\n",
            "\n",
            "Reconstructed sentence from Tokens : \n",
            "def add_two_numbers(num1, num2):\n",
            "    sum = num1 + num2\n",
            "    return sum\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4To5gq4E5oUR",
        "outputId": "610ee329-2e29-4c64-ade7-90edb4cb3882"
      },
      "source": [
        "idx = 1454\n",
        "print(f'Target Sentence :\\n{full_data.iloc[idx, 1]}\\n')\n",
        "print(f'Tokens : {tokenize_py(full_data.iloc[idx, 1])}\\n',)\n",
        "print(f'Reconstructed sentence from Tokens : \\n{\"\".join(tokenize_py(full_data.iloc[idx, 1]))}\\n')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target Sentence :\n",
            "test_list = [(1, 3), (1, 4), (2, 3), (3, 2), (5, 3), (6, 4)] \n",
            "res = {} \n",
            "for i, j in test_list: \n",
            "     res.setdefault(j, []).append(i) \n",
            "print(\"The dictionary converted from tuple list : \" + str(res))\n",
            "\n",
            "Tokens : ['test_list', ' ', '=', ' ', '[', '(', '1', ',', ' ', '3', ')', ',', ' ', '(', '1', ',', ' ', '4', ')', ',', ' ', '(', '2', ',', ' ', '3', ')', ',', ' ', '(', '3', ',', ' ', '2', ')', ',', ' ', '(', '5', ',', ' ', '3', ')', ',', ' ', '(', '6', ',', ' ', '4', ')', ']', ' ', '\\n', 'res', ' ', '=', ' ', '{', '}', ' ', '\\n', 'for', ' ', 'i', ',', ' ', 'j', ' ', 'in', ' ', 'test_list', ':', ' ', '\\n', '     ', 'res', '.', 'setdefault', '(', 'j', ',', ' ', '[', ']', ')', '.', 'append', '(', 'i', ')', ' ', '\\n', 'print', '(', '\"', 'The dictionary converted from tuple list : ', '\"', ' ', '+', ' ', 'str', '(', 'res', ')', ')', '\\n']\n",
            "\n",
            "Reconstructed sentence from Tokens : \n",
            "test_list = [(1, 3), (1, 4), (2, 3), (3, 2), (5, 3), (6, 4)] \n",
            "res = {} \n",
            "for i, j in test_list: \n",
            "     res.setdefault(j, []).append(i) \n",
            "print(\"The dictionary converted from tuple list : \" + str(res))\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mUtDWea5uOV"
      },
      "source": [
        "As we can see that the python code structure is maintained and proper tokenization is there for f-strings, spaces, newline, python operators and brackets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iSMa5iYJG-i"
      },
      "source": [
        "# Defining the fields\n",
        "SRC = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            batch_first = True)\n",
        "\n",
        "# lower=False since python is case sensitive language\n",
        "TRG = Field(tokenize = tokenize_py, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = False, \n",
        "            batch_first = True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX4CJzLKJXqE"
      },
      "source": [
        "# Creating torchtext dataset \n",
        "fields = [('src', SRC), ('trg', TRG)]\n",
        "examples = [Example.fromlist([full_data.src[i], full_data.trg[i]], fields) for i in range(full_data.shape[0])]\n",
        "complete_dataset = Dataset(examples, fields)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sxQcLlGMv0-"
      },
      "source": [
        "# Splitting into train, test and validation\n",
        "train_data, valid_data, test_data = complete_dataset.split(split_ratio=[0.80, 0.05, 0.15], \n",
        "                                    random_state=random.seed(SEED))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6pfjzztO-HE",
        "outputId": "b2b482ee-1e02-4158-ac8d-2b2ef5fee744"
      },
      "source": [
        "len(train_data), len(valid_data), len(test_data)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2828, 530, 177)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YhWJpg8PD8B",
        "outputId": "fb62c495-2dde-4f57-a470-0f506326c044"
      },
      "source": [
        "# Let's look at a few examples from the dataset\n",
        "idx = 9\n",
        "print(''.join(vars(train_data.examples[idx])['trg']))\n",
        "print(vars(train_data.examples[idx])['trg'])\n",
        "print(len(vars(train_data.examples[idx])['trg']))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence = 'The Quick 123 Fox'\n",
            "digits = 0\n",
            "letters = 0\n",
            "for c in sentence:\n",
            "   if c.isdigit():\n",
            "      digits += 1\n",
            "   elif c.isalpha():\n",
            "      letters += 1\n",
            "   else:\n",
            "      pass\n",
            "print(f'Digits: {digits}, Letters: {letters}')\n",
            "\n",
            "['sentence', ' ', '=', ' ', \"'\", 'The Quick 123 Fox', \"'\", '\\n', 'digits', ' ', '=', ' ', '0', '\\n', 'letters', ' ', '=', ' ', '0', '\\n', 'for', ' ', 'c', ' ', 'in', ' ', 'sentence', ':', '\\n', '   ', 'if', ' ', 'c', '.', 'isdigit', '(', ')', ':', '\\n', '      ', 'digits', ' ', '+', '=', ' ', '1', '\\n', '   ', 'elif', ' ', 'c', '.', 'isalpha', '(', ')', ':', '\\n', '      ', 'letters', ' ', '+', '=', ' ', '1', '\\n', '   ', 'else', ':', '\\n', '      ', 'pass', '\\n', 'print', '(', 'f', \"'\", 'Digits: ', '{', 'digits', '}', ', Letters: ', '{', 'letters', '}', \"'\", ')', '\\n']\n",
            "87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orcMjw5KohfG",
        "outputId": "7f7ee916-03ef-483a-f3df-15799380cf90"
      },
      "source": [
        "idx = 0\n",
        "print(''.join(vars(train_data.examples[idx])['trg']))\n",
        "print(vars(train_data.examples[idx])['trg'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word = \"Hello World\"\n",
            "replace = \"Bye\"\n",
            "input = \"Hello\"\n",
            "after_replace = word.replace(input, replace)\n",
            "print(f\"String ater replacement: {after_replace}\")\n",
            "\n",
            "['word', ' ', '=', ' ', '\"', 'Hello World', '\"', '\\n', 'replace', ' ', '=', ' ', '\"', 'Bye', '\"', '\\n', 'input', ' ', '=', ' ', '\"', 'Hello', '\"', '\\n', 'after_replace', ' ', '=', ' ', 'word', '.', 'replace', '(', 'input', ',', ' ', 'replace', ')', '\\n', 'print', '(', 'f', '\"', 'String ater replacement: ', '{', 'after_replace', '}', '\"', ')', '\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWATKYiJPKHY"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STmUMUnjSeFG",
        "outputId": "22509ad0-d399-40b4-8626-e3c798950361"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = 'cpu'\n",
        "device"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eYIBgWrSkln"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), sort_key = lambda x:len(x.src), sort_within_batch = False,\n",
        "     batch_size = BATCH_SIZE,\n",
        "     device = device)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCkVjzBuTXFC"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 200):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "        \n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        "            \n",
        "        return src"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKnjbUpXTaZZ"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len] \n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ycLDCPuTf63"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmIaAPSlTl-K"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEbFPA6XTp_g"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 250):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "            \n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBHcoWU0TvW6"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "            \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "            \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        # query, key, value\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06x-eTpHTxmJ"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        \n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return output, attention"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzgmVhkoTz1D"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HID_DIM = 512\n",
        "ENC_LAYERS = 4\n",
        "DEC_LAYERS = 4\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 1024\n",
        "DEC_PF_DIM = 1024\n",
        "ENC_DROPOUT = 0.2\n",
        "DEC_DROPOUT = 0.2\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pHkV-bLT3lO"
      },
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5ku2QdmT7G6",
        "outputId": "7824d22a-f537-417d-fdf6-579e904f3c43"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 25,676,464 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KALu_7hxUJmP"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlaoFi4PUMpb"
      },
      "source": [
        "model.apply(initialize_weights);"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aGeLVbfUOhw"
      },
      "source": [
        "LEARNING_RATE = 0.00001\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iFH6VuIUQsN"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67vxplARCKWU"
      },
      "source": [
        "# One Cycle LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at_ZxwaaCIph"
      },
      "source": [
        "max_lr = 0.0001\n",
        "N_EPOCHS = 100\n",
        "max_epoch = 30\n",
        "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr,\n",
        "                                     epochs = N_EPOCHS, steps_per_epoch=1, pct_start=max_epoch/N_EPOCHS, \n",
        "                                     anneal_strategy='linear', div_factor=10.0, final_div_factor=1.0)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSeRKtvzUSRd"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "                \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "            \n",
        "        output_dim = output.shape[-1]\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "                \n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "            \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RtYKHfPUUF3"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1bzVnDHUWIR"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QpGdTj_UYtL",
        "outputId": "311f1e7e-aa91-490d-9340-cfd9af6a9ba2"
      },
      "source": [
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'Experiment_2.pt')\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    scheduler.step()\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 14s\n",
            "\tTrain Loss: 7.150 | Train PPL: 1273.543\n",
            "\t Val. Loss: 6.163 |  Val. PPL: 474.794\n",
            "Epoch: 02 | Time: 0m 14s\n",
            "\tTrain Loss: 6.066 | Train PPL: 430.767\n",
            "\t Val. Loss: 5.589 |  Val. PPL: 267.443\n",
            "Epoch: 03 | Time: 0m 14s\n",
            "\tTrain Loss: 5.549 | Train PPL: 256.974\n",
            "\t Val. Loss: 5.154 |  Val. PPL: 173.067\n",
            "Epoch: 04 | Time: 0m 15s\n",
            "\tTrain Loss: 5.072 | Train PPL: 159.480\n",
            "\t Val. Loss: 4.677 |  Val. PPL: 107.472\n",
            "Epoch: 05 | Time: 0m 14s\n",
            "\tTrain Loss: 4.532 | Train PPL:  92.968\n",
            "\t Val. Loss: 3.987 |  Val. PPL:  53.885\n",
            "Epoch: 06 | Time: 0m 14s\n",
            "\tTrain Loss: 3.933 | Train PPL:  51.051\n",
            "\t Val. Loss: 3.551 |  Val. PPL:  34.842\n",
            "Epoch: 07 | Time: 0m 14s\n",
            "\tTrain Loss: 3.520 | Train PPL:  33.771\n",
            "\t Val. Loss: 3.273 |  Val. PPL:  26.394\n",
            "Epoch: 08 | Time: 0m 14s\n",
            "\tTrain Loss: 3.271 | Train PPL:  26.340\n",
            "\t Val. Loss: 3.104 |  Val. PPL:  22.277\n",
            "Epoch: 09 | Time: 0m 14s\n",
            "\tTrain Loss: 3.103 | Train PPL:  22.261\n",
            "\t Val. Loss: 2.961 |  Val. PPL:  19.309\n",
            "Epoch: 10 | Time: 0m 14s\n",
            "\tTrain Loss: 2.970 | Train PPL:  19.494\n",
            "\t Val. Loss: 2.838 |  Val. PPL:  17.086\n",
            "Epoch: 11 | Time: 0m 14s\n",
            "\tTrain Loss: 2.844 | Train PPL:  17.177\n",
            "\t Val. Loss: 2.738 |  Val. PPL:  15.453\n",
            "Epoch: 12 | Time: 0m 14s\n",
            "\tTrain Loss: 2.740 | Train PPL:  15.492\n",
            "\t Val. Loss: 2.647 |  Val. PPL:  14.116\n",
            "Epoch: 13 | Time: 0m 14s\n",
            "\tTrain Loss: 2.648 | Train PPL:  14.131\n",
            "\t Val. Loss: 2.575 |  Val. PPL:  13.133\n",
            "Epoch: 14 | Time: 0m 14s\n",
            "\tTrain Loss: 2.565 | Train PPL:  12.996\n",
            "\t Val. Loss: 2.516 |  Val. PPL:  12.375\n",
            "Epoch: 15 | Time: 0m 14s\n",
            "\tTrain Loss: 2.492 | Train PPL:  12.084\n",
            "\t Val. Loss: 2.434 |  Val. PPL:  11.400\n",
            "Epoch: 16 | Time: 0m 14s\n",
            "\tTrain Loss: 2.417 | Train PPL:  11.215\n",
            "\t Val. Loss: 2.370 |  Val. PPL:  10.696\n",
            "Epoch: 17 | Time: 0m 14s\n",
            "\tTrain Loss: 2.346 | Train PPL:  10.442\n",
            "\t Val. Loss: 2.313 |  Val. PPL:  10.104\n",
            "Epoch: 18 | Time: 0m 14s\n",
            "\tTrain Loss: 2.278 | Train PPL:   9.756\n",
            "\t Val. Loss: 2.263 |  Val. PPL:   9.614\n",
            "Epoch: 19 | Time: 0m 14s\n",
            "\tTrain Loss: 2.212 | Train PPL:   9.138\n",
            "\t Val. Loss: 2.209 |  Val. PPL:   9.108\n",
            "Epoch: 20 | Time: 0m 14s\n",
            "\tTrain Loss: 2.152 | Train PPL:   8.600\n",
            "\t Val. Loss: 2.168 |  Val. PPL:   8.741\n",
            "Epoch: 21 | Time: 0m 14s\n",
            "\tTrain Loss: 2.091 | Train PPL:   8.096\n",
            "\t Val. Loss: 2.106 |  Val. PPL:   8.216\n",
            "Epoch: 22 | Time: 0m 14s\n",
            "\tTrain Loss: 2.025 | Train PPL:   7.576\n",
            "\t Val. Loss: 2.058 |  Val. PPL:   7.828\n",
            "Epoch: 23 | Time: 0m 14s\n",
            "\tTrain Loss: 1.967 | Train PPL:   7.151\n",
            "\t Val. Loss: 2.012 |  Val. PPL:   7.477\n",
            "Epoch: 24 | Time: 0m 14s\n",
            "\tTrain Loss: 1.914 | Train PPL:   6.783\n",
            "\t Val. Loss: 1.975 |  Val. PPL:   7.204\n",
            "Epoch: 25 | Time: 0m 14s\n",
            "\tTrain Loss: 1.858 | Train PPL:   6.412\n",
            "\t Val. Loss: 1.918 |  Val. PPL:   6.809\n",
            "Epoch: 26 | Time: 0m 14s\n",
            "\tTrain Loss: 1.807 | Train PPL:   6.091\n",
            "\t Val. Loss: 1.879 |  Val. PPL:   6.547\n",
            "Epoch: 27 | Time: 0m 14s\n",
            "\tTrain Loss: 1.753 | Train PPL:   5.770\n",
            "\t Val. Loss: 1.848 |  Val. PPL:   6.349\n",
            "Epoch: 28 | Time: 0m 14s\n",
            "\tTrain Loss: 1.698 | Train PPL:   5.462\n",
            "\t Val. Loss: 1.795 |  Val. PPL:   6.021\n",
            "Epoch: 29 | Time: 0m 14s\n",
            "\tTrain Loss: 1.655 | Train PPL:   5.232\n",
            "\t Val. Loss: 1.783 |  Val. PPL:   5.946\n",
            "Epoch: 30 | Time: 0m 14s\n",
            "\tTrain Loss: 1.608 | Train PPL:   4.995\n",
            "\t Val. Loss: 1.756 |  Val. PPL:   5.788\n",
            "Epoch: 31 | Time: 0m 14s\n",
            "\tTrain Loss: 1.562 | Train PPL:   4.767\n",
            "\t Val. Loss: 1.719 |  Val. PPL:   5.581\n",
            "Epoch: 32 | Time: 0m 14s\n",
            "\tTrain Loss: 1.511 | Train PPL:   4.529\n",
            "\t Val. Loss: 1.688 |  Val. PPL:   5.406\n",
            "Epoch: 33 | Time: 0m 14s\n",
            "\tTrain Loss: 1.472 | Train PPL:   4.359\n",
            "\t Val. Loss: 1.660 |  Val. PPL:   5.260\n",
            "Epoch: 34 | Time: 0m 14s\n",
            "\tTrain Loss: 1.428 | Train PPL:   4.169\n",
            "\t Val. Loss: 1.626 |  Val. PPL:   5.083\n",
            "Epoch: 35 | Time: 0m 14s\n",
            "\tTrain Loss: 1.390 | Train PPL:   4.014\n",
            "\t Val. Loss: 1.612 |  Val. PPL:   5.015\n",
            "Epoch: 36 | Time: 0m 14s\n",
            "\tTrain Loss: 1.349 | Train PPL:   3.853\n",
            "\t Val. Loss: 1.574 |  Val. PPL:   4.828\n",
            "Epoch: 37 | Time: 0m 14s\n",
            "\tTrain Loss: 1.313 | Train PPL:   3.716\n",
            "\t Val. Loss: 1.559 |  Val. PPL:   4.752\n",
            "Epoch: 38 | Time: 0m 14s\n",
            "\tTrain Loss: 1.279 | Train PPL:   3.594\n",
            "\t Val. Loss: 1.534 |  Val. PPL:   4.635\n",
            "Epoch: 39 | Time: 0m 14s\n",
            "\tTrain Loss: 1.242 | Train PPL:   3.464\n",
            "\t Val. Loss: 1.513 |  Val. PPL:   4.540\n",
            "Epoch: 40 | Time: 0m 14s\n",
            "\tTrain Loss: 1.211 | Train PPL:   3.358\n",
            "\t Val. Loss: 1.517 |  Val. PPL:   4.559\n",
            "Epoch: 41 | Time: 0m 14s\n",
            "\tTrain Loss: 1.189 | Train PPL:   3.282\n",
            "\t Val. Loss: 1.471 |  Val. PPL:   4.354\n",
            "Epoch: 42 | Time: 0m 14s\n",
            "\tTrain Loss: 1.155 | Train PPL:   3.175\n",
            "\t Val. Loss: 1.471 |  Val. PPL:   4.355\n",
            "Epoch: 43 | Time: 0m 14s\n",
            "\tTrain Loss: 1.133 | Train PPL:   3.105\n",
            "\t Val. Loss: 1.446 |  Val. PPL:   4.245\n",
            "Epoch: 44 | Time: 0m 14s\n",
            "\tTrain Loss: 1.097 | Train PPL:   2.995\n",
            "\t Val. Loss: 1.444 |  Val. PPL:   4.238\n",
            "Epoch: 45 | Time: 0m 14s\n",
            "\tTrain Loss: 1.076 | Train PPL:   2.933\n",
            "\t Val. Loss: 1.426 |  Val. PPL:   4.163\n",
            "Epoch: 46 | Time: 0m 14s\n",
            "\tTrain Loss: 1.046 | Train PPL:   2.845\n",
            "\t Val. Loss: 1.419 |  Val. PPL:   4.134\n",
            "Epoch: 47 | Time: 0m 14s\n",
            "\tTrain Loss: 1.028 | Train PPL:   2.796\n",
            "\t Val. Loss: 1.412 |  Val. PPL:   4.104\n",
            "Epoch: 48 | Time: 0m 14s\n",
            "\tTrain Loss: 1.009 | Train PPL:   2.744\n",
            "\t Val. Loss: 1.396 |  Val. PPL:   4.040\n",
            "Epoch: 49 | Time: 0m 14s\n",
            "\tTrain Loss: 0.985 | Train PPL:   2.678\n",
            "\t Val. Loss: 1.371 |  Val. PPL:   3.938\n",
            "Epoch: 50 | Time: 0m 14s\n",
            "\tTrain Loss: 0.961 | Train PPL:   2.614\n",
            "\t Val. Loss: 1.379 |  Val. PPL:   3.970\n",
            "Epoch: 51 | Time: 0m 14s\n",
            "\tTrain Loss: 0.941 | Train PPL:   2.562\n",
            "\t Val. Loss: 1.369 |  Val. PPL:   3.932\n",
            "Epoch: 52 | Time: 0m 14s\n",
            "\tTrain Loss: 0.922 | Train PPL:   2.515\n",
            "\t Val. Loss: 1.356 |  Val. PPL:   3.880\n",
            "Epoch: 53 | Time: 0m 14s\n",
            "\tTrain Loss: 0.905 | Train PPL:   2.472\n",
            "\t Val. Loss: 1.339 |  Val. PPL:   3.814\n",
            "Epoch: 54 | Time: 0m 14s\n",
            "\tTrain Loss: 0.889 | Train PPL:   2.433\n",
            "\t Val. Loss: 1.345 |  Val. PPL:   3.838\n",
            "Epoch: 55 | Time: 0m 14s\n",
            "\tTrain Loss: 0.870 | Train PPL:   2.388\n",
            "\t Val. Loss: 1.338 |  Val. PPL:   3.810\n",
            "Epoch: 56 | Time: 0m 14s\n",
            "\tTrain Loss: 0.848 | Train PPL:   2.335\n",
            "\t Val. Loss: 1.329 |  Val. PPL:   3.776\n",
            "Epoch: 57 | Time: 0m 14s\n",
            "\tTrain Loss: 0.837 | Train PPL:   2.310\n",
            "\t Val. Loss: 1.325 |  Val. PPL:   3.762\n",
            "Epoch: 58 | Time: 0m 14s\n",
            "\tTrain Loss: 0.819 | Train PPL:   2.269\n",
            "\t Val. Loss: 1.320 |  Val. PPL:   3.745\n",
            "Epoch: 59 | Time: 0m 14s\n",
            "\tTrain Loss: 0.808 | Train PPL:   2.244\n",
            "\t Val. Loss: 1.313 |  Val. PPL:   3.716\n",
            "Epoch: 60 | Time: 0m 14s\n",
            "\tTrain Loss: 0.791 | Train PPL:   2.205\n",
            "\t Val. Loss: 1.296 |  Val. PPL:   3.653\n",
            "Epoch: 61 | Time: 0m 14s\n",
            "\tTrain Loss: 0.780 | Train PPL:   2.182\n",
            "\t Val. Loss: 1.300 |  Val. PPL:   3.669\n",
            "Epoch: 62 | Time: 0m 14s\n",
            "\tTrain Loss: 0.763 | Train PPL:   2.145\n",
            "\t Val. Loss: 1.294 |  Val. PPL:   3.646\n",
            "Epoch: 63 | Time: 0m 14s\n",
            "\tTrain Loss: 0.752 | Train PPL:   2.121\n",
            "\t Val. Loss: 1.298 |  Val. PPL:   3.664\n",
            "Epoch: 64 | Time: 0m 14s\n",
            "\tTrain Loss: 0.740 | Train PPL:   2.097\n",
            "\t Val. Loss: 1.285 |  Val. PPL:   3.613\n",
            "Epoch: 65 | Time: 0m 14s\n",
            "\tTrain Loss: 0.729 | Train PPL:   2.073\n",
            "\t Val. Loss: 1.286 |  Val. PPL:   3.618\n",
            "Epoch: 66 | Time: 0m 14s\n",
            "\tTrain Loss: 0.714 | Train PPL:   2.043\n",
            "\t Val. Loss: 1.287 |  Val. PPL:   3.621\n",
            "Epoch: 67 | Time: 0m 14s\n",
            "\tTrain Loss: 0.702 | Train PPL:   2.018\n",
            "\t Val. Loss: 1.277 |  Val. PPL:   3.585\n",
            "Epoch: 68 | Time: 0m 14s\n",
            "\tTrain Loss: 0.698 | Train PPL:   2.009\n",
            "\t Val. Loss: 1.284 |  Val. PPL:   3.611\n",
            "Epoch: 69 | Time: 0m 14s\n",
            "\tTrain Loss: 0.684 | Train PPL:   1.981\n",
            "\t Val. Loss: 1.280 |  Val. PPL:   3.596\n",
            "Epoch: 70 | Time: 0m 14s\n",
            "\tTrain Loss: 0.674 | Train PPL:   1.962\n",
            "\t Val. Loss: 1.275 |  Val. PPL:   3.578\n",
            "Epoch: 71 | Time: 0m 14s\n",
            "\tTrain Loss: 0.665 | Train PPL:   1.945\n",
            "\t Val. Loss: 1.273 |  Val. PPL:   3.572\n",
            "Epoch: 72 | Time: 0m 14s\n",
            "\tTrain Loss: 0.656 | Train PPL:   1.926\n",
            "\t Val. Loss: 1.265 |  Val. PPL:   3.542\n",
            "Epoch: 73 | Time: 0m 14s\n",
            "\tTrain Loss: 0.648 | Train PPL:   1.912\n",
            "\t Val. Loss: 1.269 |  Val. PPL:   3.558\n",
            "Epoch: 74 | Time: 0m 14s\n",
            "\tTrain Loss: 0.642 | Train PPL:   1.901\n",
            "\t Val. Loss: 1.264 |  Val. PPL:   3.540\n",
            "Epoch: 75 | Time: 0m 14s\n",
            "\tTrain Loss: 0.632 | Train PPL:   1.881\n",
            "\t Val. Loss: 1.263 |  Val. PPL:   3.535\n",
            "Epoch: 76 | Time: 0m 14s\n",
            "\tTrain Loss: 0.622 | Train PPL:   1.863\n",
            "\t Val. Loss: 1.259 |  Val. PPL:   3.523\n",
            "Epoch: 77 | Time: 0m 14s\n",
            "\tTrain Loss: 0.617 | Train PPL:   1.853\n",
            "\t Val. Loss: 1.255 |  Val. PPL:   3.508\n",
            "Epoch: 78 | Time: 0m 14s\n",
            "\tTrain Loss: 0.607 | Train PPL:   1.834\n",
            "\t Val. Loss: 1.260 |  Val. PPL:   3.525\n",
            "Epoch: 79 | Time: 0m 14s\n",
            "\tTrain Loss: 0.603 | Train PPL:   1.827\n",
            "\t Val. Loss: 1.257 |  Val. PPL:   3.515\n",
            "Epoch: 80 | Time: 0m 14s\n",
            "\tTrain Loss: 0.597 | Train PPL:   1.817\n",
            "\t Val. Loss: 1.258 |  Val. PPL:   3.519\n",
            "Epoch: 81 | Time: 0m 14s\n",
            "\tTrain Loss: 0.589 | Train PPL:   1.801\n",
            "\t Val. Loss: 1.260 |  Val. PPL:   3.527\n",
            "Epoch: 82 | Time: 0m 14s\n",
            "\tTrain Loss: 0.585 | Train PPL:   1.794\n",
            "\t Val. Loss: 1.256 |  Val. PPL:   3.511\n",
            "Epoch: 83 | Time: 0m 14s\n",
            "\tTrain Loss: 0.576 | Train PPL:   1.779\n",
            "\t Val. Loss: 1.257 |  Val. PPL:   3.514\n",
            "Epoch: 84 | Time: 0m 14s\n",
            "\tTrain Loss: 0.570 | Train PPL:   1.768\n",
            "\t Val. Loss: 1.256 |  Val. PPL:   3.512\n",
            "Epoch: 85 | Time: 0m 14s\n",
            "\tTrain Loss: 0.566 | Train PPL:   1.762\n",
            "\t Val. Loss: 1.256 |  Val. PPL:   3.510\n",
            "Epoch: 86 | Time: 0m 14s\n",
            "\tTrain Loss: 0.560 | Train PPL:   1.750\n",
            "\t Val. Loss: 1.260 |  Val. PPL:   3.525\n",
            "Epoch: 87 | Time: 0m 14s\n",
            "\tTrain Loss: 0.555 | Train PPL:   1.743\n",
            "\t Val. Loss: 1.251 |  Val. PPL:   3.492\n",
            "Epoch: 88 | Time: 0m 14s\n",
            "\tTrain Loss: 0.551 | Train PPL:   1.736\n",
            "\t Val. Loss: 1.258 |  Val. PPL:   3.519\n",
            "Epoch: 89 | Time: 0m 14s\n",
            "\tTrain Loss: 0.548 | Train PPL:   1.729\n",
            "\t Val. Loss: 1.253 |  Val. PPL:   3.502\n",
            "Epoch: 90 | Time: 0m 14s\n",
            "\tTrain Loss: 0.542 | Train PPL:   1.720\n",
            "\t Val. Loss: 1.248 |  Val. PPL:   3.483\n",
            "Epoch: 91 | Time: 0m 14s\n",
            "\tTrain Loss: 0.539 | Train PPL:   1.714\n",
            "\t Val. Loss: 1.246 |  Val. PPL:   3.478\n",
            "Epoch: 92 | Time: 0m 14s\n",
            "\tTrain Loss: 0.534 | Train PPL:   1.706\n",
            "\t Val. Loss: 1.249 |  Val. PPL:   3.488\n",
            "Epoch: 93 | Time: 0m 14s\n",
            "\tTrain Loss: 0.533 | Train PPL:   1.703\n",
            "\t Val. Loss: 1.254 |  Val. PPL:   3.506\n",
            "Epoch: 94 | Time: 0m 14s\n",
            "\tTrain Loss: 0.529 | Train PPL:   1.697\n",
            "\t Val. Loss: 1.249 |  Val. PPL:   3.488\n",
            "Epoch: 95 | Time: 0m 14s\n",
            "\tTrain Loss: 0.526 | Train PPL:   1.692\n",
            "\t Val. Loss: 1.249 |  Val. PPL:   3.488\n",
            "Epoch: 96 | Time: 0m 14s\n",
            "\tTrain Loss: 0.523 | Train PPL:   1.687\n",
            "\t Val. Loss: 1.248 |  Val. PPL:   3.483\n",
            "Epoch: 97 | Time: 0m 14s\n",
            "\tTrain Loss: 0.518 | Train PPL:   1.678\n",
            "\t Val. Loss: 1.254 |  Val. PPL:   3.506\n",
            "Epoch: 98 | Time: 0m 14s\n",
            "\tTrain Loss: 0.518 | Train PPL:   1.679\n",
            "\t Val. Loss: 1.248 |  Val. PPL:   3.482\n",
            "Epoch: 99 | Time: 0m 14s\n",
            "\tTrain Loss: 0.515 | Train PPL:   1.674\n",
            "\t Val. Loss: 1.248 |  Val. PPL:   3.484\n",
            "Epoch: 100 | Time: 0m 14s\n",
            "\tTrain Loss: 0.512 | Train PPL:   1.669\n",
            "\t Val. Loss: 1.249 |  Val. PPL:   3.486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7Dty35Sf9bL",
        "outputId": "d2d5b32f-c5a4-413a-fda7-a88945962147"
      },
      "source": [
        "model.load_state_dict(torch.load('Experiment_2.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 1.359 | Test PPL:   3.893 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "_pmW1KVL9fIA",
        "outputId": "ea2a4e38-f2e3-4f97-f8cb-b2d75114118c"
      },
      "source": [
        "def plot_losses(train_losses, valid_losses):\n",
        "  fig, ax = plt.subplots(figsize = (12, 6))\n",
        "  epochs = list(range(len(train_losses)))\n",
        "  ax.plot(epochs, train_losses, label = 'train_loss', color = 'green')\n",
        "  ax.plot(epochs, valid_losses, label = 'valid_loss', color = 'red')\n",
        "  ax.legend()\n",
        "  ax.set(xlabel = 'Epochs', ylabel = 'Cross_Entropy_Loss', title = 'Variation of loss with epochs')\n",
        "\n",
        "plot_losses(train_losses, valid_losses)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_WBWxvDzPoB"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7e5Ny4dzToy"
      },
      "source": [
        "def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 8, n_cols = 1):\n",
        "    \n",
        "    assert n_rows * n_cols == n_heads\n",
        "    \n",
        "    fig = plt.figure(figsize=(200,100))\n",
        "    \n",
        "    for i in range(n_heads):\n",
        "        \n",
        "        ax = fig.add_subplot(n_rows, n_cols, i+1)\n",
        "        \n",
        "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
        "\n",
        "        cax = ax.matshow(_attention, cmap='bone')\n",
        "\n",
        "        ax.tick_params(labelsize=12)\n",
        "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
        "                           rotation=45)\n",
        "        ax.set_yticklabels(['']+translation)\n",
        "\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN50LEW3zX3F"
      },
      "source": [
        "def show_results(infer_data, example_idx):\n",
        "  src = vars(infer_data.examples[example_idx])['src']\n",
        "  trg = vars(infer_data.examples[example_idx])['trg']\n",
        "  # print(f'src = {\" \".join(src)}')\n",
        "  # print(f'trg :\\n {\" \".join(trg)}')\n",
        "\n",
        "  translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "  # print(f'predicted trg :\\n {\" \".join(translation)}')\n",
        "\n",
        "  # display_attention(src, translation, attention)\n",
        "  return \" \".join(src), \"\".join(trg), \"\".join(translation)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPjskSMHzaHo"
      },
      "source": [
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "bdc93cf837144928a3009655639e34d2",
            "96498cf317654005b5aebd34ef3e7305",
            "4d8f8134d01b47fcac5321f28bf29daf",
            "3aac2d978a004f8f9cc11ecea52b51bb",
            "69300322050f4a4bab300069b7a4e06b",
            "2d456c50b8834d89bcff02ba59f9952e",
            "4c573b7c31104d9fb6e7f4d3a801bdc5",
            "197d5d6b7c5546cd95d289b9feb5e295"
          ]
        },
        "id": "SUib4Wduz8WM",
        "outputId": "4eb2144c-303d-43d5-f2b1-569965ef13f2"
      },
      "source": [
        "results_df = pd.DataFrame()\n",
        "for i in tqdm(range(len(test_data)), total = len(test_data)):\n",
        "  # print(i)\n",
        "  src, target, translation = show_results(test_data, i)\n",
        "  row_df = pd.DataFrame({'src': src, 'target': target, 'translation': translation}, index = [0])\n",
        "  results_df = pd.concat([results_df, row_df])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdc93cf837144928a3009655639e34d2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=177.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acikDf8BzPsP"
      },
      "source": [
        "results_df.reset_index(drop = True, inplace = True)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "P5asPFPB0maj",
        "outputId": "e230eac7-1489-4a87-afbf-404e03ad6a1d"
      },
      "source": [
        "results_df"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>target</th>\n",
              "      <th>translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>write a python function to get the surface_are...</td>\n",
              "      <td>def rec_prism_surface_area(length, width, heig...</td>\n",
              "      <td>def cal_area_rect(length, height):\\n    return...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python function to add elements of two...</td>\n",
              "      <td>def add_two_lists(list1, list2):\\n   list1 = [...</td>\n",
              "      <td>def add_two_lists(list1, list2):\\n   list2 = [...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a lambda function to multiply two numbers</td>\n",
              "      <td>multiply = lambda a, b: a*b\\n</td>\n",
              "      <td>a = {1, 2, 4, 6, 7}\\nresult = lambda a: a + b,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a python function to generate cube numbe...</td>\n",
              "      <td>def cube_numbers(n):\\n    for i in range(n):\\n...</td>\n",
              "      <td>def square_numbers(n):\\n    for i in range(1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>define a custom exception class which takes a ...</td>\n",
              "      <td>class MyError(Exception):\\n    def __init__(se...</td>\n",
              "      <td>class Person:\\n    def __init__(self, msg):\\n ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>write a   python function that returns the h...</td>\n",
              "      <td>def calculate_hcf(x1, x2):\\n    if x1 == 0:\\n ...</td>\n",
              "      <td>def hcf(num1, num2):\\n    if num1 &gt;= num2:\\n  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>write a program to compute /+/+/+ ... +n / n+ ...</td>\n",
              "      <td>n=int(raw_input())\\nsum=0.0\\nfor i in range(1,...</td>\n",
              "      <td>num = int(input(\"Enter a number: \"))\\nsum = 0\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>write a python program which takes input a num...</td>\n",
              "      <td>N = int(input(\"Please enter a number \"))\\nfirs...</td>\n",
              "      <td>n = int(input(\"Enter Number: \"))\\nn = 0\\nwhile...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>write a python class that will initiate a numb...</td>\n",
              "      <td>class Number:\\n\\tdef __init__(self, num):\\n\\t\\...</td>\n",
              "      <td>class __init__(self, self):\\n    def __init__(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>write s python program to print the difference...</td>\n",
              "      <td>A = {1, 2, 3, 4, 5}\\n B = {4, 5, 6, 7, 8}\\n pr...</td>\n",
              "      <td>A = {1, 2, 3, 4, 5}\\n B = {4, 5, 6, 7, 8}\\n pr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>177 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   src  ...                                        translation\n",
              "0    write a python function to get the surface_are...  ...  def cal_area_rect(length, height):\\n    return...\n",
              "1    write a python function to add elements of two...  ...  def add_two_lists(list1, list2):\\n   list2 = [...\n",
              "2      write a lambda function to multiply two numbers  ...  a = {1, 2, 4, 6, 7}\\nresult = lambda a: a + b,...\n",
              "3    write a python function to generate cube numbe...  ...  def square_numbers(n):\\n    for i in range(1, ...\n",
              "4    define a custom exception class which takes a ...  ...  class Person:\\n    def __init__(self, msg):\\n ...\n",
              "..                                                 ...  ...                                                ...\n",
              "172    write a   python function that returns the h...  ...  def hcf(num1, num2):\\n    if num1 >= num2:\\n  ...\n",
              "173  write a program to compute /+/+/+ ... +n / n+ ...  ...  num = int(input(\"Enter a number: \"))\\nsum = 0\\...\n",
              "174  write a python program which takes input a num...  ...  n = int(input(\"Enter Number: \"))\\nn = 0\\nwhile...\n",
              "175  write a python class that will initiate a numb...  ...  class __init__(self, self):\\n    def __init__(...\n",
              "176  write s python program to print the difference...  ...  A = {1, 2, 3, 4, 5}\\n B = {4, 5, 6, 7, 8}\\n pr...\n",
              "\n",
              "[177 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFnYxCTe09rr",
        "outputId": "69b89b85-907e-4cc1-ff5e-930fafe058c8"
      },
      "source": [
        "idx = 34\n",
        "print(results_df.iloc[idx]['src'])\n",
        "print(\"\\n\")\n",
        "print(\"Target:\")\n",
        "print(results_df.iloc[idx]['target'])\n",
        "print(\"\\n\")\n",
        "print(\"Predictions:\")\n",
        "print(results_df.iloc[idx]['translation'])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "create and print a dictionary\n",
            "\n",
            "\n",
            "Target:\n",
            "thisdict = {\n",
            "  \"brand\": \"Ford\",\n",
            "  \"model\": \"Mustang\",\n",
            "  \"year\": 1964\n",
            "}\n",
            "print(f\"Sample Dictionary:{thisdict}\")\n",
            "\n",
            "\n",
            "\n",
            "Predictions:\n",
            "thisdict = {\n",
            "  \"brand\": \"Ford\",\n",
            "  \"model\": \"Mustang\",\n",
            "  \"year\": 1964\n",
            "}\n",
            "print(f\"Sample Dictionary:{thisdict}\")\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBJsdf1Ra4lX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}