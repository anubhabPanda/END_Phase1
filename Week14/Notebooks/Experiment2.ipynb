{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3c6b3e50cd47459aa452471f0fd162d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c0b89ced478d491aa91b033db192e474",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_053493b7a5444c0b85c7523a42241363",
              "IPY_MODEL_a4a7a6671e084b78a4b89e70393c0e9c"
            ]
          }
        },
        "c0b89ced478d491aa91b033db192e474": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "053493b7a5444c0b85c7523a42241363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b0413805493140918bb78cd248cd8927",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 177,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 177,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b2a4ce7de66461c842de89f4470a372"
          }
        },
        "a4a7a6671e084b78a4b89e70393c0e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c0bca3260e764826913dfe1d66bdb799",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 177/177 [00:36&lt;00:00,  4.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_342c0a3fc0ce4575b9fe447ff6c7a0aa"
          }
        },
        "b0413805493140918bb78cd248cd8927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b2a4ce7de66461c842de89f4470a372": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c0bca3260e764826913dfe1d66bdb799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "342c0a3fc0ce4575b9fe447ff6c7a0aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p9am1aey1ym"
      },
      "source": [
        "### Features of this notebook\n",
        "1. Custom Tokenizer\n",
        "2. One Cyle LR\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cWl5cbOxnvV",
        "outputId": "c72c2b65-6152-46dd-c2cc-f68962d25841"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKkIH7bnyBAR",
        "outputId": "b4b0cd53-4ced-46e1-f1e2-8c86ac86510f"
      },
      "source": [
        "%cd /content/drive/MyDrive/END/Transformer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/END/Transformer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc2IFI5Rqxqd"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Picasso')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-dzij1s3ByF"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJVyVrloxtU0"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.legacy.data import Field, BucketIterator, Example, Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from main_engine import lr_finder, schedulers\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from spacy.tokenizer import Tokenizer\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pygments\n",
        "from pygments.lexers import PythonLexer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD6T3VORx-Ak"
      },
      "source": [
        "# Setting Random Seeds\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZf2qzPKyFc2",
        "outputId": "7a6df242-5637-414f-8153-769a8804a444"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.1.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2mâœ” Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzO_Rw8w3Zli"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM7r4aI4yHrU"
      },
      "source": [
        "lines = []\n",
        "with open('english_python_data_corrected.txt', encoding='utf-8') as f:\n",
        "    for counter, line in enumerate(f):\n",
        "            lines.append(line)\n",
        "#Removing comments  \n",
        "comment_re = re.compile(r'#\\s*\\dx\\d\\s*matrix|#\\s*result|#\\s*iterate|#\\s*initialize|#\\s*Driver|#\\s*This function|#\\s*Iterate', \n",
        "                        re.IGNORECASE)\n",
        "lines = [x for x in lines if re.search(comment_re, x) is None]\n",
        "\n",
        "example_start_id = [counter for counter,_ in enumerate(lines) if (_.startswith(\"#\") or _.startswith(\" #\")) and (lines[counter-1].strip() == '')]\n",
        "training_examples = []\n",
        "for num, idx in enumerate(example_start_id):\n",
        "    if idx != example_start_id[-1]:\n",
        "        example_dict = {}\n",
        "        example = lines[example_start_id[num]:example_start_id[num+1]]\n",
        "        if (re.search(r\"#\\s*\\d\", example[0], re.IGNORECASE)) and (re.search(r\"#\", example[1], re.IGNORECASE)) is not None:\n",
        "                    example_dict['ques_prompt'] = example[1].strip()\n",
        "                    example_dict['source_code'] = \"\".join(example[2:]).strip()\n",
        "        elif re.search(r'#\\s*In\\[\\d*\\]', \"\".join(example), re.IGNORECASE) is not None:\n",
        "            continue\n",
        "        else:\n",
        "            example_dict['ques_prompt'] = example[0].strip()\n",
        "            example_dict['source_code'] = \"\".join(example[1:]).strip()\n",
        "        training_examples.append(example_dict)\n",
        "    else:\n",
        "        example_dict = {}\n",
        "        example = lines[example_start_id[num]:]\n",
        "        example_dict['ques_prompt'] = example[0].strip()\n",
        "        example_dict['source_code'] = \"\".join(example[1:]).strip()\n",
        "        training_examples.append(example_dict)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWDP2kEEyQCN"
      },
      "source": [
        "full_data = pd.DataFrame(training_examples)\n",
        "# Dropping examples where length of code was greater than 250 characters\n",
        "len_filter = full_data['source_code'].apply(lambda x:len(x) > 250)\n",
        "full_data.drop(len_filter[len_filter == True].index.tolist(), inplace = True, axis = 0)\n",
        "full_data.reset_index(drop = True, inplace = True)\n",
        "full_data['ques_prompt'] = full_data['ques_prompt'].apply(lambda x:re.sub(r'\\d*', '', x))\n",
        "full_data['ques_prompt'] = full_data['ques_prompt'].apply(lambda x:re.sub(r'(#\\s)+', '', x))\n",
        "full_data.columns = ['src', 'trg']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "UifQzF1uIx2N",
        "outputId": "d9ab9bdc-d46b-4e80-e782-8a99d0b29a62"
      },
      "source": [
        "full_data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>trg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>write a python program to add two numbers</td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python function to add two user provid...</td>\n",
              "      <td>def add_two_numbers(num1, num2):\\n    sum = nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a program to find and print the largest ...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &gt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a program to find and print the smallest...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Write a python function to merge two given lis...</td>\n",
              "      <td>def merge_lists(l1, l2):\\n    return l1 + l2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 src                                                trg\n",
              "0          write a python program to add two numbers  num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...\n",
              "1  write a python function to add two user provid...  def add_two_numbers(num1, num2):\\n    sum = nu...\n",
              "2  write a program to find and print the largest ...  num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 >= n...\n",
              "3  write a program to find and print the smallest...  num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <= n...\n",
              "4  Write a python function to merge two given lis...       def merge_lists(l1, l2):\\n    return l1 + l2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdrOdQr80B3J"
      },
      "source": [
        "# Loading spacy language models for tokenization\n",
        "en_tokenizer = spacy.load('en')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqfrzvJE3wJm"
      },
      "source": [
        "# Custom Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtzXgqS6pfeQ"
      },
      "source": [
        "lexer = PythonLexer()\n",
        "def tokenize_py(text):\n",
        "    \"\"\"\n",
        "    Tokenizes Python text from a string into a list of tokens\n",
        "    \"\"\"\n",
        "    tokens_texts = lexer.get_tokens(text)\n",
        "    tokens_texts = [i[1] for i in tokens_texts if i[0] != pygments.token.Comment.Single]\n",
        "    return tokens_texts\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of tokens\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in en_tokenizer.tokenizer(text)]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQcuYk3C4XgX",
        "outputId": "da21df97-4f3d-4af1-fab9-e85b1a1092ae"
      },
      "source": [
        "# Let's test our custom tokenizer\n",
        "idx = 1\n",
        "print(f'Target Sentence :\\n{full_data.iloc[idx, 1]}\\n')\n",
        "print(f'Tokens : {tokenize_py(full_data.iloc[idx, 1])}\\n',)\n",
        "print(f'Reconstructed sentence from Tokens : \\n{\"\".join(tokenize_py(full_data.iloc[idx, 1]))}\\n')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target Sentence :\n",
            "def add_two_numbers(num1, num2):\n",
            "    sum = num1 + num2\n",
            "    return sum\n",
            "\n",
            "Tokens : ['def', ' ', 'add_two_numbers', '(', 'num1', ',', ' ', 'num2', ')', ':', '\\n', '    ', 'sum', ' ', '=', ' ', 'num1', ' ', '+', ' ', 'num2', '\\n', '    ', 'return', ' ', 'sum', '\\n']\n",
            "\n",
            "Reconstructed sentence from Tokens : \n",
            "def add_two_numbers(num1, num2):\n",
            "    sum = num1 + num2\n",
            "    return sum\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4To5gq4E5oUR",
        "outputId": "ccb4713a-84a0-4d3f-d1a7-7698c496e681"
      },
      "source": [
        "idx = 1454\n",
        "print(f'Target Sentence :\\n{full_data.iloc[idx, 1]}\\n')\n",
        "print(f'Tokens : {tokenize_py(full_data.iloc[idx, 1])}\\n',)\n",
        "print(f'Reconstructed sentence from Tokens : \\n{\"\".join(tokenize_py(full_data.iloc[idx, 1]))}\\n')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target Sentence :\n",
            "test_list = [(1, 3), (1, 4), (2, 3), (3, 2), (5, 3), (6, 4)] \n",
            "res = {} \n",
            "for i, j in test_list: \n",
            "     res.setdefault(j, []).append(i) \n",
            "print(\"The dictionary converted from tuple list : \" + str(res))\n",
            "\n",
            "Tokens : ['test_list', ' ', '=', ' ', '[', '(', '1', ',', ' ', '3', ')', ',', ' ', '(', '1', ',', ' ', '4', ')', ',', ' ', '(', '2', ',', ' ', '3', ')', ',', ' ', '(', '3', ',', ' ', '2', ')', ',', ' ', '(', '5', ',', ' ', '3', ')', ',', ' ', '(', '6', ',', ' ', '4', ')', ']', ' ', '\\n', 'res', ' ', '=', ' ', '{', '}', ' ', '\\n', 'for', ' ', 'i', ',', ' ', 'j', ' ', 'in', ' ', 'test_list', ':', ' ', '\\n', '     ', 'res', '.', 'setdefault', '(', 'j', ',', ' ', '[', ']', ')', '.', 'append', '(', 'i', ')', ' ', '\\n', 'print', '(', '\"', 'The dictionary converted from tuple list : ', '\"', ' ', '+', ' ', 'str', '(', 'res', ')', ')', '\\n']\n",
            "\n",
            "Reconstructed sentence from Tokens : \n",
            "test_list = [(1, 3), (1, 4), (2, 3), (3, 2), (5, 3), (6, 4)] \n",
            "res = {} \n",
            "for i, j in test_list: \n",
            "     res.setdefault(j, []).append(i) \n",
            "print(\"The dictionary converted from tuple list : \" + str(res))\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mUtDWea5uOV"
      },
      "source": [
        "As we can see that the python code structure is maintained and proper tokenization is there for f-strings, spaces, newline, python operators and brackets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iSMa5iYJG-i"
      },
      "source": [
        "# Defining the fields\n",
        "SRC = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            batch_first = True)\n",
        "\n",
        "# lower=False since python is case sensitive language\n",
        "TRG = Field(tokenize = tokenize_py, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = False, \n",
        "            batch_first = True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX4CJzLKJXqE"
      },
      "source": [
        "# Creating torchtext dataset \n",
        "fields = [('src', SRC), ('trg', TRG)]\n",
        "examples = [Example.fromlist([full_data.src[i], full_data.trg[i]], fields) for i in range(full_data.shape[0])]\n",
        "complete_dataset = Dataset(examples, fields)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sxQcLlGMv0-"
      },
      "source": [
        "# Splitting into train, test and validation\n",
        "train_data, valid_data, test_data = complete_dataset.split(split_ratio=[0.80, 0.05, 0.15], \n",
        "                                    random_state=random.seed(SEED))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6pfjzztO-HE",
        "outputId": "7f9a33e4-b50b-487f-9e62-57638ea08e99"
      },
      "source": [
        "len(train_data), len(valid_data), len(test_data)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2828, 530, 177)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YhWJpg8PD8B",
        "outputId": "33a064ed-184a-4c7f-fc5c-62fa4839fc42"
      },
      "source": [
        "# Let's look at a few examples from the dataset\n",
        "idx = 9\n",
        "print(''.join(vars(train_data.examples[idx])['trg']))\n",
        "print(vars(train_data.examples[idx])['trg'])\n",
        "print(len(vars(train_data.examples[idx])['trg']))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence = 'The Quick 123 Fox'\n",
            "digits = 0\n",
            "letters = 0\n",
            "for c in sentence:\n",
            "   if c.isdigit():\n",
            "      digits += 1\n",
            "   elif c.isalpha():\n",
            "      letters += 1\n",
            "   else:\n",
            "      pass\n",
            "print(f'Digits: {digits}, Letters: {letters}')\n",
            "\n",
            "['sentence', ' ', '=', ' ', \"'\", 'The Quick 123 Fox', \"'\", '\\n', 'digits', ' ', '=', ' ', '0', '\\n', 'letters', ' ', '=', ' ', '0', '\\n', 'for', ' ', 'c', ' ', 'in', ' ', 'sentence', ':', '\\n', '   ', 'if', ' ', 'c', '.', 'isdigit', '(', ')', ':', '\\n', '      ', 'digits', ' ', '+', '=', ' ', '1', '\\n', '   ', 'elif', ' ', 'c', '.', 'isalpha', '(', ')', ':', '\\n', '      ', 'letters', ' ', '+', '=', ' ', '1', '\\n', '   ', 'else', ':', '\\n', '      ', 'pass', '\\n', 'print', '(', 'f', \"'\", 'Digits: ', '{', 'digits', '}', ', Letters: ', '{', 'letters', '}', \"'\", ')', '\\n']\n",
            "87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orcMjw5KohfG",
        "outputId": "404ca357-8bc7-4efe-94f6-a285f287e625"
      },
      "source": [
        "idx = 0\n",
        "print(''.join(vars(train_data.examples[idx])['trg']))\n",
        "print(vars(train_data.examples[idx])['trg'])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word = \"Hello World\"\n",
            "replace = \"Bye\"\n",
            "input = \"Hello\"\n",
            "after_replace = word.replace(input, replace)\n",
            "print(f\"String ater replacement: {after_replace}\")\n",
            "\n",
            "['word', ' ', '=', ' ', '\"', 'Hello World', '\"', '\\n', 'replace', ' ', '=', ' ', '\"', 'Bye', '\"', '\\n', 'input', ' ', '=', ' ', '\"', 'Hello', '\"', '\\n', 'after_replace', ' ', '=', ' ', 'word', '.', 'replace', '(', 'input', ',', ' ', 'replace', ')', '\\n', 'print', '(', 'f', '\"', 'String ater replacement: ', '{', 'after_replace', '}', '\"', ')', '\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWATKYiJPKHY"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STmUMUnjSeFG",
        "outputId": "968e7c23-8a0f-4c3f-b9d2-ea5ef05028af"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = 'cpu'\n",
        "device"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eYIBgWrSkln"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), sort_key = lambda x:len(x.src), sort_within_batch = False,\n",
        "     batch_size = BATCH_SIZE,\n",
        "     device = device)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCkVjzBuTXFC"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 200):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "        \n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        "            \n",
        "        return src"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKnjbUpXTaZZ"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len] \n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ycLDCPuTf63"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmIaAPSlTl-K"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEbFPA6XTp_g"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 250):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "            \n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBHcoWU0TvW6"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "            \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "            \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        # query, key, value\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06x-eTpHTxmJ"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        \n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return output, attention"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzgmVhkoTz1D"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HID_DIM = 512\n",
        "ENC_LAYERS = 4\n",
        "DEC_LAYERS = 4\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 1024\n",
        "DEC_PF_DIM = 1024\n",
        "ENC_DROPOUT = 0.2\n",
        "DEC_DROPOUT = 0.2\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device)"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pHkV-bLT3lO"
      },
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5ku2QdmT7G6",
        "outputId": "c5cf89f6-ca5a-430a-a6a7-93f3cfb2a508"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 25,676,464 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KALu_7hxUJmP"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ],
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlaoFi4PUMpb"
      },
      "source": [
        "model.apply(initialize_weights);"
      ],
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aGeLVbfUOhw"
      },
      "source": [
        "LEARNING_RATE = 0.00005\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iFH6VuIUQsN"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67vxplARCKWU"
      },
      "source": [
        "# One Cycle LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at_ZxwaaCIph"
      },
      "source": [
        "max_lr = 0.0005\n",
        "N_EPOCHS = 100\n",
        "max_epoch = 30\n",
        "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr,\n",
        "                                     epochs = N_EPOCHS, steps_per_epoch=1, pct_start=max_epoch/N_EPOCHS, \n",
        "                                     anneal_strategy='linear', div_factor=10.0, final_div_factor=1.0)"
      ],
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSeRKtvzUSRd"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "                \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "            \n",
        "        output_dim = output.shape[-1]\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "                \n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "            \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RtYKHfPUUF3"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1bzVnDHUWIR"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QpGdTj_UYtL",
        "outputId": "c8d595b3-7e9d-4a67-c866-4c3cffb307a6"
      },
      "source": [
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'Experiment_2.pt')\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 16s\n",
            "\tTrain Loss: 6.111 | Train PPL: 450.956\n",
            "\t Val. Loss: 5.176 |  Val. PPL: 176.889\n",
            "Epoch: 02 | Time: 0m 16s\n",
            "\tTrain Loss: 4.861 | Train PPL: 129.201\n",
            "\t Val. Loss: 4.403 |  Val. PPL:  81.699\n",
            "Epoch: 03 | Time: 0m 15s\n",
            "\tTrain Loss: 4.105 | Train PPL:  60.644\n",
            "\t Val. Loss: 3.600 |  Val. PPL:  36.581\n",
            "Epoch: 04 | Time: 0m 15s\n",
            "\tTrain Loss: 3.508 | Train PPL:  33.387\n",
            "\t Val. Loss: 3.237 |  Val. PPL:  25.460\n",
            "Epoch: 05 | Time: 0m 15s\n",
            "\tTrain Loss: 3.194 | Train PPL:  24.388\n",
            "\t Val. Loss: 3.017 |  Val. PPL:  20.431\n",
            "Epoch: 06 | Time: 0m 16s\n",
            "\tTrain Loss: 2.999 | Train PPL:  20.069\n",
            "\t Val. Loss: 2.860 |  Val. PPL:  17.463\n",
            "Epoch: 07 | Time: 0m 16s\n",
            "\tTrain Loss: 2.854 | Train PPL:  17.364\n",
            "\t Val. Loss: 2.738 |  Val. PPL:  15.460\n",
            "Epoch: 08 | Time: 0m 16s\n",
            "\tTrain Loss: 2.733 | Train PPL:  15.384\n",
            "\t Val. Loss: 2.647 |  Val. PPL:  14.110\n",
            "Epoch: 09 | Time: 0m 15s\n",
            "\tTrain Loss: 2.640 | Train PPL:  14.019\n",
            "\t Val. Loss: 2.576 |  Val. PPL:  13.138\n",
            "Epoch: 10 | Time: 0m 15s\n",
            "\tTrain Loss: 2.560 | Train PPL:  12.930\n",
            "\t Val. Loss: 2.511 |  Val. PPL:  12.316\n",
            "Epoch: 11 | Time: 0m 16s\n",
            "\tTrain Loss: 2.481 | Train PPL:  11.955\n",
            "\t Val. Loss: 2.435 |  Val. PPL:  11.412\n",
            "Epoch: 12 | Time: 0m 15s\n",
            "\tTrain Loss: 2.414 | Train PPL:  11.177\n",
            "\t Val. Loss: 2.387 |  Val. PPL:  10.886\n",
            "Epoch: 13 | Time: 0m 15s\n",
            "\tTrain Loss: 2.356 | Train PPL:  10.545\n",
            "\t Val. Loss: 2.337 |  Val. PPL:  10.351\n",
            "Epoch: 14 | Time: 0m 15s\n",
            "\tTrain Loss: 2.296 | Train PPL:   9.931\n",
            "\t Val. Loss: 2.291 |  Val. PPL:   9.884\n",
            "Epoch: 15 | Time: 0m 15s\n",
            "\tTrain Loss: 2.246 | Train PPL:   9.452\n",
            "\t Val. Loss: 2.258 |  Val. PPL:   9.566\n",
            "Epoch: 16 | Time: 0m 15s\n",
            "\tTrain Loss: 2.197 | Train PPL:   8.995\n",
            "\t Val. Loss: 2.211 |  Val. PPL:   9.124\n",
            "Epoch: 17 | Time: 0m 15s\n",
            "\tTrain Loss: 2.144 | Train PPL:   8.530\n",
            "\t Val. Loss: 2.164 |  Val. PPL:   8.708\n",
            "Epoch: 18 | Time: 0m 15s\n",
            "\tTrain Loss: 2.097 | Train PPL:   8.140\n",
            "\t Val. Loss: 2.125 |  Val. PPL:   8.370\n",
            "Epoch: 19 | Time: 0m 15s\n",
            "\tTrain Loss: 2.056 | Train PPL:   7.812\n",
            "\t Val. Loss: 2.093 |  Val. PPL:   8.109\n",
            "Epoch: 20 | Time: 0m 15s\n",
            "\tTrain Loss: 2.009 | Train PPL:   7.454\n",
            "\t Val. Loss: 2.059 |  Val. PPL:   7.836\n",
            "Epoch: 21 | Time: 0m 16s\n",
            "\tTrain Loss: 1.971 | Train PPL:   7.180\n",
            "\t Val. Loss: 2.007 |  Val. PPL:   7.440\n",
            "Epoch: 22 | Time: 0m 15s\n",
            "\tTrain Loss: 1.932 | Train PPL:   6.902\n",
            "\t Val. Loss: 1.990 |  Val. PPL:   7.312\n",
            "Epoch: 23 | Time: 0m 15s\n",
            "\tTrain Loss: 1.893 | Train PPL:   6.641\n",
            "\t Val. Loss: 1.960 |  Val. PPL:   7.097\n",
            "Epoch: 24 | Time: 0m 15s\n",
            "\tTrain Loss: 1.860 | Train PPL:   6.425\n",
            "\t Val. Loss: 1.926 |  Val. PPL:   6.862\n",
            "Epoch: 25 | Time: 0m 15s\n",
            "\tTrain Loss: 1.824 | Train PPL:   6.200\n",
            "\t Val. Loss: 1.912 |  Val. PPL:   6.769\n",
            "Epoch: 26 | Time: 0m 16s\n",
            "\tTrain Loss: 1.788 | Train PPL:   5.976\n",
            "\t Val. Loss: 1.883 |  Val. PPL:   6.575\n",
            "Epoch: 27 | Time: 0m 16s\n",
            "\tTrain Loss: 1.755 | Train PPL:   5.782\n",
            "\t Val. Loss: 1.859 |  Val. PPL:   6.418\n",
            "Epoch: 28 | Time: 0m 15s\n",
            "\tTrain Loss: 1.726 | Train PPL:   5.620\n",
            "\t Val. Loss: 1.833 |  Val. PPL:   6.250\n",
            "Epoch: 29 | Time: 0m 15s\n",
            "\tTrain Loss: 1.697 | Train PPL:   5.456\n",
            "\t Val. Loss: 1.809 |  Val. PPL:   6.107\n",
            "Epoch: 30 | Time: 0m 15s\n",
            "\tTrain Loss: 1.672 | Train PPL:   5.322\n",
            "\t Val. Loss: 1.791 |  Val. PPL:   5.996\n",
            "Epoch: 31 | Time: 0m 15s\n",
            "\tTrain Loss: 1.636 | Train PPL:   5.136\n",
            "\t Val. Loss: 1.770 |  Val. PPL:   5.873\n",
            "Epoch: 32 | Time: 0m 15s\n",
            "\tTrain Loss: 1.608 | Train PPL:   4.992\n",
            "\t Val. Loss: 1.759 |  Val. PPL:   5.806\n",
            "Epoch: 33 | Time: 0m 15s\n",
            "\tTrain Loss: 1.580 | Train PPL:   4.857\n",
            "\t Val. Loss: 1.745 |  Val. PPL:   5.725\n",
            "Epoch: 34 | Time: 0m 15s\n",
            "\tTrain Loss: 1.563 | Train PPL:   4.774\n",
            "\t Val. Loss: 1.708 |  Val. PPL:   5.520\n",
            "Epoch: 35 | Time: 0m 15s\n",
            "\tTrain Loss: 1.529 | Train PPL:   4.612\n",
            "\t Val. Loss: 1.687 |  Val. PPL:   5.404\n",
            "Epoch: 36 | Time: 0m 15s\n",
            "\tTrain Loss: 1.506 | Train PPL:   4.507\n",
            "\t Val. Loss: 1.688 |  Val. PPL:   5.407\n",
            "Epoch: 37 | Time: 0m 15s\n",
            "\tTrain Loss: 1.480 | Train PPL:   4.392\n",
            "\t Val. Loss: 1.668 |  Val. PPL:   5.299\n",
            "Epoch: 38 | Time: 0m 15s\n",
            "\tTrain Loss: 1.455 | Train PPL:   4.283\n",
            "\t Val. Loss: 1.653 |  Val. PPL:   5.221\n",
            "Epoch: 39 | Time: 0m 15s\n",
            "\tTrain Loss: 1.437 | Train PPL:   4.206\n",
            "\t Val. Loss: 1.637 |  Val. PPL:   5.137\n",
            "Epoch: 40 | Time: 0m 15s\n",
            "\tTrain Loss: 1.408 | Train PPL:   4.087\n",
            "\t Val. Loss: 1.624 |  Val. PPL:   5.074\n",
            "Epoch: 41 | Time: 0m 15s\n",
            "\tTrain Loss: 1.389 | Train PPL:   4.009\n",
            "\t Val. Loss: 1.618 |  Val. PPL:   5.044\n",
            "Epoch: 42 | Time: 0m 16s\n",
            "\tTrain Loss: 1.368 | Train PPL:   3.928\n",
            "\t Val. Loss: 1.603 |  Val. PPL:   4.969\n",
            "Epoch: 43 | Time: 0m 15s\n",
            "\tTrain Loss: 1.348 | Train PPL:   3.849\n",
            "\t Val. Loss: 1.594 |  Val. PPL:   4.922\n",
            "Epoch: 44 | Time: 0m 15s\n",
            "\tTrain Loss: 1.326 | Train PPL:   3.766\n",
            "\t Val. Loss: 1.575 |  Val. PPL:   4.829\n",
            "Epoch: 45 | Time: 0m 15s\n",
            "\tTrain Loss: 1.307 | Train PPL:   3.697\n",
            "\t Val. Loss: 1.561 |  Val. PPL:   4.765\n",
            "Epoch: 46 | Time: 0m 16s\n",
            "\tTrain Loss: 1.285 | Train PPL:   3.616\n",
            "\t Val. Loss: 1.549 |  Val. PPL:   4.708\n",
            "Epoch: 47 | Time: 0m 16s\n",
            "\tTrain Loss: 1.262 | Train PPL:   3.534\n",
            "\t Val. Loss: 1.530 |  Val. PPL:   4.619\n",
            "Epoch: 48 | Time: 0m 15s\n",
            "\tTrain Loss: 1.245 | Train PPL:   3.473\n",
            "\t Val. Loss: 1.528 |  Val. PPL:   4.607\n",
            "Epoch: 49 | Time: 0m 16s\n",
            "\tTrain Loss: 1.225 | Train PPL:   3.405\n",
            "\t Val. Loss: 1.521 |  Val. PPL:   4.576\n",
            "Epoch: 50 | Time: 0m 15s\n",
            "\tTrain Loss: 1.207 | Train PPL:   3.343\n",
            "\t Val. Loss: 1.505 |  Val. PPL:   4.505\n",
            "Epoch: 51 | Time: 0m 15s\n",
            "\tTrain Loss: 1.188 | Train PPL:   3.279\n",
            "\t Val. Loss: 1.497 |  Val. PPL:   4.470\n",
            "Epoch: 52 | Time: 0m 15s\n",
            "\tTrain Loss: 1.172 | Train PPL:   3.230\n",
            "\t Val. Loss: 1.494 |  Val. PPL:   4.455\n",
            "Epoch: 53 | Time: 0m 15s\n",
            "\tTrain Loss: 1.158 | Train PPL:   3.183\n",
            "\t Val. Loss: 1.471 |  Val. PPL:   4.354\n",
            "Epoch: 54 | Time: 0m 16s\n",
            "\tTrain Loss: 1.140 | Train PPL:   3.127\n",
            "\t Val. Loss: 1.479 |  Val. PPL:   4.387\n",
            "Epoch: 55 | Time: 0m 15s\n",
            "\tTrain Loss: 1.125 | Train PPL:   3.081\n",
            "\t Val. Loss: 1.462 |  Val. PPL:   4.314\n",
            "Epoch: 56 | Time: 0m 15s\n",
            "\tTrain Loss: 1.107 | Train PPL:   3.025\n",
            "\t Val. Loss: 1.456 |  Val. PPL:   4.289\n",
            "Epoch: 57 | Time: 0m 15s\n",
            "\tTrain Loss: 1.091 | Train PPL:   2.978\n",
            "\t Val. Loss: 1.437 |  Val. PPL:   4.207\n",
            "Epoch: 58 | Time: 0m 15s\n",
            "\tTrain Loss: 1.074 | Train PPL:   2.928\n",
            "\t Val. Loss: 1.432 |  Val. PPL:   4.185\n",
            "Epoch: 59 | Time: 0m 15s\n",
            "\tTrain Loss: 1.058 | Train PPL:   2.879\n",
            "\t Val. Loss: 1.425 |  Val. PPL:   4.159\n",
            "Epoch: 60 | Time: 0m 15s\n",
            "\tTrain Loss: 1.039 | Train PPL:   2.826\n",
            "\t Val. Loss: 1.416 |  Val. PPL:   4.121\n",
            "Epoch: 61 | Time: 0m 15s\n",
            "\tTrain Loss: 1.027 | Train PPL:   2.793\n",
            "\t Val. Loss: 1.413 |  Val. PPL:   4.107\n",
            "Epoch: 62 | Time: 0m 15s\n",
            "\tTrain Loss: 1.014 | Train PPL:   2.758\n",
            "\t Val. Loss: 1.402 |  Val. PPL:   4.062\n",
            "Epoch: 63 | Time: 0m 15s\n",
            "\tTrain Loss: 0.997 | Train PPL:   2.710\n",
            "\t Val. Loss: 1.397 |  Val. PPL:   4.044\n",
            "Epoch: 64 | Time: 0m 15s\n",
            "\tTrain Loss: 0.983 | Train PPL:   2.674\n",
            "\t Val. Loss: 1.391 |  Val. PPL:   4.020\n",
            "Epoch: 65 | Time: 0m 15s\n",
            "\tTrain Loss: 0.974 | Train PPL:   2.649\n",
            "\t Val. Loss: 1.389 |  Val. PPL:   4.013\n",
            "Epoch: 66 | Time: 0m 16s\n",
            "\tTrain Loss: 0.955 | Train PPL:   2.600\n",
            "\t Val. Loss: 1.382 |  Val. PPL:   3.983\n",
            "Epoch: 67 | Time: 0m 15s\n",
            "\tTrain Loss: 0.947 | Train PPL:   2.577\n",
            "\t Val. Loss: 1.379 |  Val. PPL:   3.971\n",
            "Epoch: 68 | Time: 0m 15s\n",
            "\tTrain Loss: 0.933 | Train PPL:   2.541\n",
            "\t Val. Loss: 1.378 |  Val. PPL:   3.966\n",
            "Epoch: 69 | Time: 0m 15s\n",
            "\tTrain Loss: 0.917 | Train PPL:   2.502\n",
            "\t Val. Loss: 1.364 |  Val. PPL:   3.912\n",
            "Epoch: 70 | Time: 0m 15s\n",
            "\tTrain Loss: 0.908 | Train PPL:   2.479\n",
            "\t Val. Loss: 1.363 |  Val. PPL:   3.906\n",
            "Epoch: 71 | Time: 0m 15s\n",
            "\tTrain Loss: 0.894 | Train PPL:   2.446\n",
            "\t Val. Loss: 1.357 |  Val. PPL:   3.883\n",
            "Epoch: 72 | Time: 0m 15s\n",
            "\tTrain Loss: 0.882 | Train PPL:   2.415\n",
            "\t Val. Loss: 1.345 |  Val. PPL:   3.837\n",
            "Epoch: 73 | Time: 0m 15s\n",
            "\tTrain Loss: 0.868 | Train PPL:   2.382\n",
            "\t Val. Loss: 1.339 |  Val. PPL:   3.814\n",
            "Epoch: 74 | Time: 0m 16s\n",
            "\tTrain Loss: 0.855 | Train PPL:   2.353\n",
            "\t Val. Loss: 1.344 |  Val. PPL:   3.836\n",
            "Epoch: 75 | Time: 0m 15s\n",
            "\tTrain Loss: 0.845 | Train PPL:   2.327\n",
            "\t Val. Loss: 1.333 |  Val. PPL:   3.793\n",
            "Epoch: 76 | Time: 0m 15s\n",
            "\tTrain Loss: 0.837 | Train PPL:   2.309\n",
            "\t Val. Loss: 1.331 |  Val. PPL:   3.785\n",
            "Epoch: 77 | Time: 0m 15s\n",
            "\tTrain Loss: 0.820 | Train PPL:   2.270\n",
            "\t Val. Loss: 1.323 |  Val. PPL:   3.756\n",
            "Epoch: 78 | Time: 0m 15s\n",
            "\tTrain Loss: 0.811 | Train PPL:   2.249\n",
            "\t Val. Loss: 1.327 |  Val. PPL:   3.771\n",
            "Epoch: 79 | Time: 0m 15s\n",
            "\tTrain Loss: 0.802 | Train PPL:   2.230\n",
            "\t Val. Loss: 1.315 |  Val. PPL:   3.726\n",
            "Epoch: 80 | Time: 0m 15s\n",
            "\tTrain Loss: 0.789 | Train PPL:   2.201\n",
            "\t Val. Loss: 1.318 |  Val. PPL:   3.737\n",
            "Epoch: 81 | Time: 0m 15s\n",
            "\tTrain Loss: 0.778 | Train PPL:   2.178\n",
            "\t Val. Loss: 1.313 |  Val. PPL:   3.717\n",
            "Epoch: 82 | Time: 0m 15s\n",
            "\tTrain Loss: 0.771 | Train PPL:   2.163\n",
            "\t Val. Loss: 1.306 |  Val. PPL:   3.690\n",
            "Epoch: 83 | Time: 0m 16s\n",
            "\tTrain Loss: 0.756 | Train PPL:   2.130\n",
            "\t Val. Loss: 1.309 |  Val. PPL:   3.703\n",
            "Epoch: 84 | Time: 0m 15s\n",
            "\tTrain Loss: 0.745 | Train PPL:   2.107\n",
            "\t Val. Loss: 1.307 |  Val. PPL:   3.696\n",
            "Epoch: 85 | Time: 0m 15s\n",
            "\tTrain Loss: 0.740 | Train PPL:   2.097\n",
            "\t Val. Loss: 1.298 |  Val. PPL:   3.662\n",
            "Epoch: 86 | Time: 0m 15s\n",
            "\tTrain Loss: 0.728 | Train PPL:   2.070\n",
            "\t Val. Loss: 1.303 |  Val. PPL:   3.679\n",
            "Epoch: 87 | Time: 0m 15s\n",
            "\tTrain Loss: 0.719 | Train PPL:   2.053\n",
            "\t Val. Loss: 1.297 |  Val. PPL:   3.657\n",
            "Epoch: 88 | Time: 0m 15s\n",
            "\tTrain Loss: 0.711 | Train PPL:   2.036\n",
            "\t Val. Loss: 1.289 |  Val. PPL:   3.630\n",
            "Epoch: 89 | Time: 0m 15s\n",
            "\tTrain Loss: 0.701 | Train PPL:   2.015\n",
            "\t Val. Loss: 1.279 |  Val. PPL:   3.592\n",
            "Epoch: 90 | Time: 0m 15s\n",
            "\tTrain Loss: 0.690 | Train PPL:   1.994\n",
            "\t Val. Loss: 1.283 |  Val. PPL:   3.607\n",
            "Epoch: 91 | Time: 0m 15s\n",
            "\tTrain Loss: 0.682 | Train PPL:   1.979\n",
            "\t Val. Loss: 1.281 |  Val. PPL:   3.601\n",
            "Epoch: 92 | Time: 0m 15s\n",
            "\tTrain Loss: 0.676 | Train PPL:   1.967\n",
            "\t Val. Loss: 1.281 |  Val. PPL:   3.601\n",
            "Epoch: 93 | Time: 0m 15s\n",
            "\tTrain Loss: 0.663 | Train PPL:   1.941\n",
            "\t Val. Loss: 1.287 |  Val. PPL:   3.624\n",
            "Epoch: 94 | Time: 0m 15s\n",
            "\tTrain Loss: 0.657 | Train PPL:   1.929\n",
            "\t Val. Loss: 1.276 |  Val. PPL:   3.584\n",
            "Epoch: 95 | Time: 0m 15s\n",
            "\tTrain Loss: 0.651 | Train PPL:   1.918\n",
            "\t Val. Loss: 1.278 |  Val. PPL:   3.589\n",
            "Epoch: 96 | Time: 0m 15s\n",
            "\tTrain Loss: 0.642 | Train PPL:   1.900\n",
            "\t Val. Loss: 1.265 |  Val. PPL:   3.542\n",
            "Epoch: 97 | Time: 0m 15s\n",
            "\tTrain Loss: 0.633 | Train PPL:   1.884\n",
            "\t Val. Loss: 1.272 |  Val. PPL:   3.569\n",
            "Epoch: 98 | Time: 0m 15s\n",
            "\tTrain Loss: 0.628 | Train PPL:   1.873\n",
            "\t Val. Loss: 1.263 |  Val. PPL:   3.534\n",
            "Epoch: 99 | Time: 0m 15s\n",
            "\tTrain Loss: 0.618 | Train PPL:   1.855\n",
            "\t Val. Loss: 1.258 |  Val. PPL:   3.520\n",
            "Epoch: 100 | Time: 0m 15s\n",
            "\tTrain Loss: 0.610 | Train PPL:   1.840\n",
            "\t Val. Loss: 1.270 |  Val. PPL:   3.560\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7Dty35Sf9bL",
        "outputId": "14bbdd01-6685-42f2-ad68-7a292ef34843"
      },
      "source": [
        "model.load_state_dict(torch.load('Experiment_2.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 1.381 | Test PPL:   3.980 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "_pmW1KVL9fIA",
        "outputId": "4c5cdeeb-7faf-453d-9afa-7a58bc7b541d"
      },
      "source": [
        "def plot_losses(train_losses, valid_losses):\n",
        "  fig, ax = plt.subplots(figsize = (12, 6))\n",
        "  epochs = list(range(len(train_losses)))\n",
        "  ax.plot(epochs, train_losses, label = 'train_loss', color = 'green')\n",
        "  ax.plot(epochs, valid_losses, label = 'valid_loss', color = 'red')\n",
        "  ax.legend()\n",
        "  ax.set(xlabel = 'Epochs', ylabel = 'Cross_Entropy_Loss', title = 'Variation of loss with epochs')\n",
        "\n",
        "plot_losses(train_losses, valid_losses)"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_WBWxvDzPoB"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7e5Ny4dzToy"
      },
      "source": [
        "def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 8, n_cols = 1):\n",
        "    \n",
        "    assert n_rows * n_cols == n_heads\n",
        "    \n",
        "    fig = plt.figure(figsize=(200,100))\n",
        "    \n",
        "    for i in range(n_heads):\n",
        "        \n",
        "        ax = fig.add_subplot(n_rows, n_cols, i+1)\n",
        "        \n",
        "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
        "\n",
        "        cax = ax.matshow(_attention, cmap='bone')\n",
        "\n",
        "        ax.tick_params(labelsize=12)\n",
        "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
        "                           rotation=45)\n",
        "        ax.set_yticklabels(['']+translation)\n",
        "\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN50LEW3zX3F"
      },
      "source": [
        "def show_results(infer_data, example_idx):\n",
        "  src = vars(infer_data.examples[example_idx])['src']\n",
        "  trg = vars(infer_data.examples[example_idx])['trg']\n",
        "  # print(f'src = {\" \".join(src)}')\n",
        "  # print(f'trg :\\n {\" \".join(trg)}')\n",
        "\n",
        "  translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "  # print(f'predicted trg :\\n {\" \".join(translation)}')\n",
        "\n",
        "  # display_attention(src, translation, attention)\n",
        "  return \" \".join(src), \"\".join(trg), \"\".join(translation)"
      ],
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPjskSMHzaHo"
      },
      "source": [
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "3c6b3e50cd47459aa452471f0fd162d9",
            "c0b89ced478d491aa91b033db192e474",
            "053493b7a5444c0b85c7523a42241363",
            "a4a7a6671e084b78a4b89e70393c0e9c",
            "b0413805493140918bb78cd248cd8927",
            "9b2a4ce7de66461c842de89f4470a372",
            "c0bca3260e764826913dfe1d66bdb799",
            "342c0a3fc0ce4575b9fe447ff6c7a0aa"
          ]
        },
        "id": "SUib4Wduz8WM",
        "outputId": "3e352984-3884-49d3-c965-f8ad84dbfcc0"
      },
      "source": [
        "results_df = pd.DataFrame()\n",
        "for i in tqdm(range(len(test_data)), total = len(test_data)):\n",
        "  # print(i)\n",
        "  src, target, translation = show_results(test_data, i)\n",
        "  row_df = pd.DataFrame({'src': src, 'target': target, 'translation': translation}, index = [0])\n",
        "  results_df = pd.concat([results_df, row_df])"
      ],
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c6b3e50cd47459aa452471f0fd162d9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=177.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acikDf8BzPsP"
      },
      "source": [
        "results_df.reset_index(drop = True, inplace = True)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "P5asPFPB0maj",
        "outputId": "2006932f-bea2-486d-a628-461f5f997322"
      },
      "source": [
        "results_df"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>target</th>\n",
              "      <th>translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>write a python function to get the surface_are...</td>\n",
              "      <td>def rec_prism_surface_area(length, width, heig...</td>\n",
              "      <td>def cal_pe(height, height):\\n    return (heigh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python function to add elements of two...</td>\n",
              "      <td>def add_two_lists(list1, list2):\\n   list1 = [...</td>\n",
              "      <td>def add_two_lists(list1, list2):\\n   list1 = [...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a lambda function to multiply two numbers</td>\n",
              "      <td>multiply = lambda a, b: a*b\\n</td>\n",
              "      <td>def is_prod_even(num1, num2):\\n    return num1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a python function to generate cube numbe...</td>\n",
              "      <td>def cube_numbers(n):\\n    for i in range(n):\\n...</td>\n",
              "      <td>def printList():\\n    for i in range(1, n):\\n ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>define a custom exception class which takes a ...</td>\n",
              "      <td>class MyError(Exception):\\n    def __init__(se...</td>\n",
              "      <td>class __init__(self, self):\\n    def __init__(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>write a   python function that returns the h...</td>\n",
              "      <td>def calculate_hcf(x1, x2):\\n    if x1 == 0:\\n ...</td>\n",
              "      <td>def compute_hcf(x, y):\\n    if x &gt; y:\\n       ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>write a program to compute /+/+/+ ... +n / n+ ...</td>\n",
              "      <td>n=int(raw_input())\\nsum=0.0\\nfor i in range(1,...</td>\n",
              "      <td>def recursive_sum(n):\\n    sum = 0\\n    for i ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>write a python program which takes input a num...</td>\n",
              "      <td>N = int(input(\"Please enter a number \"))\\nfirs...</td>\n",
              "      <td>n=int(input(\"\"))\\nn=n\\nn=n*n\\nn=n+n\\nwhile(n-n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>write a python class that will initiate a numb...</td>\n",
              "      <td>class Number:\\n\\tdef __init__(self, num):\\n\\t\\...</td>\n",
              "      <td>def square(n):\\n    return n*2\\n&lt;eos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>write s python program to print the difference...</td>\n",
              "      <td>A = {1, 2, 3, 4, 5}\\n B = {4, 5, 6, 7, 8}\\n pr...</td>\n",
              "      <td>a = {1, 2, 3, 3, 4, 4, 5, 6, 6, 8}\\n = {4, 6, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>177 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   src  ...                                        translation\n",
              "0    write a python function to get the surface_are...  ...  def cal_pe(height, height):\\n    return (heigh...\n",
              "1    write a python function to add elements of two...  ...  def add_two_lists(list1, list2):\\n   list1 = [...\n",
              "2      write a lambda function to multiply two numbers  ...  def is_prod_even(num1, num2):\\n    return num1...\n",
              "3    write a python function to generate cube numbe...  ...  def printList():\\n    for i in range(1, n):\\n ...\n",
              "4    define a custom exception class which takes a ...  ...  class __init__(self, self):\\n    def __init__(...\n",
              "..                                                 ...  ...                                                ...\n",
              "172    write a   python function that returns the h...  ...  def compute_hcf(x, y):\\n    if x > y:\\n       ...\n",
              "173  write a program to compute /+/+/+ ... +n / n+ ...  ...  def recursive_sum(n):\\n    sum = 0\\n    for i ...\n",
              "174  write a python program which takes input a num...  ...  n=int(input(\"\"))\\nn=n\\nn=n*n\\nn=n+n\\nwhile(n-n...\n",
              "175  write a python class that will initiate a numb...  ...              def square(n):\\n    return n*2\\n<eos>\n",
              "176  write s python program to print the difference...  ...  a = {1, 2, 3, 3, 4, 4, 5, 6, 6, 8}\\n = {4, 6, ...\n",
              "\n",
              "[177 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFnYxCTe09rr",
        "outputId": "4bbe82d3-1bf4-4b45-d557-b1a8d13f4cbd"
      },
      "source": [
        "idx = 34\n",
        "print(results_df.iloc[idx]['src'])\n",
        "print(\"\\n\")\n",
        "print(\"Target:\")\n",
        "print(results_df.iloc[idx]['target'])\n",
        "print(\"\\n\")\n",
        "print(\"Predictions:\")\n",
        "print(results_df.iloc[idx]['translation'])"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "create and print a dictionary\n",
            "\n",
            "\n",
            "Target:\n",
            "thisdict = {\n",
            "  \"brand\": \"Ford\",\n",
            "  \"model\": \"Mustang\",\n",
            "  \"year\": 1964\n",
            "}\n",
            "print(f\"Sample Dictionary:{thisdict}\")\n",
            "\n",
            "\n",
            "\n",
            "Predictions:\n",
            "thisdict = {\n",
            "  \"brand\": \"Ford\",\n",
            "  \"model\": \"Mustang\",\n",
            "  \"year\": 1964\n",
            "}\n",
            "print(f\"Length of Dictionary:{len(thisdict)}\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBJsdf1Ra4lX"
      },
      "source": [
        ""
      ],
      "execution_count": 118,
      "outputs": []
    }
  ]
}