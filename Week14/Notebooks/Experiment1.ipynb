{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "635002f992d44bb09182f80b84bf587d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_18b6a56901ec4fa389c8ec95a705a494",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cda17a38a1d2483b9ea63bcc0d38a3fa",
              "IPY_MODEL_fbd4b87e599845bb81520c9f14dbfc30"
            ]
          }
        },
        "18b6a56901ec4fa389c8ec95a705a494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cda17a38a1d2483b9ea63bcc0d38a3fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9b305a5c7fb6427a9a99dae4de543ee4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 177,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 177,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d110881900544b289b281ceefec44ce"
          }
        },
        "fbd4b87e599845bb81520c9f14dbfc30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_392f57a6c0f34f20a94eab24e0b25de1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 177/177 [01:19&lt;00:00,  2.23it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_01ac3faa96654a1dbab04b6b05a408bc"
          }
        },
        "9b305a5c7fb6427a9a99dae4de543ee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d110881900544b289b281ceefec44ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "392f57a6c0f34f20a94eab24e0b25de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "01ac3faa96654a1dbab04b6b05a408bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p9am1aey1ym"
      },
      "source": [
        "### Features of this notebook\n",
        "1. Custom Spacy Tokenizer with space retained and handling open and close brackets, f strings, etc\n",
        "2. More model parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cWl5cbOxnvV",
        "outputId": "09060725-1db5-4f89-c81c-effede647797"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKkIH7bnyBAR",
        "outputId": "d218f1ea-a2cb-4c5a-bf9d-fc0783bee741"
      },
      "source": [
        "%cd /content/drive/MyDrive/END/Transformer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/END/Transformer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc2IFI5Rqxqd"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Picasso')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-dzij1s3ByF"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJVyVrloxtU0"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.legacy.data import Field, BucketIterator, Example, Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from main_engine import lr_finder, schedulers\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from spacy.tokenizer import Tokenizer\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tokenize\n",
        "from io import BytesIO"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD6T3VORx-Ak"
      },
      "source": [
        "# Setting Random Seeds\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZf2qzPKyFc2",
        "outputId": "2b2c8bac-d438-4882-937a-fb2d684ab3f3"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.1.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzO_Rw8w3Zli"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM7r4aI4yHrU"
      },
      "source": [
        "lines = []\n",
        "with open('english_python_data_corrected.txt', encoding='utf-8') as f:\n",
        "    for counter, line in enumerate(f):\n",
        "            lines.append(line)\n",
        "#Removing comments  \n",
        "comment_re = re.compile(r'#\\s*\\dx\\d\\s*matrix|#\\s*result|#\\s*iterate|#\\s*initialize|#\\s*Driver|#\\s*This function|#\\s*Iterate', \n",
        "                        re.IGNORECASE)\n",
        "lines = [x for x in lines if re.search(comment_re, x) is None]\n",
        "\n",
        "example_start_id = [counter for counter,_ in enumerate(lines) if (_.startswith(\"#\") or _.startswith(\" #\")) and (lines[counter-1].strip() == '')]\n",
        "training_examples = []\n",
        "for num, idx in enumerate(example_start_id):\n",
        "    if idx != example_start_id[-1]:\n",
        "        example_dict = {}\n",
        "        example = lines[example_start_id[num]:example_start_id[num+1]]\n",
        "        if (re.search(r\"#\\s*\\d\", example[0], re.IGNORECASE)) and (re.search(r\"#\", example[1], re.IGNORECASE)) is not None:\n",
        "                    example_dict['ques_prompt'] = example[1].strip()\n",
        "                    example_dict['source_code'] = \"\".join(example[2:]).strip()\n",
        "        elif re.search(r'#\\s*In\\[\\d*\\]', \"\".join(example), re.IGNORECASE) is not None:\n",
        "            continue\n",
        "        else:\n",
        "            example_dict['ques_prompt'] = example[0].strip()\n",
        "            example_dict['source_code'] = \"\".join(example[1:]).strip()\n",
        "        training_examples.append(example_dict)\n",
        "    else:\n",
        "        example_dict = {}\n",
        "        example = lines[example_start_id[num]:]\n",
        "        example_dict['ques_prompt'] = example[0].strip()\n",
        "        example_dict['source_code'] = \"\".join(example[1:]).strip()\n",
        "        training_examples.append(example_dict)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWDP2kEEyQCN"
      },
      "source": [
        "full_data = pd.DataFrame(training_examples)\n",
        "# Dropping examples where length of code was greater than 250 characters\n",
        "len_filter = full_data['source_code'].apply(lambda x:len(x) > 250)\n",
        "full_data.drop(len_filter[len_filter == True].index.tolist(), inplace = True, axis = 0)\n",
        "full_data.reset_index(drop = True, inplace = True)\n",
        "full_data['ques_prompt'] = full_data['ques_prompt'].apply(lambda x:re.sub(r'\\d*', '', x))\n",
        "full_data['ques_prompt'] = full_data['ques_prompt'].apply(lambda x:re.sub(r'(#\\s)+', '', x))\n",
        "full_data.columns = ['src', 'trg']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "UifQzF1uIx2N",
        "outputId": "bd8c01d7-b404-4f26-bcc2-04dbfa025e93"
      },
      "source": [
        "full_data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>trg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>write a python program to add two numbers</td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python function to add two user provid...</td>\n",
              "      <td>def add_two_numbers(num1, num2):\\n    sum = nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a program to find and print the largest ...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &gt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a program to find and print the smallest...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Write a python function to merge two given lis...</td>\n",
              "      <td>def merge_lists(l1, l2):\\n    return l1 + l2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 src                                                trg\n",
              "0          write a python program to add two numbers  num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...\n",
              "1  write a python function to add two user provid...  def add_two_numbers(num1, num2):\\n    sum = nu...\n",
              "2  write a program to find and print the largest ...  num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 >= n...\n",
              "3  write a program to find and print the smallest...  num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <= n...\n",
              "4  Write a python function to merge two given lis...       def merge_lists(l1, l2):\\n    return l1 + l2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdrOdQr80B3J"
      },
      "source": [
        "# Loading spacy language models for tokenization\n",
        "en_tokenizer = spacy.load('en')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqfrzvJE3wJm"
      },
      "source": [
        "# Custom Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtzXgqS6pfeQ"
      },
      "source": [
        "def create_custom_tokenizer(nlp):\n",
        "    \n",
        "    custom_prefix = [r'[\\(]', 'newline', '\\.']\n",
        "    \n",
        "    all_prefixes_re = spacy.util.compile_prefix_regex(tuple(list(nlp.Defaults.prefixes) + custom_prefix))\n",
        "    # To treat newline, brackets as a separate token\n",
        "    custom_infixes = ['\\.\\.\\.+', '(?<=[0-9])-(?=[0-9])', '[!&:,\\.()\\']', 'newline']\n",
        "    infix_re = spacy.util.compile_infix_regex(tuple(list(nlp.Defaults.infixes) + custom_infixes))\n",
        "    custom_suffix = ['newline', '\\.']\n",
        "    suffix_re = spacy.util.compile_suffix_regex(tuple(list(nlp.Defaults.suffixes) + custom_suffix))   \n",
        "    \n",
        "    return Tokenizer(nlp.vocab, nlp.Defaults.tokenizer_exceptions,\n",
        "                     prefix_search = all_prefixes_re.search, \n",
        "                     infix_finditer = infix_re.finditer, suffix_search = suffix_re.search,\n",
        "                     token_match=None)\n",
        "\n",
        "def tokenize_py(text):\n",
        "    \"\"\"\n",
        "    Tokenizes Python text from a string into a list of tokens\n",
        "    \"\"\"\n",
        "    token_texts = []\n",
        "    text = text.replace('\\n', 'newline')\n",
        "    doc = py_tokenizer(text)\n",
        "    for token in doc:\n",
        "      token_texts.append(token.text)\n",
        "      # To include single whitespace as a separate token\n",
        "      if token.whitespace_:  \n",
        "          token_texts.append(token.whitespace_)\n",
        "\n",
        "    token_texts = [x if x!='newline' else '\\n' for x in token_texts]\n",
        "    return token_texts\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of tokens\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in en_tokenizer.tokenizer(text)]\n",
        "\n",
        "py_tokenizer = spacy.load('en')\n",
        "py_tokenizer.tokenizer = create_custom_tokenizer(py_tokenizer)"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQcuYk3C4XgX",
        "outputId": "64e13d27-b674-47d5-c8c7-b7cd9554de02"
      },
      "source": [
        "# Let's test our custom tokenizer\n",
        "idx = 1\n",
        "print(f'Target Sentence :\\n{full_data.iloc[idx, 1]}\\n')\n",
        "print(f'Tokens : {tokenize_py(full_data.iloc[idx, 1])}\\n',)\n",
        "print(f'Reconstructed sentence from Tokens : \\n{\"\".join(tokenize_py(full_data.iloc[idx, 1]))}\\n')"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target Sentence :\n",
            "def add_two_numbers(num1, num2):\n",
            "    sum = num1 + num2\n",
            "    return sum\n",
            "\n",
            "Tokens : ['def', ' ', 'add_two_numbers', '(', 'num1', ',', ' ', 'num2', ')', ':', '\\n', ' ', '   ', 'sum', ' ', '=', ' ', 'num1', ' ', '+', ' ', 'num2', '\\n', ' ', '   ', 'return', ' ', 'sum']\n",
            "\n",
            "Reconstructed sentence from Tokens : \n",
            "def add_two_numbers(num1, num2):\n",
            "    sum = num1 + num2\n",
            "    return sum\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4To5gq4E5oUR",
        "outputId": "f5dc8d13-680e-47ad-bbb4-e5b235db65ed"
      },
      "source": [
        "idx = 1454\n",
        "print(f'Target Sentence :\\n{full_data.iloc[idx, 1]}\\n')\n",
        "print(f'Tokens : {tokenize_py(full_data.iloc[idx, 1])}\\n',)\n",
        "print(f'Reconstructed sentence from Tokens : \\n{\"\".join(tokenize_py(full_data.iloc[idx, 1]))}\\n')"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target Sentence :\n",
            "test_list = [(1, 3), (1, 4), (2, 3), (3, 2), (5, 3), (6, 4)] \n",
            "res = {} \n",
            "for i, j in test_list: \n",
            "     res.setdefault(j, []).append(i) \n",
            "print(\"The dictionary converted from tuple list : \" + str(res))\n",
            "\n",
            "Tokens : ['test_list', ' ', '=', ' ', '[', '(', '1', ',', ' ', '3', ')', ',', ' ', '(', '1', ',', ' ', '4', ')', ',', ' ', '(', '2', ',', ' ', '3', ')', ',', ' ', '(', '3', ',', ' ', '2', ')', ',', ' ', '(', '5', ',', ' ', '3', ')', ',', ' ', '(', '6', ',', ' ', '4', ')', ']', ' ', '\\n', 'res', ' ', '=', ' ', '{', '}', ' ', '\\n', 'for', ' ', 'i', ',', ' ', 'j', ' ', 'in', ' ', 'test_list', ':', ' ', '\\n', ' ', '    ', 'res', '.', 'setdefault', '(', 'j', ',', ' ', '[', ']', ')', '.', 'append', '(', 'i', ')', ' ', '\\n', 'print', '(', '\"The', ' ', 'dictionary', ' ', 'converted', ' ', 'from', ' ', 'tuple', ' ', 'list', ' ', ':', ' ', '\"', ' ', '+', ' ', 'str', '(', 'res', ')', ')']\n",
            "\n",
            "Reconstructed sentence from Tokens : \n",
            "test_list = [(1, 3), (1, 4), (2, 3), (3, 2), (5, 3), (6, 4)] \n",
            "res = {} \n",
            "for i, j in test_list: \n",
            "     res.setdefault(j, []).append(i) \n",
            "print(\"The dictionary converted from tuple list : \" + str(res))\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mUtDWea5uOV"
      },
      "source": [
        "As we can see that the python code structure is maintained and proper tokenization is there for f-strings, spaces, newline, python operators and brackets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iSMa5iYJG-i"
      },
      "source": [
        "# Defining the fields\n",
        "SRC = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            batch_first = True)\n",
        "\n",
        "# lower=False since python is case sensitive language\n",
        "TRG = Field(tokenize = tokenize_py, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = False, \n",
        "            batch_first = True)"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX4CJzLKJXqE"
      },
      "source": [
        "# Creating torchtext dataset \n",
        "fields = [('src', SRC), ('trg', TRG)]\n",
        "examples = [Example.fromlist([full_data.src[i], full_data.trg[i]], fields) for i in range(full_data.shape[0])]\n",
        "complete_dataset = Dataset(examples, fields)"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sxQcLlGMv0-"
      },
      "source": [
        "# Splitting into train, test and validation\n",
        "train_data, valid_data, test_data = complete_dataset.split(split_ratio=[0.80, 0.05, 0.15], \n",
        "                                    random_state=random.seed(SEED))"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6pfjzztO-HE",
        "outputId": "365f5cb7-4e98-4f6e-b9af-5423931f2657"
      },
      "source": [
        "len(train_data), len(valid_data), len(test_data)"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2828, 530, 177)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YhWJpg8PD8B",
        "outputId": "551e9259-1a8a-4316-ad62-ac9f94345422"
      },
      "source": [
        "# Let's look at a few examples from the dataset\n",
        "idx = 4\n",
        "print(''.join(vars(train_data.examples[idx])['trg']))\n",
        "print(vars(train_data.examples[idx])['trg'])\n",
        "print(len(vars(train_data.examples[idx])['trg']))"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "from collections import defaultdict \n",
            "test_list = [1, 3, 4, 5, 1, 3, 5]\n",
            "['from', ' ', 'collections', ' ', 'import', ' ', 'defaultdict', ' ', '\\n', 'test_list', ' ', '=', ' ', '[', '1', ',', ' ', '3', ',', ' ', '4', ',', ' ', '5', ',', ' ', '1', ',', ' ', '3', ',', ' ', '5', ']']\n",
            "34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orcMjw5KohfG",
        "outputId": "0913bb3d-efb9-466e-9902-2d949e8241df"
      },
      "source": [
        "idx = 0\n",
        "print(''.join(vars(train_data.examples[idx])['trg']))\n",
        "print(vars(train_data.examples[idx])['trg'])"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word = \"Hello World\"\n",
            "replace = \"Bye\"\n",
            "input = \"Hello\"\n",
            "after_replace = word.replace(input, replace)\n",
            "print(f\"String ater replacement: {after_replace}\")\n",
            "['word', ' ', '=', ' ', '\"', 'Hello', ' ', 'World\"', '\\n', 'replace', ' ', '=', ' ', '\"', 'Bye\"', '\\n', 'input', ' ', '=', ' ', '\"', 'Hello\"', '\\n', 'after_replace', ' ', '=', ' ', 'word', '.', 'replace', '(', 'input', ',', ' ', 'replace', ')', '\\n', 'print', '(', 'f\"String', ' ', 'ater', ' ', 'replacement', ':', ' ', '{', 'after_replace', '}', '\"', ')']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWATKYiJPKHY"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 1)"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STmUMUnjSeFG",
        "outputId": "d369fb4a-781a-42af-a872-046428d3572b"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = 'cpu'\n",
        "device"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eYIBgWrSkln"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), sort_key = lambda x:len(x.src), sort_within_batch = False,\n",
        "     batch_size = BATCH_SIZE,\n",
        "     device = device)"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCkVjzBuTXFC"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 200):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "        \n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        "            \n",
        "        return src"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKnjbUpXTaZZ"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len] \n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ycLDCPuTf63"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmIaAPSlTl-K"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEbFPA6XTp_g"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 250):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "            \n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBHcoWU0TvW6"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "            \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "            \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        # query, key, value\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06x-eTpHTxmJ"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        \n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return output, attention"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzgmVhkoTz1D"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HID_DIM = 512\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 6\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 1028\n",
        "DEC_PF_DIM = 1028\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device)"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pHkV-bLT3lO"
      },
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5ku2QdmT7G6",
        "outputId": "496e8a52-a049-4143-f715-08c5b20091b5"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 31,135,094 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KALu_7hxUJmP"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlaoFi4PUMpb"
      },
      "source": [
        "model.apply(initialize_weights);"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aGeLVbfUOhw"
      },
      "source": [
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iFH6VuIUQsN"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSeRKtvzUSRd"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "                \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "            \n",
        "        output_dim = output.shape[-1]\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "                \n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "            \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RtYKHfPUUF3"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1bzVnDHUWIR"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QpGdTj_UYtL",
        "outputId": "5b4565a5-8b30-4a23-9230-b695da8070bc"
      },
      "source": [
        "CLIP = 1\n",
        "N_EPOCHS = 70\n",
        "best_valid_loss = float('inf')\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'Experiment_1.pt')\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 42s\n",
            "\tTrain Loss: 5.578 | Train PPL: 264.645\n",
            "\t Val. Loss: 4.501 |  Val. PPL:  90.064\n",
            "Epoch: 02 | Time: 0m 42s\n",
            "\tTrain Loss: 4.295 | Train PPL:  73.308\n",
            "\t Val. Loss: 4.060 |  Val. PPL:  57.978\n",
            "Epoch: 03 | Time: 0m 42s\n",
            "\tTrain Loss: 3.670 | Train PPL:  39.241\n",
            "\t Val. Loss: 3.359 |  Val. PPL:  28.752\n",
            "Epoch: 04 | Time: 0m 43s\n",
            "\tTrain Loss: 3.177 | Train PPL:  23.966\n",
            "\t Val. Loss: 3.036 |  Val. PPL:  20.826\n",
            "Epoch: 05 | Time: 0m 43s\n",
            "\tTrain Loss: 2.905 | Train PPL:  18.271\n",
            "\t Val. Loss: 2.840 |  Val. PPL:  17.122\n",
            "Epoch: 06 | Time: 0m 43s\n",
            "\tTrain Loss: 2.698 | Train PPL:  14.845\n",
            "\t Val. Loss: 2.725 |  Val. PPL:  15.262\n",
            "Epoch: 07 | Time: 0m 43s\n",
            "\tTrain Loss: 2.538 | Train PPL:  12.657\n",
            "\t Val. Loss: 2.538 |  Val. PPL:  12.649\n",
            "Epoch: 08 | Time: 0m 43s\n",
            "\tTrain Loss: 2.386 | Train PPL:  10.872\n",
            "\t Val. Loss: 2.427 |  Val. PPL:  11.320\n",
            "Epoch: 09 | Time: 0m 43s\n",
            "\tTrain Loss: 2.256 | Train PPL:   9.546\n",
            "\t Val. Loss: 2.326 |  Val. PPL:  10.238\n",
            "Epoch: 10 | Time: 0m 43s\n",
            "\tTrain Loss: 2.137 | Train PPL:   8.473\n",
            "\t Val. Loss: 2.263 |  Val. PPL:   9.610\n",
            "Epoch: 11 | Time: 0m 44s\n",
            "\tTrain Loss: 2.034 | Train PPL:   7.642\n",
            "\t Val. Loss: 2.173 |  Val. PPL:   8.781\n",
            "Epoch: 12 | Time: 0m 43s\n",
            "\tTrain Loss: 1.935 | Train PPL:   6.926\n",
            "\t Val. Loss: 2.110 |  Val. PPL:   8.246\n",
            "Epoch: 13 | Time: 0m 43s\n",
            "\tTrain Loss: 1.850 | Train PPL:   6.357\n",
            "\t Val. Loss: 2.068 |  Val. PPL:   7.910\n",
            "Epoch: 14 | Time: 0m 43s\n",
            "\tTrain Loss: 1.770 | Train PPL:   5.871\n",
            "\t Val. Loss: 2.000 |  Val. PPL:   7.388\n",
            "Epoch: 15 | Time: 0m 43s\n",
            "\tTrain Loss: 1.699 | Train PPL:   5.469\n",
            "\t Val. Loss: 1.945 |  Val. PPL:   6.995\n",
            "Epoch: 16 | Time: 0m 43s\n",
            "\tTrain Loss: 1.629 | Train PPL:   5.101\n",
            "\t Val. Loss: 1.894 |  Val. PPL:   6.643\n",
            "Epoch: 17 | Time: 0m 43s\n",
            "\tTrain Loss: 1.561 | Train PPL:   4.765\n",
            "\t Val. Loss: 1.861 |  Val. PPL:   6.429\n",
            "Epoch: 18 | Time: 0m 43s\n",
            "\tTrain Loss: 1.489 | Train PPL:   4.433\n",
            "\t Val. Loss: 1.822 |  Val. PPL:   6.184\n",
            "Epoch: 19 | Time: 0m 43s\n",
            "\tTrain Loss: 1.431 | Train PPL:   4.181\n",
            "\t Val. Loss: 1.798 |  Val. PPL:   6.037\n",
            "Epoch: 20 | Time: 0m 43s\n",
            "\tTrain Loss: 1.376 | Train PPL:   3.958\n",
            "\t Val. Loss: 1.774 |  Val. PPL:   5.891\n",
            "Epoch: 21 | Time: 0m 43s\n",
            "\tTrain Loss: 1.320 | Train PPL:   3.743\n",
            "\t Val. Loss: 1.725 |  Val. PPL:   5.612\n",
            "Epoch: 22 | Time: 0m 43s\n",
            "\tTrain Loss: 1.266 | Train PPL:   3.547\n",
            "\t Val. Loss: 1.681 |  Val. PPL:   5.372\n",
            "Epoch: 23 | Time: 0m 43s\n",
            "\tTrain Loss: 1.215 | Train PPL:   3.370\n",
            "\t Val. Loss: 1.659 |  Val. PPL:   5.254\n",
            "Epoch: 24 | Time: 0m 43s\n",
            "\tTrain Loss: 1.171 | Train PPL:   3.227\n",
            "\t Val. Loss: 1.670 |  Val. PPL:   5.314\n",
            "Epoch: 25 | Time: 0m 43s\n",
            "\tTrain Loss: 1.122 | Train PPL:   3.071\n",
            "\t Val. Loss: 1.625 |  Val. PPL:   5.076\n",
            "Epoch: 26 | Time: 0m 43s\n",
            "\tTrain Loss: 1.087 | Train PPL:   2.965\n",
            "\t Val. Loss: 1.590 |  Val. PPL:   4.902\n",
            "Epoch: 27 | Time: 0m 43s\n",
            "\tTrain Loss: 1.037 | Train PPL:   2.822\n",
            "\t Val. Loss: 1.580 |  Val. PPL:   4.856\n",
            "Epoch: 28 | Time: 0m 44s\n",
            "\tTrain Loss: 0.999 | Train PPL:   2.716\n",
            "\t Val. Loss: 1.560 |  Val. PPL:   4.761\n",
            "Epoch: 29 | Time: 0m 43s\n",
            "\tTrain Loss: 0.963 | Train PPL:   2.620\n",
            "\t Val. Loss: 1.539 |  Val. PPL:   4.660\n",
            "Epoch: 30 | Time: 0m 43s\n",
            "\tTrain Loss: 0.929 | Train PPL:   2.531\n",
            "\t Val. Loss: 1.516 |  Val. PPL:   4.552\n",
            "Epoch: 31 | Time: 0m 43s\n",
            "\tTrain Loss: 0.890 | Train PPL:   2.436\n",
            "\t Val. Loss: 1.514 |  Val. PPL:   4.545\n",
            "Epoch: 32 | Time: 0m 42s\n",
            "\tTrain Loss: 0.855 | Train PPL:   2.351\n",
            "\t Val. Loss: 1.492 |  Val. PPL:   4.445\n",
            "Epoch: 33 | Time: 0m 43s\n",
            "\tTrain Loss: 0.825 | Train PPL:   2.281\n",
            "\t Val. Loss: 1.501 |  Val. PPL:   4.487\n",
            "Epoch: 34 | Time: 0m 42s\n",
            "\tTrain Loss: 0.791 | Train PPL:   2.206\n",
            "\t Val. Loss: 1.471 |  Val. PPL:   4.353\n",
            "Epoch: 35 | Time: 0m 43s\n",
            "\tTrain Loss: 0.765 | Train PPL:   2.150\n",
            "\t Val. Loss: 1.459 |  Val. PPL:   4.300\n",
            "Epoch: 36 | Time: 0m 43s\n",
            "\tTrain Loss: 0.735 | Train PPL:   2.085\n",
            "\t Val. Loss: 1.448 |  Val. PPL:   4.254\n",
            "Epoch: 37 | Time: 0m 43s\n",
            "\tTrain Loss: 0.709 | Train PPL:   2.031\n",
            "\t Val. Loss: 1.441 |  Val. PPL:   4.224\n",
            "Epoch: 38 | Time: 0m 43s\n",
            "\tTrain Loss: 0.678 | Train PPL:   1.969\n",
            "\t Val. Loss: 1.426 |  Val. PPL:   4.160\n",
            "Epoch: 39 | Time: 0m 43s\n",
            "\tTrain Loss: 0.651 | Train PPL:   1.918\n",
            "\t Val. Loss: 1.418 |  Val. PPL:   4.130\n",
            "Epoch: 40 | Time: 0m 43s\n",
            "\tTrain Loss: 0.634 | Train PPL:   1.884\n",
            "\t Val. Loss: 1.422 |  Val. PPL:   4.145\n",
            "Epoch: 41 | Time: 0m 43s\n",
            "\tTrain Loss: 0.614 | Train PPL:   1.849\n",
            "\t Val. Loss: 1.412 |  Val. PPL:   4.102\n",
            "Epoch: 42 | Time: 0m 43s\n",
            "\tTrain Loss: 0.588 | Train PPL:   1.801\n",
            "\t Val. Loss: 1.401 |  Val. PPL:   4.059\n",
            "Epoch: 43 | Time: 0m 43s\n",
            "\tTrain Loss: 0.572 | Train PPL:   1.772\n",
            "\t Val. Loss: 1.390 |  Val. PPL:   4.015\n",
            "Epoch: 44 | Time: 0m 42s\n",
            "\tTrain Loss: 0.546 | Train PPL:   1.726\n",
            "\t Val. Loss: 1.380 |  Val. PPL:   3.976\n",
            "Epoch: 45 | Time: 0m 43s\n",
            "\tTrain Loss: 0.529 | Train PPL:   1.697\n",
            "\t Val. Loss: 1.381 |  Val. PPL:   3.980\n",
            "Epoch: 46 | Time: 0m 43s\n",
            "\tTrain Loss: 0.504 | Train PPL:   1.655\n",
            "\t Val. Loss: 1.382 |  Val. PPL:   3.984\n",
            "Epoch: 47 | Time: 0m 43s\n",
            "\tTrain Loss: 0.493 | Train PPL:   1.637\n",
            "\t Val. Loss: 1.369 |  Val. PPL:   3.931\n",
            "Epoch: 48 | Time: 0m 43s\n",
            "\tTrain Loss: 0.474 | Train PPL:   1.606\n",
            "\t Val. Loss: 1.350 |  Val. PPL:   3.856\n",
            "Epoch: 49 | Time: 0m 43s\n",
            "\tTrain Loss: 0.457 | Train PPL:   1.580\n",
            "\t Val. Loss: 1.372 |  Val. PPL:   3.943\n",
            "Epoch: 50 | Time: 0m 43s\n",
            "\tTrain Loss: 0.438 | Train PPL:   1.549\n",
            "\t Val. Loss: 1.357 |  Val. PPL:   3.885\n",
            "Epoch: 51 | Time: 0m 43s\n",
            "\tTrain Loss: 0.423 | Train PPL:   1.526\n",
            "\t Val. Loss: 1.355 |  Val. PPL:   3.876\n",
            "Epoch: 52 | Time: 0m 43s\n",
            "\tTrain Loss: 0.408 | Train PPL:   1.504\n",
            "\t Val. Loss: 1.363 |  Val. PPL:   3.909\n",
            "Epoch: 53 | Time: 0m 43s\n",
            "\tTrain Loss: 0.398 | Train PPL:   1.489\n",
            "\t Val. Loss: 1.344 |  Val. PPL:   3.835\n",
            "Epoch: 54 | Time: 0m 43s\n",
            "\tTrain Loss: 0.384 | Train PPL:   1.468\n",
            "\t Val. Loss: 1.360 |  Val. PPL:   3.897\n",
            "Epoch: 55 | Time: 0m 43s\n",
            "\tTrain Loss: 0.372 | Train PPL:   1.451\n",
            "\t Val. Loss: 1.377 |  Val. PPL:   3.962\n",
            "Epoch: 56 | Time: 0m 43s\n",
            "\tTrain Loss: 0.353 | Train PPL:   1.424\n",
            "\t Val. Loss: 1.372 |  Val. PPL:   3.942\n",
            "Epoch: 57 | Time: 0m 43s\n",
            "\tTrain Loss: 0.345 | Train PPL:   1.413\n",
            "\t Val. Loss: 1.364 |  Val. PPL:   3.913\n",
            "Epoch: 58 | Time: 0m 43s\n",
            "\tTrain Loss: 0.332 | Train PPL:   1.394\n",
            "\t Val. Loss: 1.361 |  Val. PPL:   3.901\n",
            "Epoch: 59 | Time: 0m 43s\n",
            "\tTrain Loss: 0.321 | Train PPL:   1.378\n",
            "\t Val. Loss: 1.364 |  Val. PPL:   3.910\n",
            "Epoch: 60 | Time: 0m 43s\n",
            "\tTrain Loss: 0.310 | Train PPL:   1.363\n",
            "\t Val. Loss: 1.372 |  Val. PPL:   3.942\n",
            "Epoch: 61 | Time: 0m 43s\n",
            "\tTrain Loss: 0.302 | Train PPL:   1.353\n",
            "\t Val. Loss: 1.347 |  Val. PPL:   3.845\n",
            "Epoch: 62 | Time: 0m 43s\n",
            "\tTrain Loss: 0.292 | Train PPL:   1.339\n",
            "\t Val. Loss: 1.367 |  Val. PPL:   3.925\n",
            "Epoch: 63 | Time: 0m 43s\n",
            "\tTrain Loss: 0.282 | Train PPL:   1.326\n",
            "\t Val. Loss: 1.357 |  Val. PPL:   3.885\n",
            "Epoch: 64 | Time: 0m 43s\n",
            "\tTrain Loss: 0.273 | Train PPL:   1.314\n",
            "\t Val. Loss: 1.362 |  Val. PPL:   3.905\n",
            "Epoch: 65 | Time: 0m 42s\n",
            "\tTrain Loss: 0.268 | Train PPL:   1.307\n",
            "\t Val. Loss: 1.379 |  Val. PPL:   3.970\n",
            "Epoch: 66 | Time: 0m 43s\n",
            "\tTrain Loss: 0.258 | Train PPL:   1.294\n",
            "\t Val. Loss: 1.375 |  Val. PPL:   3.954\n",
            "Epoch: 67 | Time: 0m 43s\n",
            "\tTrain Loss: 0.249 | Train PPL:   1.283\n",
            "\t Val. Loss: 1.368 |  Val. PPL:   3.928\n",
            "Epoch: 68 | Time: 0m 43s\n",
            "\tTrain Loss: 0.243 | Train PPL:   1.275\n",
            "\t Val. Loss: 1.374 |  Val. PPL:   3.950\n",
            "Epoch: 69 | Time: 0m 43s\n",
            "\tTrain Loss: 0.235 | Train PPL:   1.264\n",
            "\t Val. Loss: 1.357 |  Val. PPL:   3.884\n",
            "Epoch: 70 | Time: 0m 43s\n",
            "\tTrain Loss: 0.226 | Train PPL:   1.253\n",
            "\t Val. Loss: 1.374 |  Val. PPL:   3.951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7Dty35Sf9bL",
        "outputId": "1eb68a4a-520f-48c3-cbd4-2aa4a7324e95"
      },
      "source": [
        "model.load_state_dict(torch.load('Experiment_1.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 1.439 | Test PPL:   4.216 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "_pmW1KVL9fIA",
        "outputId": "3d170cc1-df6d-42ee-e39d-a232c1c45b9a"
      },
      "source": [
        "def plot_losses(train_losses, valid_losses):\n",
        "  fig, ax = plt.subplots(figsize = (12, 6))\n",
        "  epochs = list(range(len(train_losses)))\n",
        "  ax.plot(epochs, train_losses, label = 'train_loss', color = 'green')\n",
        "  ax.plot(epochs, valid_losses, label = 'valid_loss', color = 'red')\n",
        "  ax.legend()\n",
        "  ax.set(xlabel = 'Epochs', ylabel = 'Cross_Entropy_Loss', title = 'Variation of loss with epochs')\n",
        "\n",
        "plot_losses(train_losses, valid_losses)"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_WBWxvDzPoB"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7e5Ny4dzToy"
      },
      "source": [
        "def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 8, n_cols = 1):\n",
        "    \n",
        "    assert n_rows * n_cols == n_heads\n",
        "    \n",
        "    fig = plt.figure(figsize=(200,100))\n",
        "    \n",
        "    for i in range(n_heads):\n",
        "        \n",
        "        ax = fig.add_subplot(n_rows, n_cols, i+1)\n",
        "        \n",
        "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
        "\n",
        "        cax = ax.matshow(_attention, cmap='bone')\n",
        "\n",
        "        ax.tick_params(labelsize=12)\n",
        "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
        "                           rotation=45)\n",
        "        ax.set_yticklabels(['']+translation)\n",
        "\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN50LEW3zX3F"
      },
      "source": [
        "def show_results(infer_data, example_idx):\n",
        "  src = vars(infer_data.examples[example_idx])['src']\n",
        "  trg = vars(infer_data.examples[example_idx])['trg']\n",
        "  # print(f'src = {\" \".join(src)}')\n",
        "  # print(f'trg :\\n {\" \".join(trg)}')\n",
        "\n",
        "  translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "  # print(f'predicted trg :\\n {\" \".join(translation)}')\n",
        "\n",
        "  # display_attention(src, translation, attention)\n",
        "  return \" \".join(src), \"\".join(trg), \"\".join(translation)"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPjskSMHzaHo"
      },
      "source": [
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "635002f992d44bb09182f80b84bf587d",
            "18b6a56901ec4fa389c8ec95a705a494",
            "cda17a38a1d2483b9ea63bcc0d38a3fa",
            "fbd4b87e599845bb81520c9f14dbfc30",
            "9b305a5c7fb6427a9a99dae4de543ee4",
            "8d110881900544b289b281ceefec44ce",
            "392f57a6c0f34f20a94eab24e0b25de1",
            "01ac3faa96654a1dbab04b6b05a408bc"
          ]
        },
        "id": "SUib4Wduz8WM",
        "outputId": "e2c54cd9-43c4-4b08-ace8-8dad06c03cfc"
      },
      "source": [
        "results_df = pd.DataFrame()\n",
        "for i in tqdm(range(len(test_data)), total = len(test_data)):\n",
        "  # print(i)\n",
        "  src, target, translation = show_results(test_data, i)\n",
        "  row_df = pd.DataFrame({'src': src, 'target': target, 'translation': translation}, index = [0])\n",
        "  results_df = pd.concat([results_df, row_df])"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "635002f992d44bb09182f80b84bf587d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=177.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acikDf8BzPsP"
      },
      "source": [
        "results_df.reset_index(drop = True, inplace = True)"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "P5asPFPB0maj",
        "outputId": "6a15fac6-fa90-4ae7-d43d-996d0f29e089"
      },
      "source": [
        "results_df"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>target</th>\n",
              "      <th>translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>write a python function to get the surface_are...</td>\n",
              "      <td>def rec_prism_surface_area(length, width, heig...</td>\n",
              "      <td>def pyramid_surface_area(length, height):\\n   ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python function to add elements of two...</td>\n",
              "      <td>def add_two_lists(list1, list2):\\n   list1 = [...</td>\n",
              "      <td>def add_two_lists(list1, list2):\\n   list1 = [...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a lambda function to multiply two numbers</td>\n",
              "      <td>multiply = lambda a, b: a*b</td>\n",
              "      <td>def add_two_lists(a, b):\\n    union(x, y) = la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a python function to generate cube numbe...</td>\n",
              "      <td>def cube_numbers(n):\\n    for i in range(n):\\n...</td>\n",
              "      <td>def square_numbers(n):\\n    for i in range(n):...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>define a custom exception class which takes a ...</td>\n",
              "      <td>class MyError(Exception):\\n    def __init__(se...</td>\n",
              "      <td>class MyError(msg):\\n    def __init__(self, ms...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>write a   python function that returns the h...</td>\n",
              "      <td>def calculate_hcf(x1, x2):\\n    if x1 == 0:\\n ...</td>\n",
              "      <td>def gcd(a, b):\\n    return a * b&lt;eos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>write a program to compute /+/+/+ ... +n / n+ ...</td>\n",
              "      <td>n=int(raw_input())\\nsum=0.0\\nfor i in range(1,...</td>\n",
              "      <td>n=int(input(\"Enter the Number:\"))\\nsum = 0\\nfo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>write a python program which takes input a num...</td>\n",
              "      <td>N = int(input(\"Please enter a number \"))\\nfirs...</td>\n",
              "      <td>n = int(input(\"Enter a a number: \"))\\nn = 0\\nf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>write a python class that will initiate a numb...</td>\n",
              "      <td>class Number:\\n\\tdef __init__(self, num):\\n\\t\\...</td>\n",
              "      <td>class Person:\\n    def __init__(self, n):\\n   ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>write s python program to print the difference...</td>\n",
              "      <td>A = {1, 2, 3, 4, 5}\\n B = {4, 5, 6, 7, 8}\\n pr...</td>\n",
              "      <td>A = {1, 2, 3, 4, 5}\\n B = {4, 5, 6, 7, 8}\\n pr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>177 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   src  ...                                        translation\n",
              "0    write a python function to get the surface_are...  ...  def pyramid_surface_area(length, height):\\n   ...\n",
              "1    write a python function to add elements of two...  ...  def add_two_lists(list1, list2):\\n   list1 = [...\n",
              "2      write a lambda function to multiply two numbers  ...  def add_two_lists(a, b):\\n    union(x, y) = la...\n",
              "3    write a python function to generate cube numbe...  ...  def square_numbers(n):\\n    for i in range(n):...\n",
              "4    define a custom exception class which takes a ...  ...  class MyError(msg):\\n    def __init__(self, ms...\n",
              "..                                                 ...  ...                                                ...\n",
              "172    write a   python function that returns the h...  ...              def gcd(a, b):\\n    return a * b<eos>\n",
              "173  write a program to compute /+/+/+ ... +n / n+ ...  ...  n=int(input(\"Enter the Number:\"))\\nsum = 0\\nfo...\n",
              "174  write a python program which takes input a num...  ...  n = int(input(\"Enter a a number: \"))\\nn = 0\\nf...\n",
              "175  write a python class that will initiate a numb...  ...  class Person:\\n    def __init__(self, n):\\n   ...\n",
              "176  write s python program to print the difference...  ...  A = {1, 2, 3, 4, 5}\\n B = {4, 5, 6, 7, 8}\\n pr...\n",
              "\n",
              "[177 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFnYxCTe09rr",
        "outputId": "c7d64879-90a6-46bb-d732-db9808c016d1"
      },
      "source": [
        "idx = 29\n",
        "print(results_df.iloc[idx]['src'])\n",
        "print(\"\\n\")\n",
        "print(\"Target:\")\n",
        "print(results_df.iloc[idx]['target'])\n",
        "print(\"\\n\")\n",
        "print(\"Predictions:\")\n",
        "print(results_df.iloc[idx]['translation'])"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compute the product of every pair of numbers from two lists\n",
            "\n",
            "\n",
            "Target:\n",
            "list1 = [1, 2, 3]\n",
            "list2 = [5, 6, 7] \n",
            "final = [a*b for a in list1 for b in list2]\n",
            "print(f\"Product of every pair of numbers from two lists:{final}\")\n",
            "\n",
            "\n",
            "Predictions:\n",
            "list1 = [1, 2, 3]\n",
            "list2 = [5, 6, 7] \n",
            "final = [a*b for a in list1 for b in list2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBJsdf1Ra4lX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}